_base_result_dir: /scratch/chenyuan-data/knighter-dev/result-gpt-5-0814
commit_id: 8bc35475ef1a23b0e224f3242eb11c76cab0ea88
commit_type: Concurrency
index: 4
initial_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/ASTContext.h\"\n#include \"clang/AST/Expr.h\"\n#include \"\
  clang/AST/Stmt.h\"\n#include \"clang/Lex/Lexer.h\"\n\nusing namespace clang;\nusing\
  \ namespace ento;\nusing namespace taint;\n\nREGISTER_MAP_WITH_PROGRAMSTATE(SharedSpecReadMap,\
  \ const MemRegion*, const Stmt*)\n\nnamespace {\n\nclass SAGenTestChecker : public\
  \ Checker<check::Bind, check::BranchCondition> {\n   mutable std::unique_ptr<BugType>\
  \ BT;\n\n   public:\n      SAGenTestChecker() : BT(new BugType(this, \"Speculative\
  \ shared read before gate\", \"Concurrency\")) {}\n\n      void checkBind(SVal Loc,\
  \ SVal Val, const Stmt *S, CheckerContext &C) const;\n      void checkBranchCondition(const\
  \ Stmt *Condition, CheckerContext &C) const;\n\n   private:\n\n      // Helpers\n\
  \      static const MemRegion *getStoreRegion(SVal Loc);\n      static bool conditionHasFromCancel(const\
  \ Stmt *Cond, CheckerContext &C);\n      static const BinaryOperator *getTopLevelLAnd(const\
  \ Stmt *Cond);\n      static bool isBefore(const Stmt *A, const Stmt *B, CheckerContext\
  \ &C);\n\n      static const UnaryOperator *findDerefOfWorkDataBitsInStmt(const\
  \ Stmt *S, CheckerContext &C);\n      static const MemRegion *findTrackedRegionInExpr(const\
  \ Expr *E, ProgramStateRef State, CheckerContext &C);\n};\n\n// --- Helper implementations\
  \ ---\n\nconst MemRegion *SAGenTestChecker::getStoreRegion(SVal Loc) {\n  if (const\
  \ MemRegion *MR = Loc.getAsRegion()) {\n    return MR->getBaseRegion();\n  }\n \
  \ return nullptr;\n}\n\nbool SAGenTestChecker::conditionHasFromCancel(const Stmt\
  \ *Cond, CheckerContext &C) {\n  if (!Cond) return false;\n  const Expr *E = dyn_cast<Expr>(Cond);\n\
  \  if (!E) return false;\n  return ExprHasName(E, \"from_cancel\", C);\n}\n\nconst\
  \ BinaryOperator *SAGenTestChecker::getTopLevelLAnd(const Stmt *Cond) {\n  if (!Cond)\
  \ return nullptr;\n  const Expr *E = dyn_cast<Expr>(Cond);\n  if (!E) return nullptr;\n\
  \  E = E->IgnoreImplicit();\n  if (const auto *BO = dyn_cast<BinaryOperator>(E))\
  \ {\n    if (BO->getOpcode() == BO_LAnd)\n      return BO;\n  }\n  return nullptr;\n\
  }\n\nbool SAGenTestChecker::isBefore(const Stmt *A, const Stmt *B, CheckerContext\
  \ &C) {\n  if (!A || !B) return false;\n  const SourceManager &SM = C.getSourceManager();\n\
  \  return SM.isBeforeInTranslationUnit(A->getBeginLoc(), B->getBeginLoc());\n}\n\
  \nstatic const UnaryOperator *findDerefOfWorkDataBitsInStmtRec(const Stmt *S, CheckerContext\
  \ &C) {\n  if (!S) return nullptr;\n\n  if (const auto *UO = dyn_cast<UnaryOperator>(S))\
  \ {\n    if (UO->getOpcode() == UO_Deref) {\n      const Expr *Sub = UO->getSubExpr();\n\
  \      if (Sub && ExprHasName(Sub, \"work_data_bits\", C))\n        return UO;\n\
  \    }\n  }\n\n  for (const Stmt *Child : S->children()) {\n    if (const UnaryOperator\
  \ *Res = findDerefOfWorkDataBitsInStmtRec(Child, C))\n      return Res;\n  }\n \
  \ return nullptr;\n}\n\nconst UnaryOperator *SAGenTestChecker::findDerefOfWorkDataBitsInStmt(const\
  \ Stmt *S, CheckerContext &C) {\n  return findDerefOfWorkDataBitsInStmtRec(S, C);\n\
  }\n\nstatic const MemRegion *findTrackedRegionInExprRec(const Expr *E, ProgramStateRef\
  \ State, CheckerContext &C) {\n  if (!E) return nullptr;\n\n  // Try current expression\
  \ if it's a DeclRefExpr\n  if (const auto *DRE = dyn_cast<DeclRefExpr>(E->IgnoreParenCasts()))\
  \ {\n    if (const MemRegion *MR = getMemRegionFromExpr(DRE, C)) {\n      MR = MR->getBaseRegion();\n\
  \      if (MR) {\n        if (State->get<SharedSpecReadMap>(MR))\n          return\
  \ MR;\n      }\n    }\n  }\n\n  // Recurse into children\n  for (const Stmt *Child\
  \ : E->children()) {\n    if (const auto *CE = dyn_cast_or_null<Expr>(Child)) {\n\
  \      if (const MemRegion *Found = findTrackedRegionInExprRec(CE, State, C))\n\
  \        return Found;\n    }\n  }\n  return nullptr;\n}\n\nconst MemRegion *SAGenTestChecker::findTrackedRegionInExpr(const\
  \ Expr *E, ProgramStateRef State, CheckerContext &C) {\n  return findTrackedRegionInExprRec(E,\
  \ State, C);\n}\n\n// --- Checker callbacks ---\n\nvoid SAGenTestChecker::checkBind(SVal\
  \ Loc, SVal /*Val*/, const Stmt *S, CheckerContext &C) const {\n  ProgramStateRef\
  \ State = C.getState();\n\n  const MemRegion *DestR = getStoreRegion(Loc);\n  if\
  \ (!DestR)\n    return;\n\n  // Only track simple variable regions (local/param)\n\
  \  if (!isa<VarRegion>(DestR))\n    return;\n\n  // Check if RHS (present in the\
  \ StoreE statement) contains \"*work_data_bits(...)\"\n  const UnaryOperator *Deref\
  \ = findDerefOfWorkDataBitsInStmt(S, C);\n\n  if (Deref) {\n    // Mark this variable\
  \ as holding a speculative read from work->data\n    State = State->set<SharedSpecReadMap>(DestR,\
  \ cast<Stmt>(Deref));\n    C.addTransition(State);\n    return;\n  }\n\n  // Not\
  \ assigned from work_data_bits deref; clear any previous mark\n  if (State->get<SharedSpecReadMap>(DestR))\
  \ {\n    State = State->remove<SharedSpecReadMap>(DestR);\n    C.addTransition(State);\n\
  \  }\n}\n\nvoid SAGenTestChecker::checkBranchCondition(const Stmt *Condition, CheckerContext\
  \ &C) const {\n  ProgramStateRef State = C.getState();\n\n  if (!conditionHasFromCancel(Condition,\
  \ C))\n    return;\n\n  const BinaryOperator *LAnd = getTopLevelLAnd(Condition);\n\
  \  if (!LAnd)\n    return;\n\n  const Expr *RHS = dyn_cast<Expr>(LAnd->getRHS());\n\
  \  if (!RHS)\n    return;\n\n  const MemRegion *UsedR = findTrackedRegionInExpr(RHS,\
  \ State, C);\n  if (!UsedR)\n    return;\n\n  const Stmt *ReadSite = State->get<SharedSpecReadMap>(UsedR);\n\
  \  if (!ReadSite)\n    return;\n\n  // Ensure the speculative read happens before\
  \ this condition in source order\n  if (!isBefore(ReadSite, Condition, C))\n   \
  \ return;\n\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n  if (!N)\n   \
  \ return;\n\n  auto R = std::make_unique<PathSensitiveBugReport>(\n      *BT, \"\
  Speculative read of work->data before checking from_cancel\", N);\n\n  // Highlight\
  \ the dereference '*work_data_bits(...)'\n  R->addRange(ReadSite->getSourceRange());\n\
  \  C.emitReport(std::move(R));\n\n  // Optional: prevent duplicate reports for the\
  \ same variable along other paths\n  State = State->remove<SharedSpecReadMap>(UsedR);\n\
  \  C.addTransition(State);\n}\n\n} // end anonymous namespace\n\nextern \"C\" void\
  \ clang_registerCheckers(CheckerRegistry &registry) {\n  registry.addChecker<SAGenTestChecker>(\n\
  \      \"custom.SAGenTestChecker\",\n      \"Detects read of work->data before checking\
  \ from_cancel\",\n      \"\");\n}\n\nextern \"C\" const char clang_analyzerAPIVersionString[]\
  \ =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
patch: "## Patch Description\n\nworkqueue: Fix spruious data race in __flush_work()\n\
  \nWhen flushing a work item for cancellation, __flush_work() knows that it\nexclusively\
  \ owns the work item through its PENDING bit. 134874e2eee9\n(\"workqueue: Allow\
  \ cancel_work_sync() and disable_work() from atomic\ncontexts on BH work items\"\
  ) added a read of @work->data to determine whether\nto use busy wait for BH work\
  \ items that are being canceled. While the read\nis safe when @from_cancel, @work->data\
  \ was read before testing @from_cancel\nto simplify code structure:\n\n\tdata =\
  \ *work_data_bits(work);\n\tif (from_cancel &&\n\t    !WARN_ON_ONCE(data & WORK_STRUCT_PWQ)\
  \ && (data & WORK_OFFQ_BH)) {\n\nWhile the read data was never used if !@from_cancel,\
  \ this could trigger\nKCSAN data race detection spuriously:\n\n  ==================================================================\n\
  \  BUG: KCSAN: data-race in __flush_work / __flush_work\n\n  write to 0xffff8881223aa3e8\
  \ of 8 bytes by task 3998 on cpu 0:\n   instrument_write include/linux/instrumented.h:41\
  \ [inline]\n   ___set_bit include/asm-generic/bitops/instrumented-non-atomic.h:28\
  \ [inline]\n   insert_wq_barrier kernel/workqueue.c:3790 [inline]\n   start_flush_work\
  \ kernel/workqueue.c:4142 [inline]\n   __flush_work+0x30b/0x570 kernel/workqueue.c:4178\n\
  \   flush_work kernel/workqueue.c:4229 [inline]\n   ...\n\n  read to 0xffff8881223aa3e8\
  \ of 8 bytes by task 50 on cpu 1:\n   __flush_work+0x42a/0x570 kernel/workqueue.c:4188\n\
  \   flush_work kernel/workqueue.c:4229 [inline]\n   flush_delayed_work+0x66/0x70\
  \ kernel/workqueue.c:4251\n   ...\n\n  value changed: 0x0000000000400000 -> 0xffff88810006c00d\n\
  \nReorganize the code so that @from_cancel is tested before @work->data is\naccessed.\
  \ The only problem is triggering KCSAN detection spuriously. This\nshouldn't need\
  \ READ_ONCE() or other access qualifiers.\n\nNo functional changes.\n\nSigned-off-by:\
  \ Tejun Heo <tj@kernel.org>\nReported-by: syzbot+b3e4f2f51ed645fd5df2@syzkaller.appspotmail.com\n\
  Fixes: 134874e2eee9 (\"workqueue: Allow cancel_work_sync() and disable_work() from\
  \ atomic contexts on BH work items\")\nLink: http://lkml.kernel.org/r/000000000000ae429e061eea2157@google.com\n\
  Cc: Jens Axboe <axboe@kernel.dk>\n\n## Buggy Code\n\n```c\n// Function: __flush_work\
  \ in kernel/workqueue.c\nstatic bool __flush_work(struct work_struct *work, bool\
  \ from_cancel)\n{\n\tstruct wq_barrier barr;\n\tunsigned long data;\n\n\tif (WARN_ON(!wq_online))\n\
  \t\treturn false;\n\n\tif (WARN_ON(!work->func))\n\t\treturn false;\n\n\tif (!start_flush_work(work,\
  \ &barr, from_cancel))\n\t\treturn false;\n\n\t/*\n\t * start_flush_work() returned\
  \ %true. If @from_cancel is set, we know\n\t * that @work must have been executing\
  \ during start_flush_work() and\n\t * can't currently be queued. Its data must contain\
  \ OFFQ bits. If @work\n\t * was queued on a BH workqueue, we also know that it was\
  \ running in the\n\t * BH context and thus can be busy-waited.\n\t */\n\tdata =\
  \ *work_data_bits(work);\n\tif (from_cancel &&\n\t    !WARN_ON_ONCE(data & WORK_STRUCT_PWQ)\
  \ && (data & WORK_OFFQ_BH)) {\n\t\t/*\n\t\t * On RT, prevent a live lock when %current\
  \ preempted soft\n\t\t * interrupt processing or prevents ksoftirqd from running\
  \ by\n\t\t * keeping flipping BH. If the BH work item runs on a different\n\t\t\
  \ * CPU then this has no effect other than doing the BH\n\t\t * disable/enable dance\
  \ for nothing. This is copied from\n\t\t * kernel/softirq.c::tasklet_unlock_spin_wait().\n\
  \t\t */\n\t\twhile (!try_wait_for_completion(&barr.done)) {\n\t\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT))\
  \ {\n\t\t\t\tlocal_bh_disable();\n\t\t\t\tlocal_bh_enable();\n\t\t\t} else {\n\t\
  \t\t\tcpu_relax();\n\t\t\t}\n\t\t}\n\t} else {\n\t\twait_for_completion(&barr.done);\n\
  \t}\n\n\tdestroy_work_on_stack(&barr.work);\n\treturn true;\n}\n```\n\n## Bug Fix\
  \ Patch\n\n```diff\ndiff --git a/kernel/workqueue.c b/kernel/workqueue.c\nindex\
  \ d56bd2277e58..ef174d8c1f63 100644\n--- a/kernel/workqueue.c\n+++ b/kernel/workqueue.c\n\
  @@ -4166,7 +4166,6 @@ static bool start_flush_work(struct work_struct *work, struct\
  \ wq_barrier *barr,\n static bool __flush_work(struct work_struct *work, bool from_cancel)\n\
  \ {\n \tstruct wq_barrier barr;\n-\tunsigned long data;\n \n \tif (WARN_ON(!wq_online))\n\
  \ \t\treturn false;\n@@ -4184,29 +4183,35 @@ static bool __flush_work(struct work_struct\
  \ *work, bool from_cancel)\n \t * was queued on a BH workqueue, we also know that\
  \ it was running in the\n \t * BH context and thus can be busy-waited.\n \t */\n\
  -\tdata = *work_data_bits(work);\n-\tif (from_cancel &&\n-\t    !WARN_ON_ONCE(data\
  \ & WORK_STRUCT_PWQ) && (data & WORK_OFFQ_BH)) {\n-\t\t/*\n-\t\t * On RT, prevent\
  \ a live lock when %current preempted soft\n-\t\t * interrupt processing or prevents\
  \ ksoftirqd from running by\n-\t\t * keeping flipping BH. If the BH work item runs\
  \ on a different\n-\t\t * CPU then this has no effect other than doing the BH\n\
  -\t\t * disable/enable dance for nothing. This is copied from\n-\t\t * kernel/softirq.c::tasklet_unlock_spin_wait().\n\
  -\t\t */\n-\t\twhile (!try_wait_for_completion(&barr.done)) {\n-\t\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT))\
  \ {\n-\t\t\t\tlocal_bh_disable();\n-\t\t\t\tlocal_bh_enable();\n-\t\t\t} else {\n\
  -\t\t\t\tcpu_relax();\n+\tif (from_cancel) {\n+\t\tunsigned long data = *work_data_bits(work);\n\
  +\n+\t\tif (!WARN_ON_ONCE(data & WORK_STRUCT_PWQ) &&\n+\t\t    (data & WORK_OFFQ_BH))\
  \ {\n+\t\t\t/*\n+\t\t\t * On RT, prevent a live lock when %current preempted\n+\t\
  \t\t * soft interrupt processing or prevents ksoftirqd from\n+\t\t\t * running by\
  \ keeping flipping BH. If the BH work item\n+\t\t\t * runs on a different CPU then\
  \ this has no effect other\n+\t\t\t * than doing the BH disable/enable dance for\
  \ nothing.\n+\t\t\t * This is copied from\n+\t\t\t * kernel/softirq.c::tasklet_unlock_spin_wait().\n\
  +\t\t\t */\n+\t\t\twhile (!try_wait_for_completion(&barr.done)) {\n+\t\t\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT))\
  \ {\n+\t\t\t\t\tlocal_bh_disable();\n+\t\t\t\t\tlocal_bh_enable();\n+\t\t\t\t} else\
  \ {\n+\t\t\t\t\tcpu_relax();\n+\t\t\t\t}\n \t\t\t}\n+\t\t\tgoto out_destroy;\n \t\
  \t}\n-\t} else {\n-\t\twait_for_completion(&barr.done);\n \t}\n \n+\twait_for_completion(&barr.done);\n\
  +\n+out_destroy:\n \tdestroy_work_on_stack(&barr.work);\n \treturn true;\n }\n```\n"
pattern: '## Bug Pattern


  Unconditional speculative read of a concurrently updated shared field before checking
  the gating condition that makes the read safe.


  Concretely:

  - Reading work->data (a field updated by other CPUs) without synchronization and
  before verifying from_cancel, even though the value is only needed when from_cancel
  is true.

  - This unnecessary, unsynchronized read can race with writers (e.g., insert_wq_barrier
  updating work->data), triggering KCSAN data-race reports.


  Pattern in code:

  unsigned long data = *work_data_bits(work);

  if (from_cancel && use(data)) { ... }


  Correct approach: First check the gating condition (from_cancel), then read the
  shared field only when needed.'
plan: "Plan\n\n1) Program state customization\n- REGISTER_MAP_WITH_PROGRAMSTATE(SharedSpecReadMap,\
  \ const MemRegion*, const Stmt*)\n  - Key: the MemRegion of a local variable that\
  \ receives a suspicious read.\n  - Value: the Stmt (read site) where the unconditional\
  \ read happened. This lets us:\n    - Verify source order (read happens before the\
  \ if).\n    - Provide a precise note range when reporting.\n- No other traits needed\
  \ (we avoid pointer aliasing for simplicity; the pattern uses a local temp like\
  \ \u201Cdata\u201D).\n\n2) Helper predicates/utilities (small, local helpers)\n\
  - isDerefOfWorkDataBits(const Stmt *S, CheckerContext &C) -> const UnaryOperator*\n\
  \  - Use findSpecificTypeInChildren<UnaryOperator>(S) to find a UO_Deref node.\n\
  \  - If found, check its sub-expression with ExprHasName(SubExpr, \"work_data_bits\"\
  , C).\n  - Return the deref node if it matches; otherwise nullptr.\n- getStoreRegion(SVal\
  \ Loc) -> const MemRegion*\n  - Return Loc.getAsRegion().\n- conditionHasFromCancel(const\
  \ Stmt *Cond, CheckerContext &C) -> bool\n  - Return ExprHasName(cast<Expr>(Cond),\
  \ \"from_cancel\", C).\n- getTopLevelLAnd(const Stmt *Cond) -> const BinaryOperator*\n\
  \  - If Cond->IgnoreImplicit() is a BinaryOperator with opcode BO_LAnd, return it;\
  \ else nullptr.\n- findUsedSharedVarInExpr(const Expr *E, ProgramStateRef State)\
  \ -> const MemRegion*\n  - Use findSpecificTypeInChildren<DeclRefExpr>(E) to get\
  \ a DeclRefExpr (best-effort; utility returns one).\n  - From that DRE, retrieve\
  \ its region with getMemRegionFromExpr and check if it exists in SharedSpecReadMap.\n\
  \  - If not found on first try, return nullptr. (Simple and fast; good enough for\
  \ the target pattern where the single RHS identifier is \u201Cdata\u201D.)\n- isBefore(const\
  \ Stmt *A, const Stmt *B, CheckerContext &C) -> bool\n  - Compare SourceLocations\
  \ with C.getSourceManager().isBeforeInTranslationUnit(A->getBeginLoc(), B->getBeginLoc()).\n\
  \n3) Callbacks and logic\n\nA) checkBind(SVal Loc, SVal Val, const Stmt *S, CheckerContext\
  \ &C) const\n- Goal: mark a local variable when it receives an unconditional dereference\
  \ of work_data_bits(work).\n- Steps:\n  1) Get DestR = getStoreRegion(Loc). If null\
  \ or not a VarRegion, return.\n  2) Detect suspicious RHS by pattern match on S:\n\
  \     - Deref = isDerefOfWorkDataBits(S, C). If null, this bind is not our target;\
  \ erase DestR from SharedSpecReadMap if present (the variable is overwritten with\
  \ a non-suspicious value).\n     - If Deref is found, add (DestR -> Deref) to SharedSpecReadMap.\n\
  \        - Rationale: \u201Cdata = *work_data_bits(work);\u201D\n- Notes:\n  - This\
  \ catches both initialization in a DeclStmt and a later assignment, because checkBind\
  \ observes both.\n  - We keep only the most recent mapping per variable. Any subsequent\
  \ re-assignment will erase or update it.\n\nB) checkBranchCondition(const Stmt *Condition,\
  \ CheckerContext &C) const\n- Goal: detect the if (from_cancel && use(data)) shape\
  \ where data was read speculatively before the gate.\n- Steps:\n  1) Quick filter:\
  \ if not conditionHasFromCancel(Condition, C), return.\n  2) Get the top-level LAnd:\
  \ Bin = getTopLevelLAnd(Condition). If null, return.\n  3) Consider RHS = Bin->getRHS()->IgnoreImplicit().\
  \ This is where \u201Cdata\u201D typically appears in the kernel pattern.\n  4)\
  \ Find a used shared var region on RHS: UsedR = findUsedSharedVarInExpr(RHS, State).\n\
  \     - If UsedR is null, return.\n  5) Retrieve the stored read site Stmt* ReadSite\
  \ = SharedSpecReadMap[UsedR].\n     - If absent, return (no prior marked speculative\
  \ read).\n  6) Ensure correct source order: if not isBefore(ReadSite, Condition,\
  \ C), return. (Avoid flagging cases where the read is inside the gated condition.)\n\
  \  7) Report:\n     - Generate a non-fatal error node; if null, return.\n     -\
  \ Message: \"Speculative read of work->data before checking from_cancel\"\n    \
  \ - Create a BasicBugReport or PathSensitiveBugReport (short message required).\n\
  \     - Add the range of ReadSite (the deref) if possible, and highlight RHS of\
  \ the condition (optional).\n     - Emit the report.\n- Optional robustness:\n \
  \ - After reporting, erase UsedR from SharedSpecReadMap to avoid duplicate reports\
  \ at the same site on other paths.\n\n4) Minimal false-positive controls\n- Specific\
  \ read recognition: only flag when the RHS dereference is exactly of the form \"\
  *work_data_bits(...)\" via ExprHasName on the deref\u2019s sub-expression. This\
  \ anchors the checker to the intended kernel idiom.\n- Gate recognition: require\
  \ that the condition text contains \"from_cancel\".\n- Order check: ensure the read\
  \ happens earlier than the if condition.\n- Overwrite clearing: any non-suspicious\
  \ writes to the same variable erase it from the map.\n\n5) Reporting\n- BugType:\
  \ \"Speculative shared read before gate\"\n- Short message: \"Speculative read of\
  \ work->data before checking from_cancel\"\n- Explanation (one-liner in description):\
  \ \"Read '*work_data_bits(work)' is done unconditionally; it should be performed\
  \ only if from_cancel is true to avoid spurious data races.\"\n- Use std::make_unique<BasicBugReport>\
  \ (or PathSensitiveBugReport if a path note is desirable); use generateNonFatalErrorNode().\n\
  \n6) Summary of used CSA hooks and utilities\n- Program state: REGISTER_MAP_WITH_PROGRAMSTATE(SharedSpecReadMap,\
  \ const MemRegion*, const Stmt*)\n- checkBind: mark/clear the local variable when\
  \ assigned from \"*work_data_bits(...)\"\n- checkBranchCondition: detect if (from_cancel\
  \ && use(var)) and report\n- Utilities used:\n  - findSpecificTypeInChildren<UnaryOperator>\
  \ for deref detection\n  - findSpecificTypeInChildren<DeclRefExpr> for RHS var use\
  \ detection\n  - ExprHasName(...) to pinpoint \"work_data_bits\" and \"from_cancel\"\
  \n  - getMemRegionFromExpr(...) to map DeclRefExpr to MemRegion\n  - SourceManager::isBeforeInTranslationUnit(...)\
  \ for order check\n\nThis is the simplest, kernel-focused checker to catch the exact\
  \ bug pattern addressed by the patch: reading work->data via work_data_bits() speculatively\
  \ before verifying from_cancel."
refined_plan: null
repaired_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/ASTContext.h\"\n#include \"clang/AST/Expr.h\"\n#include \"\
  clang/AST/Stmt.h\"\n#include \"clang/Lex/Lexer.h\"\n\nusing namespace clang;\nusing\
  \ namespace ento;\nusing namespace taint;\n\nREGISTER_MAP_WITH_PROGRAMSTATE(SharedSpecReadMap,\
  \ const MemRegion*, const Stmt*)\n\nnamespace {\n\nclass SAGenTestChecker : public\
  \ Checker<check::Bind, check::BranchCondition> {\n   mutable std::unique_ptr<BugType>\
  \ BT;\n\n   public:\n      SAGenTestChecker() : BT(new BugType(this, \"Speculative\
  \ shared read before gate\", \"Concurrency\")) {}\n\n      void checkBind(SVal Loc,\
  \ SVal Val, const Stmt *S, CheckerContext &C) const;\n      void checkBranchCondition(const\
  \ Stmt *Condition, CheckerContext &C) const;\n\n   private:\n\n      // Helpers\n\
  \      static const MemRegion *getStoreRegion(SVal Loc);\n      static bool conditionHasFromCancel(const\
  \ Stmt *Cond, CheckerContext &C);\n      static const BinaryOperator *getTopLevelLAnd(const\
  \ Stmt *Cond);\n      static bool isBefore(const Stmt *A, const Stmt *B, CheckerContext\
  \ &C);\n\n      static const UnaryOperator *findDerefOfWorkDataBitsInStmt(const\
  \ Stmt *S, CheckerContext &C);\n      static const MemRegion *findTrackedRegionInExpr(const\
  \ Expr *E, ProgramStateRef State, CheckerContext &C);\n};\n\n// --- Helper implementations\
  \ ---\n\nconst MemRegion *SAGenTestChecker::getStoreRegion(SVal Loc) {\n  if (const\
  \ MemRegion *MR = Loc.getAsRegion()) {\n    return MR->getBaseRegion();\n  }\n \
  \ return nullptr;\n}\n\nbool SAGenTestChecker::conditionHasFromCancel(const Stmt\
  \ *Cond, CheckerContext &C) {\n  if (!Cond) return false;\n  const Expr *E = dyn_cast<Expr>(Cond);\n\
  \  if (!E) return false;\n  return ExprHasName(E, \"from_cancel\", C);\n}\n\nconst\
  \ BinaryOperator *SAGenTestChecker::getTopLevelLAnd(const Stmt *Cond) {\n  if (!Cond)\
  \ return nullptr;\n  const Expr *E = dyn_cast<Expr>(Cond);\n  if (!E) return nullptr;\n\
  \  E = E->IgnoreImplicit();\n  if (const auto *BO = dyn_cast<BinaryOperator>(E))\
  \ {\n    if (BO->getOpcode() == BO_LAnd)\n      return BO;\n  }\n  return nullptr;\n\
  }\n\nbool SAGenTestChecker::isBefore(const Stmt *A, const Stmt *B, CheckerContext\
  \ &C) {\n  if (!A || !B) return false;\n  const SourceManager &SM = C.getSourceManager();\n\
  \  return SM.isBeforeInTranslationUnit(A->getBeginLoc(), B->getBeginLoc());\n}\n\
  \nstatic const UnaryOperator *findDerefOfWorkDataBitsInStmtRec(const Stmt *S, CheckerContext\
  \ &C) {\n  if (!S) return nullptr;\n\n  if (const auto *UO = dyn_cast<UnaryOperator>(S))\
  \ {\n    if (UO->getOpcode() == UO_Deref) {\n      const Expr *Sub = UO->getSubExpr();\n\
  \      if (Sub && ExprHasName(Sub, \"work_data_bits\", C))\n        return UO;\n\
  \    }\n  }\n\n  for (const Stmt *Child : S->children()) {\n    if (const UnaryOperator\
  \ *Res = findDerefOfWorkDataBitsInStmtRec(Child, C))\n      return Res;\n  }\n \
  \ return nullptr;\n}\n\nconst UnaryOperator *SAGenTestChecker::findDerefOfWorkDataBitsInStmt(const\
  \ Stmt *S, CheckerContext &C) {\n  return findDerefOfWorkDataBitsInStmtRec(S, C);\n\
  }\n\nstatic const MemRegion *findTrackedRegionInExprRec(const Expr *E, ProgramStateRef\
  \ State, CheckerContext &C) {\n  if (!E) return nullptr;\n\n  // Try current expression\
  \ if it's a DeclRefExpr\n  if (const auto *DRE = dyn_cast<DeclRefExpr>(E->IgnoreParenCasts()))\
  \ {\n    if (const MemRegion *MR = getMemRegionFromExpr(DRE, C)) {\n      MR = MR->getBaseRegion();\n\
  \      if (MR) {\n        if (State->get<SharedSpecReadMap>(MR))\n          return\
  \ MR;\n      }\n    }\n  }\n\n  // Recurse into children\n  for (const Stmt *Child\
  \ : E->children()) {\n    if (const auto *CE = dyn_cast_or_null<Expr>(Child)) {\n\
  \      if (const MemRegion *Found = findTrackedRegionInExprRec(CE, State, C))\n\
  \        return Found;\n    }\n  }\n  return nullptr;\n}\n\nconst MemRegion *SAGenTestChecker::findTrackedRegionInExpr(const\
  \ Expr *E, ProgramStateRef State, CheckerContext &C) {\n  return findTrackedRegionInExprRec(E,\
  \ State, C);\n}\n\n// --- Checker callbacks ---\n\nvoid SAGenTestChecker::checkBind(SVal\
  \ Loc, SVal /*Val*/, const Stmt *S, CheckerContext &C) const {\n  ProgramStateRef\
  \ State = C.getState();\n\n  const MemRegion *DestR = getStoreRegion(Loc);\n  if\
  \ (!DestR)\n    return;\n\n  // Only track simple variable regions (local/param)\n\
  \  if (!isa<VarRegion>(DestR))\n    return;\n\n  // Check if RHS (present in the\
  \ StoreE statement) contains \"*work_data_bits(...)\"\n  const UnaryOperator *Deref\
  \ = findDerefOfWorkDataBitsInStmt(S, C);\n\n  if (Deref) {\n    // Mark this variable\
  \ as holding a speculative read from work->data\n    State = State->set<SharedSpecReadMap>(DestR,\
  \ cast<Stmt>(Deref));\n    C.addTransition(State);\n    return;\n  }\n\n  // Not\
  \ assigned from work_data_bits deref; clear any previous mark\n  if (State->get<SharedSpecReadMap>(DestR))\
  \ {\n    State = State->remove<SharedSpecReadMap>(DestR);\n    C.addTransition(State);\n\
  \  }\n}\n\nvoid SAGenTestChecker::checkBranchCondition(const Stmt *Condition, CheckerContext\
  \ &C) const {\n  ProgramStateRef State = C.getState();\n\n  if (!conditionHasFromCancel(Condition,\
  \ C))\n    return;\n\n  const BinaryOperator *LAnd = getTopLevelLAnd(Condition);\n\
  \  if (!LAnd)\n    return;\n\n  const Expr *RHS = dyn_cast<Expr>(LAnd->getRHS());\n\
  \  if (!RHS)\n    return;\n\n  const MemRegion *UsedR = findTrackedRegionInExpr(RHS,\
  \ State, C);\n  if (!UsedR)\n    return;\n\n  const Stmt *const *ReadSitePtr = State->get<SharedSpecReadMap>(UsedR);\n\
  \  if (!ReadSitePtr)\n    return;\n  const Stmt *ReadSite = *ReadSitePtr;\n\n  //\
  \ Ensure the speculative read happens before this condition in source order\n  if\
  \ (!isBefore(ReadSite, Condition, C))\n    return;\n\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n\
  \  if (!N)\n    return;\n\n  auto R = std::make_unique<PathSensitiveBugReport>(\n\
  \      *BT, \"Speculative read of work->data before checking from_cancel\", N);\n\
  \n  // Highlight the dereference '*work_data_bits(...)'\n  R->addRange(ReadSite->getSourceRange());\n\
  \  C.emitReport(std::move(R));\n\n  // Optional: prevent duplicate reports for the\
  \ same variable along other paths\n  State = State->remove<SharedSpecReadMap>(UsedR);\n\
  \  C.addTransition(State);\n}\n\n} // end anonymous namespace\n\nextern \"C\" void\
  \ clang_registerCheckers(CheckerRegistry &registry) {\n  registry.addChecker<SAGenTestChecker>(\n\
  \      \"custom.SAGenTestChecker\",\n      \"Detects read of work->data before checking\
  \ from_cancel\",\n      \"\");\n}\n\nextern \"C\" const char clang_analyzerAPIVersionString[]\
  \ =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
tn_score: 1
tp_score: 0
