_base_result_dir: /scratch/chenyuan-data/knighter-dev/result-gpt-5-0814
commit_id: 3b0daecfeac0103aba8b293df07a0cbaf8b43f29
commit_type: Integer-Overflow
index: 4
initial_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/Expr.h\"\n#include \"clang/Lex/Lexer.h\"\n\nusing namespace\
  \ clang;\nusing namespace ento;\nusing namespace taint;\n\n// No custom program\
  \ states needed.\n\nnamespace {\n\nclass SAGenTestChecker : public Checker<check::PreCall>\
  \ {\n   mutable std::unique_ptr<BugType> BT;\n\n   public:\n      SAGenTestChecker()\
  \ : BT(new BugType(this, \"Overflow-prone kmalloc/kzalloc size\", \"Memory Management\"\
  )) {}\n\n      void checkPreCall(const CallEvent &Call, CheckerContext &C) const;\n\
  \n   private:\n\n      // Helper: match function name reliably using ExprHasName\
  \ as suggested.\n      bool calleeNameIs(const CallEvent &Call, StringRef Name,\
  \ CheckerContext &C) const {\n        const Expr *OE = Call.getOriginExpr();\n \
  \       if (OE && ExprHasName(OE, Name, C))\n          return true;\n        if\
  \ (const IdentifierInfo *II = Call.getCalleeIdentifier())\n          return II->getName()\
  \ == Name;\n        return false;\n      }\n\n      bool isOverflowProneAllocator(const\
  \ CallEvent &Call, CheckerContext &C) const {\n        return calleeNameIs(Call,\
  \ \"kmalloc\", C) ||\n               calleeNameIs(Call, \"kzalloc\", C) ||\n   \
  \            calleeNameIs(Call, \"kmalloc_node\", C) ||\n               calleeNameIs(Call,\
  \ \"kzalloc_node\", C);\n      }\n\n      bool isOverflowCheckedAllocator(const\
  \ CallEvent &Call, CheckerContext &C) const {\n        return calleeNameIs(Call,\
  \ \"kcalloc\", C) ||\n               calleeNameIs(Call, \"kvcalloc\", C) ||\n  \
  \             calleeNameIs(Call, \"kcalloc_node\", C) ||\n               calleeNameIs(Call,\
  \ \"kvcalloc_node\", C) ||\n               calleeNameIs(Call, \"kmalloc_array\"\
  , C);\n      }\n\n      bool isConstExpr(const Expr *E, CheckerContext &C) const\
  \ {\n        if (!E) return false;\n        llvm::APSInt Tmp;\n        return EvaluateExprToInt(Tmp,\
  \ E, C);\n      }\n\n      // Find a multiplication in SizeArg and split operands:\n\
  \      // one must contain sizeof(...), the other is the \"count\".\n      bool\
  \ findMulAndSplit(const Expr *SizeArg,\n                           const BinaryOperator\
  \ *&MulBO,\n                           const Expr *&ElementSizeExpr,\n         \
  \                  const Expr *&CountExpr,\n                           CheckerContext\
  \ &C) const {\n        if (!SizeArg) return false;\n        MulBO = findSpecificTypeInChildren<BinaryOperator>(SizeArg);\n\
  \        if (!MulBO || MulBO->getOpcode() != BO_Mul)\n          return false;\n\n\
  \        const Expr *L = MulBO->getLHS();\n        const Expr *R = MulBO->getRHS();\n\
  \        if (!L || !R) return false;\n\n        const auto *LSize = findSpecificTypeInChildren<UnaryExprOrTypeTraitExpr>(L);\n\
  \        const auto *RSize = findSpecificTypeInChildren<UnaryExprOrTypeTraitExpr>(R);\n\
  \n        bool LHasSize = LSize && LSize->getKind() == UETT_SizeOf;\n        bool\
  \ RHasSize = RSize && RSize->getKind() == UETT_SizeOf;\n\n        // Require sizeof\
  \ to be clearly on exactly one side.\n        if (LHasSize == RHasSize)\n      \
  \    return false;\n\n        if (LHasSize) {\n          ElementSizeExpr = L;\n\
  \          CountExpr = R;\n        } else {\n          ElementSizeExpr = R;\n  \
  \        CountExpr = L;\n        }\n        return true;\n      }\n\n      // Optional\
  \ suppression using symbolic upper bound reasoning.\n      bool proveNoOverflow(const\
  \ CallEvent &Call,\n                           const Expr *ElementSizeExpr,\n  \
  \                         const Expr *CountExpr,\n                           CheckerContext\
  \ &C) const {\n        if (!ElementSizeExpr || !CountExpr)\n          return false;\n\
  \n        // Get element size as integer.\n        llvm::APSInt ElemSizeAPS;\n \
  \       if (!EvaluateExprToInt(ElemSizeAPS, ElementSizeExpr, C))\n          return\
  \ false; // fail-open\n\n        uint64_t ElemSizeZ = ElemSizeAPS.getZExtValue();\n\
  \        if (ElemSizeZ == 0)\n          return false; // pathological, fail-open\n\
  \n        // Try to obtain a symbol for CountExpr.\n        ProgramStateRef State\
  \ = C.getState();\n        SVal CountSV = State->getSVal(CountExpr, C.getLocationContext());\n\
  \        SymbolRef CountSym = CountSV.getAsSymbol();\n        if (!CountSym)\n \
  \         return false; // fail-open\n\n        const llvm::APSInt *MaxCountAPS\
  \ = inferSymbolMaxVal(CountSym, C);\n        if (!MaxCountAPS)\n          return\
  \ false; // fail-open\n\n        // Compute maximum allowed count = SIZE_MAX / ElemSize.\n\
  \        unsigned W = C.getASTContext().getTypeSize(Call.getArgExpr(0)->getType());\n\
  \        if (W == 0)\n          return false;\n\n        llvm::APInt SizeMaxAP(W,\
  \ 0);\n        SizeMaxAP.setAllBits(); // SIZE_MAX for given width\n\n        llvm::APInt\
  \ ElemAP(W, ElemSizeZ); // zero-extended into width W\n\n        if (ElemAP == 0)\n\
  \          return false;\n\n        llvm::APInt BoundAP = SizeMaxAP.udiv(ElemAP);\n\
  \n        uint64_t BoundZ = BoundAP.getLimitedValue(UINT64_MAX);\n        uint64_t\
  \ MaxCountZ = MaxCountAPS->getZExtValue(); // best-effort\n\n        // If the maximum\
  \ possible count fits into the safe bound, suppress warning.\n        return MaxCountZ\
  \ <= BoundZ;\n      }\n\n      void report(const CallEvent &Call, const Stmt *LocStmt,\
  \ CheckerContext &C) const {\n        ExplodedNode *N = C.generateNonFatalErrorNode();\n\
  \        if (!N)\n          return;\n\n        auto R = std::make_unique<PathSensitiveBugReport>(\n\
  \          *BT,\n          \"Use kcalloc/kvcalloc(count, size) instead of kmalloc/kzalloc(count*size);\
  \ multiplication may overflow.\",\n          N);\n\n        if (LocStmt)\n     \
  \     R->addRange(LocStmt->getSourceRange());\n\n        C.emitReport(std::move(R));\n\
  \      }\n};\n\nvoid SAGenTestChecker::checkPreCall(const CallEvent &Call, CheckerContext\
  \ &C) const {\n  // Skip if already using overflow-checked helpers.\n  if (isOverflowCheckedAllocator(Call,\
  \ C))\n    return;\n\n  // Focus on kmalloc/kzalloc and their _node variants.\n\
  \  if (!isOverflowProneAllocator(Call, C))\n    return;\n\n  if (Call.getNumArgs()\
  \ == 0)\n    return;\n\n  const Expr *SizeArg = Call.getArgExpr(0);\n  if (!SizeArg)\n\
  \    return;\n\n  // Require multiplication present.\n  const BinaryOperator *MulBO\
  \ = nullptr;\n  const Expr *ElementSizeExpr = nullptr;\n  const Expr *CountExpr\
  \ = nullptr;\n  if (!findMulAndSplit(SizeArg, MulBO, ElementSizeExpr, CountExpr,\
  \ C))\n    return;\n\n  // Require sizeof(...) to be present in exactly one operand\
  \ (ensured by findMulAndSplit).\n\n  // Skip if the entire size is a compile-time\
  \ constant.\n  if (isConstExpr(SizeArg, C))\n    return;\n\n  // Skip if the count\
  \ is a compile-time constant (to reduce noise on fixed sizes).\n  if (isConstExpr(CountExpr,\
  \ C))\n    return;\n\n  // Optional suppression: if we can prove no overflow can\
  \ happen for count*elem_size.\n  if (proveNoOverflow(Call, ElementSizeExpr, CountExpr,\
  \ C))\n    return;\n\n  // Report at the multiplication site if possible.\n  const\
  \ Stmt *LocStmt = MulBO ? static_cast<const Stmt*>(MulBO) : static_cast<const Stmt*>(SizeArg);\n\
  \  report(Call, LocStmt, C);\n}\n\n} // end anonymous namespace\n\nextern \"C\"\
  \ void clang_registerCheckers(CheckerRegistry &registry) {\n  registry.addChecker<SAGenTestChecker>(\n\
  \      \"custom.SAGenTestChecker\",\n      \"Detects kmalloc/kzalloc with size computed\
  \ as count*element_size; suggest kcalloc/kvcalloc to avoid integer overflow\",\n\
  \      \"\");\n}\n\nextern \"C\" const char clang_analyzerAPIVersionString[] =\n\
  \    CLANG_ANALYZER_API_VERSION_STRING;\n"
patch: "## Patch Description\n\namdkfd: use calloc instead of kzalloc to avoid integer\
  \ overflow\n\nThis uses calloc instead of doing the multiplication which might\n\
  overflow.\n\nCc: stable@vger.kernel.org\nSigned-off-by: Dave Airlie <airlied@redhat.com>\n\
  \n## Buggy Code\n\n```c\n// Function: kfd_ioctl_get_process_apertures_new in drivers/gpu/drm/amd/amdkfd/kfd_chardev.c\n\
  static int kfd_ioctl_get_process_apertures_new(struct file *filp,\n\t\t\t\tstruct\
  \ kfd_process *p, void *data)\n{\n\tstruct kfd_ioctl_get_process_apertures_new_args\
  \ *args = data;\n\tstruct kfd_process_device_apertures *pa;\n\tint ret;\n\tint i;\n\
  \n\tdev_dbg(kfd_device, \"get apertures for PASID 0x%x\", p->pasid);\n\n\tif (args->num_of_nodes\
  \ == 0) {\n\t\t/* Return number of nodes, so that user space can alloacate\n\t\t\
  \ * sufficient memory\n\t\t */\n\t\tmutex_lock(&p->mutex);\n\t\targs->num_of_nodes\
  \ = p->n_pdds;\n\t\tgoto out_unlock;\n\t}\n\n\t/* Fill in process-aperture information\
  \ for all available\n\t * nodes, but not more than args->num_of_nodes as that is\n\
  \t * the amount of memory allocated by user\n\t */\n\tpa = kzalloc((sizeof(struct\
  \ kfd_process_device_apertures) *\n\t\t\t\targs->num_of_nodes), GFP_KERNEL);\n\t\
  if (!pa)\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&p->mutex);\n\n\tif (!p->n_pdds) {\n\
  \t\targs->num_of_nodes = 0;\n\t\tkfree(pa);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Run\
  \ over all pdd of the process */\n\tfor (i = 0; i < min(p->n_pdds, args->num_of_nodes);\
  \ i++) {\n\t\tstruct kfd_process_device *pdd = p->pdds[i];\n\n\t\tpa[i].gpu_id =\
  \ pdd->dev->id;\n\t\tpa[i].lds_base = pdd->lds_base;\n\t\tpa[i].lds_limit = pdd->lds_limit;\n\
  \t\tpa[i].gpuvm_base = pdd->gpuvm_base;\n\t\tpa[i].gpuvm_limit = pdd->gpuvm_limit;\n\
  \t\tpa[i].scratch_base = pdd->scratch_base;\n\t\tpa[i].scratch_limit = pdd->scratch_limit;\n\
  \n\t\tdev_dbg(kfd_device,\n\t\t\t\"gpu id %u\\n\", pdd->dev->id);\n\t\tdev_dbg(kfd_device,\n\
  \t\t\t\"lds_base %llX\\n\", pdd->lds_base);\n\t\tdev_dbg(kfd_device,\n\t\t\t\"lds_limit\
  \ %llX\\n\", pdd->lds_limit);\n\t\tdev_dbg(kfd_device,\n\t\t\t\"gpuvm_base %llX\\\
  n\", pdd->gpuvm_base);\n\t\tdev_dbg(kfd_device,\n\t\t\t\"gpuvm_limit %llX\\n\",\
  \ pdd->gpuvm_limit);\n\t\tdev_dbg(kfd_device,\n\t\t\t\"scratch_base %llX\\n\", pdd->scratch_base);\n\
  \t\tdev_dbg(kfd_device,\n\t\t\t\"scratch_limit %llX\\n\", pdd->scratch_limit);\n\
  \t}\n\tmutex_unlock(&p->mutex);\n\n\targs->num_of_nodes = i;\n\tret = copy_to_user(\n\
  \t\t\t(void __user *)args->kfd_process_device_apertures_ptr,\n\t\t\tpa,\n\t\t\t\
  (i * sizeof(struct kfd_process_device_apertures)));\n\tkfree(pa);\n\treturn ret\
  \ ? -EFAULT : 0;\n\nout_unlock:\n\tmutex_unlock(&p->mutex);\n\treturn 0;\n}\n```\n\
  \n## Bug Fix Patch\n\n```diff\ndiff --git a/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c\
  \ b/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c\nindex f9631f4b1a02..55aa74cbc532 100644\n\
  --- a/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c\n+++ b/drivers/gpu/drm/amd/amdkfd/kfd_chardev.c\n\
  @@ -779,8 +779,8 @@ static int kfd_ioctl_get_process_apertures_new(struct file *filp,\n\
  \ \t * nodes, but not more than args->num_of_nodes as that is\n \t * the amount\
  \ of memory allocated by user\n \t */\n-\tpa = kzalloc((sizeof(struct kfd_process_device_apertures)\
  \ *\n-\t\t\t\targs->num_of_nodes), GFP_KERNEL);\n+\tpa = kcalloc(args->num_of_nodes,\
  \ sizeof(struct kfd_process_device_apertures),\n+\t\t     GFP_KERNEL);\n \tif (!pa)\n\
  \ \t\treturn -ENOMEM;\n \n```\n"
pattern: '## Bug Pattern


  Manually computing the allocation size for an array as count * element_size when
  calling kmalloc/kzalloc, where count can be large or user-controlled, leading to
  integer overflow and under-allocation. Subsequent writes using the intended count
  then overrun the allocated buffer. Correct approach is to use kcalloc/kvcalloc(count,
  element_size, GFP_KERNEL), which performs overflow-checked multiplication.'
plan: "1) Program state\n- No custom program state is needed. The detection can be\
  \ done purely at call sites.\n\n2) Callbacks and implementation\n\n- checkPreCall\
  \ (core detection)\n  - Goal: Flag calls to kmalloc/kzalloc-family that pass a size\
  \ argument computed by multiplication (count * element_size), which is overflow-prone,\
  \ and recommend using kcalloc/kvcalloc.\n  - Steps:\n    1) Identify target allocators:\n\
  \       - Obtain callee name via Call.getCalleeIdentifier()->getName().\n      \
  \ - Match against:\n         - kmalloc, kzalloc\n         - kmalloc_node, kzalloc_node\n\
  \         - (Do not warn for kcalloc/kvcalloc/\u2026_array variants; those are already\
  \ overflow-safe.)\n    2) Extract the size argument:\n       - For kmalloc/kzalloc\
  \ and their _node variants, the first argument is the size expression: const Expr\
  \ *SizeArg = Call.getArgExpr(0).\n       - If SizeArg is null, return.\n    3) Find\
  \ a multiplication in SizeArg:\n       - Use findSpecificTypeInChildren<BinaryOperator>(SizeArg)\
  \ and check op == BO_Mul.\n       - If not a multiplication, do nothing.\n    4)\
  \ Ensure one operand is a sizeof(...) expression:\n       - Within the found BinaryOperator\
  \ MulBO, locate a UnaryExprOrTypeTraitExpr with kind UETT_SizeOf using findSpecificTypeInChildren<UnaryExprOrTypeTraitExpr>(MulBO).\n\
  \       - If no sizeof(...) found, return (to reduce false positives).\n       -\
  \ Determine operands:\n         - Let L = MulBO->getLHS()->IgnoreParenImpCasts()\n\
  \         - Let R = MulBO->getRHS()->IgnoreParenImpCasts()\n         - If sizeof\
  \ is found within L but not R, set ElementSizeExpr = L, CountExpr = R; if in R but\
  \ not L, swap.\n         - If sizeof is found in both or neither side clearly, return\
  \ (be conservative).\n    5) Filter out trivial constants:\n       - If EvaluateExprToInt\
  \ returns true for CountExpr, it\u2019s a compile-time constant. Skip to avoid noisy\
  \ reports on fixed-size allocations.\n       - If EvaluateExprToInt on the entire\
  \ SizeArg succeeds, skip (fully constant size).\n    6) Optional suppression using\
  \ symbolic upper bound (if easy to compute):\n       - Try to get a symbolic value\
  \ for CountExpr: SVal SV = C.getSVal(CountExpr); SymbolRef Sym = SV.getAsSymbol();\n\
  \       - If Sym exists:\n         - Retrieve max bound: const llvm::APSInt *MaxCount\
  \ = inferSymbolMaxVal(Sym, C);\n         - Get element size as integer: llvm::APSInt\
  \ ElemSize; EvaluateExprToInt(ElemSize, ElementSizeExpr, C).\n         - Compute\
  \ size type width: unsigned W = C.getASTContext().getTypeSize(Call.getArgExpr(0)->getType());\n\
  \         - Construct SIZE_MAX: llvm::APSInt SizeMax(W, /*Unsigned*/true); SizeMax.setAllBits();\n\
  \         - Compute Bound = SizeMax / ElemSize; if MaxCount exists and *MaxCount\
  \ <= Bound, skip warning.\n       - If any of these steps fail, proceed with warning\
  \ (fail-open).\n    7) Emit report:\n       - Create a non-fatal error node: ExplodedNode\
  \ *N = C.generateNonFatalErrorNode();\n       - Message: \"kmalloc/kzalloc with\
  \ size as count*element_size; use kcalloc/kvcalloc to avoid overflow.\"\n      \
  \ - Use the multiplication operator (MulBO) or SizeArg as the report location.\n\
  \       - Emit: C.emitReport(std::make_unique<PathSensitiveBugReport>(...)).\n\n\
  - No other callbacks are required.\n\n3) Helper routines (internal to the checker)\n\
  - bool isOverflowProneAllocator(const CallEvent &Call):\n  - Returns true if callee\
  \ is one of {kmalloc, kzalloc, kmalloc_node, kzalloc_node}.\n- bool isAlreadyOverflowCheckedAllocator(const\
  \ CallEvent &Call):\n  - Returns true if callee is one of {kcalloc, kvcalloc, kmalloc_array,\
  \ kcalloc_node, kvcalloc_node}.\n- bool findMulAndSplit(const Expr *SizeArg, const\
  \ BinaryOperator *&MulBO, const Expr *&ElementSizeExpr, const Expr *&CountExpr,\
  \ CheckerContext &C):\n  - Finds a BO_Mul and identifies which side is sizeof(...)\
  \ and which is the count, as described above.\n- bool isConstExpr(const Expr *E,\
  \ CheckerContext &C):\n  - Wrapper using EvaluateExprToInt.\n\n4) Reporting\n- Use\
  \ a single, concise message:\n  - \"Use kcalloc/kvcalloc(count, size) instead of\
  \ kmalloc/kzalloc(count*size); multiplication may overflow.\"\n- Point to the multiplication\
  \ site if possible for clarity.\n\n5) Notes and false-positive control\n- Requiring\
  \ a sizeof(...) in one operand and rejecting compile-time-constant CountExpr significantly\
  \ reduces noise.\n- Optional: If you successfully infer a tight max bound for the\
  \ count (inferSymbolMaxVal) that proves no overflow is possible for the given element\
  \ size, suppress the warning.\n- Do not warn for calls already using kcalloc/kvcalloc\
  \ or *_array helpers."
refined_plan: null
repaired_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/Expr.h\"\n#include \"clang/Lex/Lexer.h\"\n\nusing namespace\
  \ clang;\nusing namespace ento;\nusing namespace taint;\n\n// No custom program\
  \ states needed.\n\nnamespace {\n\nclass SAGenTestChecker : public Checker<check::PreCall>\
  \ {\n   mutable std::unique_ptr<BugType> BT;\n\n   public:\n      SAGenTestChecker()\
  \ : BT(new BugType(this, \"Overflow-prone kmalloc/kzalloc size\", \"Memory Management\"\
  )) {}\n\n      void checkPreCall(const CallEvent &Call, CheckerContext &C) const;\n\
  \n   private:\n\n      // Helper: match function name reliably using ExprHasName\
  \ as suggested.\n      bool calleeNameIs(const CallEvent &Call, StringRef Name,\
  \ CheckerContext &C) const {\n        const Expr *OE = Call.getOriginExpr();\n \
  \       if (OE && ExprHasName(OE, Name, C))\n          return true;\n        if\
  \ (const IdentifierInfo *II = Call.getCalleeIdentifier())\n          return II->getName()\
  \ == Name;\n        return false;\n      }\n\n      bool isOverflowProneAllocator(const\
  \ CallEvent &Call, CheckerContext &C) const {\n        return calleeNameIs(Call,\
  \ \"kmalloc\", C) ||\n               calleeNameIs(Call, \"kzalloc\", C) ||\n   \
  \            calleeNameIs(Call, \"kmalloc_node\", C) ||\n               calleeNameIs(Call,\
  \ \"kzalloc_node\", C);\n      }\n\n      bool isOverflowCheckedAllocator(const\
  \ CallEvent &Call, CheckerContext &C) const {\n        return calleeNameIs(Call,\
  \ \"kcalloc\", C) ||\n               calleeNameIs(Call, \"kvcalloc\", C) ||\n  \
  \             calleeNameIs(Call, \"kcalloc_node\", C) ||\n               calleeNameIs(Call,\
  \ \"kvcalloc_node\", C) ||\n               calleeNameIs(Call, \"kmalloc_array\"\
  , C);\n      }\n\n      bool isConstExpr(const Expr *E, CheckerContext &C) const\
  \ {\n        if (!E) return false;\n        llvm::APSInt Tmp;\n        return EvaluateExprToInt(Tmp,\
  \ E, C);\n      }\n\n      // Find a multiplication in SizeArg and split operands:\n\
  \      // one must contain sizeof(...), the other is the \"count\".\n      bool\
  \ findMulAndSplit(const Expr *SizeArg,\n                           const BinaryOperator\
  \ *&MulBO,\n                           const Expr *&ElementSizeExpr,\n         \
  \                  const Expr *&CountExpr,\n                           CheckerContext\
  \ &C) const {\n        if (!SizeArg) return false;\n        MulBO = findSpecificTypeInChildren<BinaryOperator>(SizeArg);\n\
  \        if (!MulBO || MulBO->getOpcode() != BO_Mul)\n          return false;\n\n\
  \        const Expr *L = MulBO->getLHS();\n        const Expr *R = MulBO->getRHS();\n\
  \        if (!L || !R) return false;\n\n        const auto *LSize = findSpecificTypeInChildren<UnaryExprOrTypeTraitExpr>(L);\n\
  \        const auto *RSize = findSpecificTypeInChildren<UnaryExprOrTypeTraitExpr>(R);\n\
  \n        bool LHasSize = LSize && LSize->getKind() == UETT_SizeOf;\n        bool\
  \ RHasSize = RSize && RSize->getKind() == UETT_SizeOf;\n\n        // Require sizeof\
  \ to be clearly on exactly one side.\n        if (LHasSize == RHasSize)\n      \
  \    return false;\n\n        if (LHasSize) {\n          ElementSizeExpr = L;\n\
  \          CountExpr = R;\n        } else {\n          ElementSizeExpr = R;\n  \
  \        CountExpr = L;\n        }\n        return true;\n      }\n\n      // Optional\
  \ suppression using symbolic upper bound reasoning.\n      bool proveNoOverflow(const\
  \ CallEvent &Call,\n                           const Expr *ElementSizeExpr,\n  \
  \                         const Expr *CountExpr,\n                           CheckerContext\
  \ &C) const {\n        if (!ElementSizeExpr || !CountExpr)\n          return false;\n\
  \n        // Get element size as integer.\n        llvm::APSInt ElemSizeAPS;\n \
  \       if (!EvaluateExprToInt(ElemSizeAPS, ElementSizeExpr, C))\n          return\
  \ false; // fail-open\n\n        uint64_t ElemSizeZ = ElemSizeAPS.getZExtValue();\n\
  \        if (ElemSizeZ == 0)\n          return false; // pathological, fail-open\n\
  \n        // Try to obtain a symbol for CountExpr.\n        ProgramStateRef State\
  \ = C.getState();\n        SVal CountSV = State->getSVal(CountExpr, C.getLocationContext());\n\
  \        SymbolRef CountSym = CountSV.getAsSymbol();\n        if (!CountSym)\n \
  \         return false; // fail-open\n\n        const llvm::APSInt *MaxCountAPS\
  \ = inferSymbolMaxVal(CountSym, C);\n        if (!MaxCountAPS)\n          return\
  \ false; // fail-open\n\n        // Compute maximum allowed count = SIZE_MAX / ElemSize.\n\
  \        unsigned W = C.getASTContext().getTypeSize(Call.getArgExpr(0)->getType());\n\
  \        if (W == 0)\n          return false;\n\n        llvm::APInt SizeMaxAP(W,\
  \ 0);\n        SizeMaxAP.setAllBits(); // SIZE_MAX for given width\n\n        llvm::APInt\
  \ ElemAP(W, ElemSizeZ); // zero-extended into width W\n\n        if (ElemAP == 0)\n\
  \          return false;\n\n        llvm::APInt BoundAP = SizeMaxAP.udiv(ElemAP);\n\
  \n        uint64_t BoundZ = BoundAP.getLimitedValue(UINT64_MAX);\n        uint64_t\
  \ MaxCountZ = MaxCountAPS->getZExtValue(); // best-effort\n\n        // If the maximum\
  \ possible count fits into the safe bound, suppress warning.\n        return MaxCountZ\
  \ <= BoundZ;\n      }\n\n      void report(const CallEvent &Call, const Stmt *LocStmt,\
  \ CheckerContext &C) const {\n        ExplodedNode *N = C.generateNonFatalErrorNode();\n\
  \        if (!N)\n          return;\n\n        auto R = std::make_unique<PathSensitiveBugReport>(\n\
  \          *BT,\n          \"Use kcalloc/kvcalloc(count, size) instead of kmalloc/kzalloc(count*size);\
  \ multiplication may overflow.\",\n          N);\n\n        if (LocStmt)\n     \
  \     R->addRange(LocStmt->getSourceRange());\n\n        C.emitReport(std::move(R));\n\
  \      }\n};\n\nvoid SAGenTestChecker::checkPreCall(const CallEvent &Call, CheckerContext\
  \ &C) const {\n  // Skip if already using overflow-checked helpers.\n  if (isOverflowCheckedAllocator(Call,\
  \ C))\n    return;\n\n  // Focus on kmalloc/kzalloc and their _node variants.\n\
  \  if (!isOverflowProneAllocator(Call, C))\n    return;\n\n  if (Call.getNumArgs()\
  \ == 0)\n    return;\n\n  const Expr *SizeArg = Call.getArgExpr(0);\n  if (!SizeArg)\n\
  \    return;\n\n  // Require multiplication present.\n  const BinaryOperator *MulBO\
  \ = nullptr;\n  const Expr *ElementSizeExpr = nullptr;\n  const Expr *CountExpr\
  \ = nullptr;\n  if (!findMulAndSplit(SizeArg, MulBO, ElementSizeExpr, CountExpr,\
  \ C))\n    return;\n\n  // Require sizeof(...) to be present in exactly one operand\
  \ (ensured by findMulAndSplit).\n\n  // Skip if the entire size is a compile-time\
  \ constant.\n  if (isConstExpr(SizeArg, C))\n    return;\n\n  // Skip if the count\
  \ is a compile-time constant (to reduce noise on fixed sizes).\n  if (isConstExpr(CountExpr,\
  \ C))\n    return;\n\n  // Optional suppression: if we can prove no overflow can\
  \ happen for count*elem_size.\n  if (proveNoOverflow(Call, ElementSizeExpr, CountExpr,\
  \ C))\n    return;\n\n  // Report at the multiplication site if possible.\n  const\
  \ Stmt *LocStmt = MulBO ? static_cast<const Stmt*>(MulBO) : static_cast<const Stmt*>(SizeArg);\n\
  \  report(Call, LocStmt, C);\n}\n\n} // end anonymous namespace\n\nextern \"C\"\
  \ void clang_registerCheckers(CheckerRegistry &registry) {\n  registry.addChecker<SAGenTestChecker>(\n\
  \      \"custom.SAGenTestChecker\",\n      \"Detects kmalloc/kzalloc with size computed\
  \ as count*element_size; suggest kcalloc/kvcalloc to avoid integer overflow\",\n\
  \      \"\");\n}\n\nextern \"C\" const char clang_analyzerAPIVersionString[] =\n\
  \    CLANG_ANALYZER_API_VERSION_STRING;\n"
tn_score: 1
tp_score: 0
