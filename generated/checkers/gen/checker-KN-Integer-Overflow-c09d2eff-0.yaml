_base_result_dir: /scratch/chenyuan-data/knighter-dev/result-gpt-5-0814
commit_id: c09d2eff81a997c169e0cacacd6b60c5e3aa33f2
commit_type: Integer-Overflow
index: 0
initial_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/ASTContext.h\"\n#include \"clang/AST/Expr.h\"\n#include \"\
  clang/AST/ExprCXX.h\"\n#include \"clang/AST/OperationKinds.h\"\n#include \"clang/AST/Stmt.h\"\
  \n#include \"clang/Basic/SourceManager.h\"\n#include \"clang/Lex/Lexer.h\"\n\nusing\
  \ namespace clang;\nusing namespace ento;\nusing namespace taint;\n\n// No custom\
  \ program state needed.\n\nnamespace {\n\nclass SAGenTestChecker : public Checker<check::PostStmt<BinaryOperator>>\
  \ {\n   mutable std::unique_ptr<BugType> BT;\n\npublic:\n  SAGenTestChecker()\n\
  \      : BT(new BugType(this, \"32-bit multiply widened to 64-bit\",\n         \
  \              \"Integer Overflow\")) {}\n\n  void checkPostStmt(const BinaryOperator\
  \ *B, CheckerContext &C) const;\n\nprivate:\n  // Helpers\n  static unsigned getIntWidth(QualType\
  \ T, CheckerContext &C) {\n    return C.getASTContext().getIntWidth(T);\n  }\n\n\
  \  static bool isInt64OrWider(QualType T, CheckerContext &C) {\n    return T->isIntegerType()\
  \ && getIntWidth(T, C) >= 64;\n  }\n\n  static bool isIntegerType(const Expr *E)\
  \ {\n    if (!E) return false;\n    return E->getType()->isIntegerType();\n  }\n\
  \n  // Determine if the expression result is used in a 64-bit integer context.\n\
  \  bool isWidenedUseTo64(const Expr *E, CheckerContext &C) const {\n    if (!E)\
  \ return false;\n\n    // 1) Look for an implicit cast to 64-bit integer.\n    if\
  \ (const auto *ICE = findSpecificTypeInParents<ImplicitCastExpr>(E, C)) {\n    \
  \  QualType DestTy = ICE->getType();\n      if (isInt64OrWider(DestTy, C))\n   \
  \     return true;\n    }\n\n    // 2) Look for a C-style cast to 64-bit\n    if\
  \ (const auto *CS = findSpecificTypeInParents<CStyleCastExpr>(E, C)) {\n      QualType\
  \ DestTy = CS->getTypeAsWritten();\n      if (isInt64OrWider(DestTy, C))\n     \
  \   return true;\n    }\n\n    // 3) Look for assignment where LHS is 64-bit\n \
  \   if (const auto *PAssn = findSpecificTypeInParents<BinaryOperator>(E, C)) {\n\
  \      if (PAssn->isAssignmentOp()) {\n        const Expr *LHS = PAssn->getLHS();\n\
  \        if (LHS && isInt64OrWider(LHS->getType(), C))\n          return true;\n\
  \      }\n    }\n\n    // 4) Look for return statement where function returns 64-bit\n\
  \    if (findSpecificTypeInParents<ReturnStmt>(E, C)) {\n      const auto *D = dyn_cast_or_null<FunctionDecl>(C.getLocationContext()->getDecl());\n\
  \      if (D) {\n        QualType RetTy = D->getReturnType();\n        if (isInt64OrWider(RetTy,\
  \ C))\n          return true;\n      }\n    }\n\n    // 5) Look for function call\
  \ argument where the parameter is 64-bit\n    if (const auto *Call = findSpecificTypeInParents<CallExpr>(E,\
  \ C)) {\n      const FunctionDecl *FD = Call->getDirectCallee();\n      if (!FD)\n\
  \        return false;\n      for (unsigned i = 0, n = Call->getNumArgs(); i < n\
  \ && i < FD->getNumParams(); ++i) {\n        const Expr *Arg = Call->getArg(i);\n\
  \        if (!Arg)\n          continue;\n        const Expr *ArgCore = Arg->IgnoreParenImpCasts();\n\
  \        const Expr *ECore = E->IgnoreParenImpCasts();\n        if (ArgCore == ECore)\
  \ {\n          QualType ParamTy = FD->getParamDecl(i)->getType();\n          if\
  \ (isInt64OrWider(ParamTy, C))\n            return true;\n        }\n      }\n \
  \   }\n\n    return false;\n  }\n\n  // Try to get the maximum possible value of\
  \ an expression.\n  bool getMaxForExpr(const Expr *E, CheckerContext &C, llvm::APSInt\
  \ &Out) const {\n    if (!E) return false;\n\n    // Try constant evaluation\n \
  \   if (EvaluateExprToInt(Out, E, C))\n      return true;\n\n    // Try symbolic\
  \ max value\n    ProgramStateRef State = C.getState();\n    SVal V = State->getSVal(E,\
  \ C.getLocationContext());\n    SymbolRef Sym = V.getAsSymbol();\n    if (!Sym)\n\
  \      return false;\n\n    if (const llvm::APSInt *MaxV = inferSymbolMaxVal(Sym,\
  \ C)) {\n      Out = *MaxV;\n      return true;\n    }\n    return false;\n  }\n\
  \n  // Check if we can prove the product fits into the narrow type; if yes, suppress.\n\
  \  bool productDefinitelyFits(const BinaryOperator *B, CheckerContext &C) const\
  \ {\n    if (!B) return false;\n    const Expr *LHS = B->getLHS();\n    const Expr\
  \ *RHS = B->getRHS();\n    if (!LHS || !RHS)\n      return false;\n\n    llvm::APSInt\
  \ MaxL, MaxR;\n    if (!getMaxForExpr(LHS, C, MaxL) || !getMaxForExpr(RHS, C, MaxR))\n\
  \      return false; // Can't prove, so not definitely safe.\n\n    // Compute product\
  \ with 128-bit headroom using unsigned math.\n    uint64_t ML = MaxL.getZExtValue();\n\
  \    uint64_t MR = MaxR.getZExtValue();\n    __uint128_t Prod = ( (__uint128_t)ML\
  \ ) * ( (__uint128_t)MR );\n\n    // Determine limit for the narrow type (result\
  \ type of the multiply).\n    unsigned MulW = getIntWidth(B->getType(), C);\n  \
  \  bool IsUnsigned = B->getType()->isUnsignedIntegerType();\n    __uint128_t Limit;\n\
  \    if (IsUnsigned) {\n      if (MulW >= 64) {\n        // If multiply is already\
  \ 64-bit or more (should not be here), treat as safe.\n        return true;\n  \
  \    }\n      Limit = (((__uint128_t)1) << MulW) - 1;\n    } else {\n      if (MulW\
  \ == 0)\n        return false;\n      if (MulW >= 64) {\n        // As above, treat\
  \ as safe (won't reach in typical flow).\n        return true;\n      }\n      //\
  \ Signed max: 2^(W-1) - 1\n      Limit = (((__uint128_t)1) << (MulW - 1)) - 1;\n\
  \    }\n\n    return Prod <= Limit;\n  }\n};\n\nvoid SAGenTestChecker::checkPostStmt(const\
  \ BinaryOperator *B, CheckerContext &C) const {\n  if (!B)\n    return;\n\n  //\
  \ Only care about integer multiplication.\n  if (B->getOpcode() != BO_Mul)\n   \
  \ return;\n  if (!B->getType()->isIntegerType())\n    return;\n\n  // The multiply's\
  \ arithmetic width (after integer promotions).\n  unsigned MulWidth = getIntWidth(B->getType(),\
  \ C);\n\n  // If arithmetic is already 64-bit or more, that's OK.\n  if (MulWidth\
  \ >= 64)\n    return;\n\n  // Ensure operands are integer-typed as well.\n  if (!isIntegerType(B->getLHS())\
  \ || !isIntegerType(B->getRHS()))\n    return;\n\n  // Is the result used in 64-bit\
  \ integer context?\n  const Expr *E = dyn_cast<Expr>(B);\n  if (!E)\n    return;\n\
  \n  if (!isWidenedUseTo64(E, C))\n    return;\n\n  // Optional reduction: if we\
  \ can prove product fits in the narrow type, don't warn.\n  if (productDefinitelyFits(B,\
  \ C))\n    return;\n\n  // Report: multiplication in 32-bit (or narrower) that is\
  \ widened to 64-bit.\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n  if (!N)\n\
  \    return;\n\n  auto R = std::make_unique<PathSensitiveBugReport>(\n      *BT,\n\
  \      \"32-bit multiply widens to 64-bit after overflow; cast an operand to 64-bit\
  \ before the multiply\",\n      N);\n  R->addRange(B->getSourceRange());\n  C.emitReport(std::move(R));\n\
  }\n\n} // end anonymous namespace\n\nextern \"C\" void clang_registerCheckers(CheckerRegistry\
  \ &registry) {\n  registry.addChecker<SAGenTestChecker>(\n      \"custom.SAGenTestChecker\"\
  ,\n      \"Detect 32-bit multiply whose result is only widened to 64-bit afterward,\
  \ risking overflow\",\n      \"\");\n}\n\nextern \"C\" const char clang_analyzerAPIVersionString[]\
  \ =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
patch: "## Patch Description\n\ndrm/amdgu: fix Unintentional integer overflow for\
  \ mall size\n\nPotentially overflowing expression mall_size_per_umc * adev->gmc.num_umc\
  \ with type unsigned int (32 bits, unsigned)\nis evaluated using 32-bit arithmetic,and\
  \ then used in a context that expects an expression of type u64 (64 bits, unsigned).\n\
  \nSigned-off-by: Jesse Zhang <Jesse.Zhang@amd.com>\nReviewed-by: Christian K\xF6\
  nig <christian.koenig@amd.com>\nSigned-off-by: Alex Deucher <alexander.deucher@amd.com>\n\
  \n## Buggy Code\n\n```c\n// Function: amdgpu_discovery_get_mall_info in drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c\n\
  static int amdgpu_discovery_get_mall_info(struct amdgpu_device *adev)\n{\n\tstruct\
  \ binary_header *bhdr;\n\tunion mall_info *mall_info;\n\tu32 u, mall_size_per_umc,\
  \ m_s_present, half_use;\n\tu64 mall_size;\n\tu16 offset;\n\n\tif (!adev->mman.discovery_bin)\
  \ {\n\t\tDRM_ERROR(\"ip discovery uninitialized\\n\");\n\t\treturn -EINVAL;\n\t\
  }\n\n\tbhdr = (struct binary_header *)adev->mman.discovery_bin;\n\toffset = le16_to_cpu(bhdr->table_list[MALL_INFO].offset);\n\
  \n\tif (!offset)\n\t\treturn 0;\n\n\tmall_info = (union mall_info *)(adev->mman.discovery_bin\
  \ + offset);\n\n\tswitch (le16_to_cpu(mall_info->v1.header.version_major)) {\n\t\
  case 1:\n\t\tmall_size = 0;\n\t\tmall_size_per_umc = le32_to_cpu(mall_info->v1.mall_size_per_m);\n\
  \t\tm_s_present = le32_to_cpu(mall_info->v1.m_s_present);\n\t\thalf_use = le32_to_cpu(mall_info->v1.m_half_use);\n\
  \t\tfor (u = 0; u < adev->gmc.num_umc; u++) {\n\t\t\tif (m_s_present & (1 << u))\n\
  \t\t\t\tmall_size += mall_size_per_umc * 2;\n\t\t\telse if (half_use & (1 << u))\n\
  \t\t\t\tmall_size += mall_size_per_umc / 2;\n\t\t\telse\n\t\t\t\tmall_size += mall_size_per_umc;\n\
  \t\t}\n\t\tadev->gmc.mall_size = mall_size;\n\t\tadev->gmc.m_half_use = half_use;\n\
  \t\tbreak;\n\tcase 2:\n\t\tmall_size_per_umc = le32_to_cpu(mall_info->v2.mall_size_per_umc);\n\
  \t\tadev->gmc.mall_size = mall_size_per_umc * adev->gmc.num_umc;\n\t\tbreak;\n\t\
  default:\n\t\tdev_err(adev->dev,\n\t\t\t\"Unhandled MALL info table %d.%d\\n\",\n\
  \t\t\tle16_to_cpu(mall_info->v1.header.version_major),\n\t\t\tle16_to_cpu(mall_info->v1.header.version_minor));\n\
  \t\treturn -EINVAL;\n\t}\n\treturn 0;\n}\n```\n\n## Bug Fix Patch\n\n```diff\ndiff\
  \ --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c\n\
  index 87b31ed8de19..c71356cb393d 100644\n--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c\n\
  +++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_discovery.c\n@@ -1629,7 +1629,7 @@ static\
  \ int amdgpu_discovery_get_mall_info(struct amdgpu_device *adev)\n \t\tbreak;\n\
  \ \tcase 2:\n \t\tmall_size_per_umc = le32_to_cpu(mall_info->v2.mall_size_per_umc);\n\
  -\t\tadev->gmc.mall_size = mall_size_per_umc * adev->gmc.num_umc;\n+\t\tadev->gmc.mall_size\
  \ = (uint64_t)mall_size_per_umc * adev->gmc.num_umc;\n \t\tbreak;\n \tdefault:\n\
  \ \t\tdev_err(adev->dev,\n```\n"
pattern: '## Bug Pattern


  Computing a size using 32-bit arithmetic and only then assigning it to a 64-bit
  variable, causing overflow before the assignment. Specifically, multiplying two
  32-bit operands (e.g., u32 mall_size_per_umc and u32 num_umc) without promoting
  to 64-bit first:


  u64 total = (u32)a * (u32)b;  // overflow happens in 32-bit

  // Correct:

  u64 total = (u64)a * b;  // force 64-bit arithmetic before assignment


  This pattern arises when size/count calculations use narrower integer types for
  intermediate arithmetic even though the result is stored in a wider type.'
plan: "1) Program state\n- No custom program state is needed. The pattern is a purely\
  \ semantic/typing issue (where the arithmetic is performed in a narrower integer\
  \ type and only later widened). We can detect it reliably from the AST and type\
  \ information.\n\n2) Callback functions and detailed implementation\n\nA) checkPostStmt(const\
  \ BinaryOperator *B) const\n- Goal: Detect a multiplication that is computed in\
  \ 32-bit (or generally <64-bit) and only later converted to a 64-bit integer.\n\
  - Steps:\n  1. Filter to multiplication:\n     - If B->getOpcode() != BO_Mul, return.\n\
  \     - If !B->getType()->isIntegerType(), return.\n  2. Get the bit-width of the\
  \ multiplication\u2019s resulting type:\n     - unsigned MulWidth = C.getASTContext().getIntWidth(B->getType());\n\
  \     - If MulWidth >= 64, return (the multiply already happens in a 64-bit type;\
  \ safe).\n  3. Check operands (optional sanity; not strictly required since the\
  \ result width already encodes the effective arithmetic width):\n     - Both operands\
  \ should be integer types. If not, return.\n  4. Determine if the result of this\
  \ multiply is used in a 64-bit integer context:\n     - Search upwards for any of\
  \ these parents with destination 64-bit integer type:\n       - ImplicitCastExpr\
  \ (IntegralCast, IntegralToBoolean won\u2019t be 64-bit; we want integral cast to\
  \ a 64-bit integer)\n       - CStyleCastExpr\n       - CXXStaticCastExpr / CXXFunctionalCastExpr\n\
  \     - For each of these types, use findSpecificTypeInParents<T>(B, C). If found,\
  \ check the cast\u2019s target type:\n       - If the cast\u2019s target is an integer\
  \ type with width >= 64, mark as \u201Cwidened use\u201D.\n     - If no cast found,\
  \ also check for the broader contexts which imply a 64-bit destination (in case\
  \ the CastExpr was optimized away or doesn\u2019t exist as a node near the expression):\n\
  \       - Assignment: Find a parent BinaryOperator that is an assignment (isAssignmentOp()).\
  \ If found and its LHS type is integer with width >= 64, mark as \u201Cwidened use\u201D\
  .\n       - Return: Find a parent ReturnStmt. If found, get the current function\u2019\
  s return type from C.getLocationContext()->getDecl()->getReturnType() and check\
  \ width >= 64.\n       - Function argument: Find a parent CallExpr; if found, try\
  \ to see if this multiply expression is used as a direct argument:\n         - Iterate\
  \ the call\u2019s arguments; if any arg expression pointer (after IgnoreParenImpCasts)\
  \ is equal to B or contains B as its immediate expression, and the corresponding\
  \ parameter type is integer with width >= 64, mark as \u201Cwidened use\u201D.\n\
  \         - Note: In most cases a 64-bit argument will introduce an ImplicitCastExpr\
  \ parent above the multiply; therefore this is a fallback. If it\u2019s too complex\
  \ to reliably match the argument, you can skip this step since the ImplicitCastExpr\
  \ search will catch the common cases.\n     - If no \u201Cwidened use\u201D is found,\
  \ return.\n  5. Optional false-positive reduction (prove no 32-bit overflow can\
  \ occur):\n     - Extract LHS and RHS operands: const Expr *E1 = B->getLHS(); const\
  \ Expr *E2 = B->getRHS();\n     - Try to determine maximum possible values:\n  \
  \     - If EvaluateExprToInt(C1, E1, C) succeeds, we have a constant for E1; otherwise,\
  \ try symbol max with inferSymbolMaxVal on E1\u2019s symbol.\n       - Do the same\
  \ for E2.\n     - If you get concrete maxima for both sides (U1 and U2, treating\
  \ as unsigned if types are unsigned), compute U1 * U2 using 64-bit arithmetic and\
  \ check if the product fits in 32 bits (<= 0xFFFFFFFF for unsigned). If it definitely\
  \ fits, do not warn.\n     - If you cannot retrieve both maxima, or the computed\
  \ product exceeds 32-bit range, proceed to warn.\n  6. Emit a bug report:\n    \
  \ - Create a BugType once (e.g., \"Narrow multiply widened after overflow\").\n\
  \     - Create a BasicBugReport with a short message:\n       - \"32-bit multiply\
  \ widens to 64-bit after overflow; cast an operand to 64-bit before the multiply.\"\
  \n     - Highlight the source range of the multiplication (B->getSourceRange()).\n\
  \     - Use C.emitReport(std::make_unique<BasicBugReport>(...)).\n\nNotes and rationale:\n\
  - Checking B->getType() gives the effective arithmetic type after usual integer\
  \ promotions and usual arithmetic conversions. If that type\u2019s width is 32 and\
  \ the parent context widens to 64, the multiply was indeed computed in 32-bit first.\n\
  - Looking for any parent CastExpr to 64-bit captures:\n  - Assignment to u64 fields/vars\
  \ (there is typically an implicit cast on the RHS),\n  - Returning u64 from a function,\n\
  \  - Passing the multiply result to a u64 parameter.\n- If an explicit cast surrounds\
  \ the multiply, e.g., (u64)(a*b), we still warn because the multiply occurred in\
  \ 32-bit before the explicit cast.\n- The optional range reasoning uses provided\
  \ utilities to reduce noise when both operands\u2019 maxima ensure the product fits\
  \ in 32 bits.\n\nB) No other callbacks required\n- The multiply-then-widen pattern\
  \ is most reliably caught at the multiply node itself via checkPostStmt(const BinaryOperator*).\n\
  - DeclStmt/ReturnStmt/Call checks are indirectly covered via parent CastExpr detection.\
  \ If desired, implement the function-argument fallback described above; otherwise\
  \ you can rely on ImplicitCastExprs to catch the common cases.\n\n3) Small helper\
  \ logic (as comments in the checker)\n- Helper to get integer width and signedness:\n\
  \  - Use C.getASTContext().getIntWidth(QualType) and Ty->isUnsignedIntegerType()\
  \ to understand widths and signedness.\n- Parent search:\n  - Use the provided findSpecificTypeInParents<T>(...)\
  \ repeatedly for ImplicitCastExpr, CStyleCastExpr, CXXStaticCastExpr, BinaryOperator\
  \ (assignment), ReturnStmt, and CallExpr.\n\n4) Report message\n- Keep it short\
  \ and actionable:\n  - \"32-bit multiply widens to 64-bit after overflow; cast an\
  \ operand to 64-bit before the multiply.\""
refined_plan: null
repaired_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/ASTContext.h\"\n#include \"clang/AST/Expr.h\"\n#include \"\
  clang/AST/ExprCXX.h\"\n#include \"clang/AST/OperationKinds.h\"\n#include \"clang/AST/Stmt.h\"\
  \n#include \"clang/Basic/SourceManager.h\"\n#include \"clang/Lex/Lexer.h\"\n\nusing\
  \ namespace clang;\nusing namespace ento;\nusing namespace taint;\n\n// No custom\
  \ program state needed.\n\nnamespace {\n\nclass SAGenTestChecker : public Checker<check::PostStmt<BinaryOperator>>\
  \ {\n   mutable std::unique_ptr<BugType> BT;\n\npublic:\n  SAGenTestChecker()\n\
  \      : BT(new BugType(this, \"32-bit multiply widened to 64-bit\",\n         \
  \              \"Integer Overflow\")) {}\n\n  void checkPostStmt(const BinaryOperator\
  \ *B, CheckerContext &C) const;\n\nprivate:\n  // Helpers\n  static unsigned getIntWidth(QualType\
  \ T, CheckerContext &C) {\n    return C.getASTContext().getIntWidth(T);\n  }\n\n\
  \  static bool isInt64OrWider(QualType T, CheckerContext &C) {\n    return T->isIntegerType()\
  \ && getIntWidth(T, C) >= 64;\n  }\n\n  static bool isIntegerType(const Expr *E)\
  \ {\n    if (!E) return false;\n    return E->getType()->isIntegerType();\n  }\n\
  \n  // Determine if the expression result is used in a 64-bit integer context.\n\
  \  bool isWidenedUseTo64(const Expr *E, CheckerContext &C) const {\n    if (!E)\
  \ return false;\n\n    // 1) Look for an implicit cast to 64-bit integer.\n    if\
  \ (const auto *ICE = findSpecificTypeInParents<ImplicitCastExpr>(E, C)) {\n    \
  \  QualType DestTy = ICE->getType();\n      if (isInt64OrWider(DestTy, C))\n   \
  \     return true;\n    }\n\n    // 2) Look for a C-style cast to 64-bit\n    if\
  \ (const auto *CS = findSpecificTypeInParents<CStyleCastExpr>(E, C)) {\n      QualType\
  \ DestTy = CS->getTypeAsWritten();\n      if (isInt64OrWider(DestTy, C))\n     \
  \   return true;\n    }\n\n    // 3) Look for assignment where LHS is 64-bit\n \
  \   if (const auto *PAssn = findSpecificTypeInParents<BinaryOperator>(E, C)) {\n\
  \      if (PAssn->isAssignmentOp()) {\n        const Expr *LHS = PAssn->getLHS();\n\
  \        if (LHS && isInt64OrWider(LHS->getType(), C))\n          return true;\n\
  \      }\n    }\n\n    // 4) Look for return statement where function returns 64-bit\n\
  \    if (findSpecificTypeInParents<ReturnStmt>(E, C)) {\n      const auto *D = dyn_cast_or_null<FunctionDecl>(C.getLocationContext()->getDecl());\n\
  \      if (D) {\n        QualType RetTy = D->getReturnType();\n        if (isInt64OrWider(RetTy,\
  \ C))\n          return true;\n      }\n    }\n\n    // 5) Look for function call\
  \ argument where the parameter is 64-bit\n    if (const auto *Call = findSpecificTypeInParents<CallExpr>(E,\
  \ C)) {\n      const FunctionDecl *FD = Call->getDirectCallee();\n      if (!FD)\n\
  \        return false;\n      for (unsigned i = 0, n = Call->getNumArgs(); i < n\
  \ && i < FD->getNumParams(); ++i) {\n        const Expr *Arg = Call->getArg(i);\n\
  \        if (!Arg)\n          continue;\n        const Expr *ArgCore = Arg->IgnoreParenImpCasts();\n\
  \        const Expr *ECore = E->IgnoreParenImpCasts();\n        if (ArgCore == ECore)\
  \ {\n          QualType ParamTy = FD->getParamDecl(i)->getType();\n          if\
  \ (isInt64OrWider(ParamTy, C))\n            return true;\n        }\n      }\n \
  \   }\n\n    return false;\n  }\n\n  // Try to get the maximum possible value of\
  \ an expression.\n  bool getMaxForExpr(const Expr *E, CheckerContext &C, llvm::APSInt\
  \ &Out) const {\n    if (!E) return false;\n\n    // Try constant evaluation\n \
  \   if (EvaluateExprToInt(Out, E, C))\n      return true;\n\n    // Try symbolic\
  \ max value\n    ProgramStateRef State = C.getState();\n    SVal V = State->getSVal(E,\
  \ C.getLocationContext());\n    SymbolRef Sym = V.getAsSymbol();\n    if (!Sym)\n\
  \      return false;\n\n    if (const llvm::APSInt *MaxV = inferSymbolMaxVal(Sym,\
  \ C)) {\n      Out = *MaxV;\n      return true;\n    }\n    return false;\n  }\n\
  \n  // Check if we can prove the product fits into the narrow type; if yes, suppress.\n\
  \  bool productDefinitelyFits(const BinaryOperator *B, CheckerContext &C) const\
  \ {\n    if (!B) return false;\n    const Expr *LHS = B->getLHS();\n    const Expr\
  \ *RHS = B->getRHS();\n    if (!LHS || !RHS)\n      return false;\n\n    llvm::APSInt\
  \ MaxL, MaxR;\n    if (!getMaxForExpr(LHS, C, MaxL) || !getMaxForExpr(RHS, C, MaxR))\n\
  \      return false; // Can't prove, so not definitely safe.\n\n    // Compute product\
  \ with 128-bit headroom using unsigned math.\n    uint64_t ML = MaxL.getZExtValue();\n\
  \    uint64_t MR = MaxR.getZExtValue();\n    __uint128_t Prod = ( (__uint128_t)ML\
  \ ) * ( (__uint128_t)MR );\n\n    // Determine limit for the narrow type (result\
  \ type of the multiply).\n    unsigned MulW = getIntWidth(B->getType(), C);\n  \
  \  bool IsUnsigned = B->getType()->isUnsignedIntegerType();\n    __uint128_t Limit;\n\
  \    if (IsUnsigned) {\n      if (MulW >= 64) {\n        // If multiply is already\
  \ 64-bit or more (should not be here), treat as safe.\n        return true;\n  \
  \    }\n      Limit = (((__uint128_t)1) << MulW) - 1;\n    } else {\n      if (MulW\
  \ == 0)\n        return false;\n      if (MulW >= 64) {\n        // As above, treat\
  \ as safe (won't reach in typical flow).\n        return true;\n      }\n      //\
  \ Signed max: 2^(W-1) - 1\n      Limit = (((__uint128_t)1) << (MulW - 1)) - 1;\n\
  \    }\n\n    return Prod <= Limit;\n  }\n};\n\nvoid SAGenTestChecker::checkPostStmt(const\
  \ BinaryOperator *B, CheckerContext &C) const {\n  if (!B)\n    return;\n\n  //\
  \ Only care about integer multiplication.\n  if (B->getOpcode() != BO_Mul)\n   \
  \ return;\n  if (!B->getType()->isIntegerType())\n    return;\n\n  // The multiply's\
  \ arithmetic width (after integer promotions).\n  unsigned MulWidth = getIntWidth(B->getType(),\
  \ C);\n\n  // If arithmetic is already 64-bit or more, that's OK.\n  if (MulWidth\
  \ >= 64)\n    return;\n\n  // Ensure operands are integer-typed as well.\n  if (!isIntegerType(B->getLHS())\
  \ || !isIntegerType(B->getRHS()))\n    return;\n\n  // Is the result used in 64-bit\
  \ integer context?\n  const Expr *E = dyn_cast<Expr>(B);\n  if (!E)\n    return;\n\
  \n  if (!isWidenedUseTo64(E, C))\n    return;\n\n  // Optional reduction: if we\
  \ can prove product fits in the narrow type, don't warn.\n  if (productDefinitelyFits(B,\
  \ C))\n    return;\n\n  // Report: multiplication in 32-bit (or narrower) that is\
  \ widened to 64-bit.\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n  if (!N)\n\
  \    return;\n\n  auto R = std::make_unique<PathSensitiveBugReport>(\n      *BT,\n\
  \      \"32-bit multiply widens to 64-bit after overflow; cast an operand to 64-bit\
  \ before the multiply\",\n      N);\n  R->addRange(B->getSourceRange());\n  C.emitReport(std::move(R));\n\
  }\n\n} // end anonymous namespace\n\nextern \"C\" void clang_registerCheckers(CheckerRegistry\
  \ &registry) {\n  registry.addChecker<SAGenTestChecker>(\n      \"custom.SAGenTestChecker\"\
  ,\n      \"Detect 32-bit multiply whose result is only widened to 64-bit afterward,\
  \ risking overflow\",\n      \"\");\n}\n\nextern \"C\" const char clang_analyzerAPIVersionString[]\
  \ =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
tn_score: 1
tp_score: 1
