_base_result_dir: /scratch/chenyuan-data/knighter-dev/result-gpt-5-0814
commit_id: 8bc35475ef1a23b0e224f3242eb11c76cab0ea88
commit_type: Concurrency
index: 6
initial_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/ASTContext.h\"\n#include \"clang/AST/Decl.h\"\n#include \"\
  clang/AST/Expr.h\"\n#include \"clang/AST/Stmt.h\"\n#include \"clang/AST/StmtCXX.h\"\
  \n#include \"clang/Basic/SourceManager.h\"\n#include \"clang/Lex/Lexer.h\"\n\nusing\
  \ namespace clang;\nusing namespace ento;\nusing namespace taint;\n\n// Map a local\
  \ VarRegion (the receiver variable) to the statement that performed\n// the suspicious\
  \ speculative load (assignment/init).\nREGISTER_MAP_WITH_PROGRAMSTATE(SpeculativeLoadMap,\
  \ const VarRegion *, const Stmt *)\n\nnamespace {\n\nclass SAGenTestChecker\n  :\
  \ public Checker<\n        check::PostStmt<DeclStmt>,\n        check::Bind,\n  \
  \      check::BranchCondition,\n        check::EndFunction\n      > {\n   mutable\
  \ std::unique_ptr<BugType> BT;\n\npublic:\n  SAGenTestChecker() : BT(new BugType(this,\
  \ \"Speculative unguarded read\", \"Concurrency\")) {}\n\n  void checkPostStmt(const\
  \ DeclStmt *DS, CheckerContext &C) const;\n  void checkBind(SVal Loc, SVal Val,\
  \ const Stmt *S, CheckerContext &C) const;\n  void checkBranchCondition(const Stmt\
  \ *Condition, CheckerContext &C) const;\n  void checkEndFunction(const ReturnStmt\
  \ *RS, CheckerContext &C) const;\n\nprivate:\n  // Returns true if RHS matches the\
  \ suspicious pattern \"*call(args...)\" and\n  // the call's first argument refers\
  \ to a shared location (param/global).\n  bool analyzeAssignment(const VarDecl *VD,\
  \ const Expr *RHS,\n                         const Stmt *BindSite, CheckerContext\
  \ &C) const;\n\n  // Utility: collect local (automatic storage) VarDecls referenced\
  \ in E.\n  void collectLocalVarDeclsInExpr(const Expr *E,\n                    \
  \              llvm::SmallVectorImpl<const VarDecl*> &Out) const;\n\n  // Utility:\
  \ verify destination variable kind is acceptable (local, scalar or pointer).\n \
  \ bool isLocalScalarOrPointerVar(const VarDecl *VD, ASTContext &ACtx) const;\n\n\
  \  // Report diagnostic at the speculative load statement.\n  void reportAtLoad(const\
  \ Stmt *LoadS, const IfStmt *IfS, CheckerContext &C) const;\n\n  // Check if IfS\
  \ is immediately following LoadS inside the same compound block.\n  bool isImmediatelyBefore(const\
  \ Stmt *Prev, const IfStmt *IfS, CheckerContext &C) const;\n};\n\nbool SAGenTestChecker::isLocalScalarOrPointerVar(const\
  \ VarDecl *VD, ASTContext &ACtx) const {\n  if (!VD)\n    return false;\n  if (!VD->hasLocalStorage())\n\
  \    return false;\n  QualType QT = VD->getType();\n  if (QT.isNull())\n    return\
  \ false;\n  return QT->isScalarType() || QT->isPointerType() || QT->isIntegerType();\n\
  }\n\nvoid SAGenTestChecker::collectLocalVarDeclsInExpr(const Expr *E,\n    llvm::SmallVectorImpl<const\
  \ VarDecl*> &Out) const {\n  if (!E) return;\n  struct Walker {\n    static void\
  \ run(const Expr *Node, llvm::SmallVectorImpl<const VarDecl*> &Out) {\n      if\
  \ (!Node) return;\n      if (const auto *DRE = dyn_cast<DeclRefExpr>(Node->IgnoreParenCasts()))\
  \ {\n        if (const auto *VD = dyn_cast<VarDecl>(DRE->getDecl())) {\n       \
  \   if (VD->hasLocalStorage())\n            Out.push_back(VD);\n        }\n    \
  \  }\n      for (const Stmt *Child : Node->children()) {\n        if (const auto\
  \ *CE = dyn_cast_or_null<Expr>(Child))\n          run(CE, Out);\n      }\n    }\n\
  \  };\n  Walker::run(E, Out);\n}\n\nbool SAGenTestChecker::analyzeAssignment(const\
  \ VarDecl *VD, const Expr *RHS,\n                                         const\
  \ Stmt *BindSite, CheckerContext &C) const {\n  if (!VD || !RHS || !BindSite)\n\
  \    return false;\n\n  if (!isLocalScalarOrPointerVar(VD, C.getASTContext()))\n\
  \    return false;\n\n  // Skip if expression explicitly uses READ_ONCE or 'atomic'\
  \ markers.\n  if (ExprHasName(RHS, \"READ_ONCE\", C) || ExprHasName(RHS, \"atomic\"\
  , C))\n    return false;\n\n  // Look for a unary '*' dereference of a call expression.\n\
  \  const UnaryOperator *UO = findSpecificTypeInChildren<UnaryOperator>(RHS);\n \
  \ if (!UO || UO->getOpcode() != UO_Deref)\n    return false;\n\n  const Expr *Sub\
  \ = UO->getSubExpr();\n  if (!Sub)\n    return false;\n  Sub = Sub->IgnoreParenCasts();\n\
  \n  const CallExpr *CE = dyn_cast<CallExpr>(Sub);\n  if (!CE)\n    return false;\n\
  \n  // Heuristic: first argument should refer to a parameter or global storage.\n\
  \  if (CE->getNumArgs() > 0) {\n    const Expr *A0 = CE->getArg(0);\n    if (!A0)\n\
  \      return false;\n\n    const MemRegion *R = getMemRegionFromExpr(A0, C);\n\
  \    if (!R)\n      return false;\n    R = R->getBaseRegion();\n    if (!R)\n  \
  \    return false;\n\n    if (isa<ParamRegion>(R)) {\n      // OK, likely shared\
  \ via parameter.\n    } else if (const auto *VR = dyn_cast<VarRegion>(R)) {\n  \
  \    const VarDecl *SrcVD = VR->getDecl();\n      if (!SrcVD || !SrcVD->hasGlobalStorage())\n\
  \        return false;\n    } else {\n      // Unknown source - be conservative\
  \ and skip.\n      return false;\n    }\n  } else {\n    // No arguments - less\
  \ likely to be shared; be conservative.\n    return false;\n  }\n\n  return true;\n\
  }\n\nbool SAGenTestChecker::isImmediatelyBefore(const Stmt *Prev, const IfStmt *IfS,\
  \ CheckerContext &C) const {\n  if (!Prev || !IfS)\n    return false;\n\n  const\
  \ CompoundStmt *CS = findSpecificTypeInParents<CompoundStmt>(IfS, C);\n  if (!CS)\n\
  \    return false;\n\n  const Stmt *Last = nullptr;\n  for (const Stmt *Child :\
  \ CS->body()) {\n    if (Child == IfS)\n      return Last == Prev;\n    Last = Child;\n\
  \  }\n  return false;\n}\n\nvoid SAGenTestChecker::reportAtLoad(const Stmt *LoadS,\
  \ const IfStmt *IfS, CheckerContext &C) const {\n  if (!LoadS)\n    return;\n  ExplodedNode\
  \ *N = C.generateNonFatalErrorNode();\n  if (!N)\n    return;\n\n  auto R = std::make_unique<PathSensitiveBugReport>(\n\
  \      *BT, \"Speculative unguarded read; move the read under the guard\", N);\n\
  \  R->addRange(LoadS->getSourceRange());\n  C.emitReport(std::move(R));\n}\n\nvoid\
  \ SAGenTestChecker::checkPostStmt(const DeclStmt *DS, CheckerContext &C) const {\n\
  \  if (!DS)\n    return;\n\n  ProgramStateRef State = C.getState();\n  MemRegionManager\
  \ &MRMgr = C.getSValBuilder().getRegionManager();\n\n  for (const Decl *D : DS->decls())\
  \ {\n    const auto *VD = dyn_cast<VarDecl>(D);\n    if (!VD)\n      continue;\n\
  \n    if (!VD->hasInit())\n      continue;\n\n    const Expr *Init = VD->getInit();\n\
  \    if (!Init)\n      continue;\n\n    if (!analyzeAssignment(VD, Init, DS, C))\n\
  \      continue;\n\n    const VarRegion *VR = MRMgr.getVarRegion(VD, C.getLocationContext());\n\
  \    if (!VR)\n      continue;\n\n    State = State->set<SpeculativeLoadMap>(VR,\
  \ DS);\n  }\n\n  if (State != C.getState())\n    C.addTransition(State);\n}\n\n\
  void SAGenTestChecker::checkBind(SVal Loc, SVal Val, const Stmt *S, CheckerContext\
  \ &C) const {\n  if (!S)\n    return;\n\n  const auto *BO = dyn_cast<BinaryOperator>(S);\n\
  \  if (!BO || !BO->isAssignmentOp())\n    return;\n\n  const Expr *LHS = BO->getLHS();\n\
  \  const Expr *RHS = BO->getRHS();\n  if (!LHS || !RHS)\n    return;\n\n  const\
  \ auto *DRE = dyn_cast<DeclRefExpr>(LHS->IgnoreParenCasts());\n  if (!DRE)\n   \
  \ return;\n\n  const auto *VD = dyn_cast<VarDecl>(DRE->getDecl());\n  if (!VD)\n\
  \    return;\n\n  if (!isLocalScalarOrPointerVar(VD, C.getASTContext()))\n    return;\n\
  \n  if (!analyzeAssignment(VD, RHS, S, C))\n    return;\n\n  ProgramStateRef State\
  \ = C.getState();\n  MemRegionManager &MRMgr = C.getSValBuilder().getRegionManager();\n\
  \  const VarRegion *VR = MRMgr.getVarRegion(VD, C.getLocationContext());\n  if (!VR)\n\
  \    return;\n\n  State = State->set<SpeculativeLoadMap>(VR, S);\n  if (State !=\
  \ C.getState())\n    C.addTransition(State);\n}\n\nvoid SAGenTestChecker::checkBranchCondition(const\
  \ Stmt *Condition, CheckerContext &C) const {\n  if (!Condition)\n    return;\n\n\
  \  const IfStmt *IfS = findSpecificTypeInParents<IfStmt>(Condition, C);\n  if (!IfS)\n\
  \    return;\n\n  const Expr *CondE = IfS->getCond();\n  if (!CondE)\n    return;\n\
  \  CondE = CondE->IgnoreParenCasts();\n\n  const auto *BO = dyn_cast<BinaryOperator>(CondE);\n\
  \  if (!BO || BO->getOpcode() != BO_LAnd)\n    return;\n\n  const Expr *LHS = BO->getLHS();\n\
  \  const Expr *RHS = BO->getRHS();\n  if (!LHS || !RHS)\n    return;\n\n  // Collect\
  \ local variables referenced on RHS.\n  llvm::SmallVector<const VarDecl*, 8> RHSVars;\n\
  \  collectLocalVarDeclsInExpr(RHS, RHSVars);\n\n  if (RHSVars.empty())\n    return;\n\
  \n  ProgramStateRef State = C.getState();\n  MemRegionManager &MRMgr = C.getSValBuilder().getRegionManager();\n\
  \n  for (const VarDecl *VD : RHSVars) {\n    if (!VD)\n      continue;\n\n    const\
  \ VarRegion *VR = MRMgr.getVarRegion(VD, C.getLocationContext());\n    if (!VR)\n\
  \      continue;\n\n    const Stmt *const *LoadSP = State->get<SpeculativeLoadMap>(VR);\n\
  \    if (!LoadSP)\n      continue;\n\n    const Stmt *LoadS = *LoadSP;\n    if (!LoadS)\n\
  \      continue;\n\n    // Ensure the variable is not referenced in the guard (LHS).\n\
  \    if (ExprHasName(LHS, VD->getName(), C))\n      continue;\n\n    // Ensure adjacency:\
  \ the 'if' immediately follows the load statement.\n    if (!isImmediatelyBefore(LoadS,\
  \ IfS, C))\n      continue;\n\n    // Report the issue at the speculative load site.\n\
  \    reportAtLoad(LoadS, IfS, C);\n\n    // Remove the entry to avoid duplicate\
  \ reports.\n    State = State->remove<SpeculativeLoadMap>(VR);\n  }\n\n  if (State\
  \ != C.getState())\n    C.addTransition(State);\n}\n\nvoid SAGenTestChecker::checkEndFunction(const\
  \ ReturnStmt *RS, CheckerContext &C) const {\n  // No explicit clearing is necessary;\
  \ function-local regions die at function exit.\n  // Kept for completeness per plan.\n\
  }\n\n} // end anonymous namespace\n\nextern \"C\" void clang_registerCheckers(CheckerRegistry\
  \ &registry) {\n  registry.addChecker<SAGenTestChecker>(\n      \"custom.SAGenTestChecker\"\
  ,\n      \"Detects speculative unguarded reads before guard checks (e.g., reading\
  \ shared state before testing a guard such as from_cancel)\",\n      \"\");\n}\n\
  \nextern \"C\" const char clang_analyzerAPIVersionString[] =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
patch: "## Patch Description\n\nworkqueue: Fix spruious data race in __flush_work()\n\
  \nWhen flushing a work item for cancellation, __flush_work() knows that it\nexclusively\
  \ owns the work item through its PENDING bit. 134874e2eee9\n(\"workqueue: Allow\
  \ cancel_work_sync() and disable_work() from atomic\ncontexts on BH work items\"\
  ) added a read of @work->data to determine whether\nto use busy wait for BH work\
  \ items that are being canceled. While the read\nis safe when @from_cancel, @work->data\
  \ was read before testing @from_cancel\nto simplify code structure:\n\n\tdata =\
  \ *work_data_bits(work);\n\tif (from_cancel &&\n\t    !WARN_ON_ONCE(data & WORK_STRUCT_PWQ)\
  \ && (data & WORK_OFFQ_BH)) {\n\nWhile the read data was never used if !@from_cancel,\
  \ this could trigger\nKCSAN data race detection spuriously:\n\n  ==================================================================\n\
  \  BUG: KCSAN: data-race in __flush_work / __flush_work\n\n  write to 0xffff8881223aa3e8\
  \ of 8 bytes by task 3998 on cpu 0:\n   instrument_write include/linux/instrumented.h:41\
  \ [inline]\n   ___set_bit include/asm-generic/bitops/instrumented-non-atomic.h:28\
  \ [inline]\n   insert_wq_barrier kernel/workqueue.c:3790 [inline]\n   start_flush_work\
  \ kernel/workqueue.c:4142 [inline]\n   __flush_work+0x30b/0x570 kernel/workqueue.c:4178\n\
  \   flush_work kernel/workqueue.c:4229 [inline]\n   ...\n\n  read to 0xffff8881223aa3e8\
  \ of 8 bytes by task 50 on cpu 1:\n   __flush_work+0x42a/0x570 kernel/workqueue.c:4188\n\
  \   flush_work kernel/workqueue.c:4229 [inline]\n   flush_delayed_work+0x66/0x70\
  \ kernel/workqueue.c:4251\n   ...\n\n  value changed: 0x0000000000400000 -> 0xffff88810006c00d\n\
  \nReorganize the code so that @from_cancel is tested before @work->data is\naccessed.\
  \ The only problem is triggering KCSAN detection spuriously. This\nshouldn't need\
  \ READ_ONCE() or other access qualifiers.\n\nNo functional changes.\n\nSigned-off-by:\
  \ Tejun Heo <tj@kernel.org>\nReported-by: syzbot+b3e4f2f51ed645fd5df2@syzkaller.appspotmail.com\n\
  Fixes: 134874e2eee9 (\"workqueue: Allow cancel_work_sync() and disable_work() from\
  \ atomic contexts on BH work items\")\nLink: http://lkml.kernel.org/r/000000000000ae429e061eea2157@google.com\n\
  Cc: Jens Axboe <axboe@kernel.dk>\n\n## Buggy Code\n\n```c\n// Function: __flush_work\
  \ in kernel/workqueue.c\nstatic bool __flush_work(struct work_struct *work, bool\
  \ from_cancel)\n{\n\tstruct wq_barrier barr;\n\tunsigned long data;\n\n\tif (WARN_ON(!wq_online))\n\
  \t\treturn false;\n\n\tif (WARN_ON(!work->func))\n\t\treturn false;\n\n\tif (!start_flush_work(work,\
  \ &barr, from_cancel))\n\t\treturn false;\n\n\t/*\n\t * start_flush_work() returned\
  \ %true. If @from_cancel is set, we know\n\t * that @work must have been executing\
  \ during start_flush_work() and\n\t * can't currently be queued. Its data must contain\
  \ OFFQ bits. If @work\n\t * was queued on a BH workqueue, we also know that it was\
  \ running in the\n\t * BH context and thus can be busy-waited.\n\t */\n\tdata =\
  \ *work_data_bits(work);\n\tif (from_cancel &&\n\t    !WARN_ON_ONCE(data & WORK_STRUCT_PWQ)\
  \ && (data & WORK_OFFQ_BH)) {\n\t\t/*\n\t\t * On RT, prevent a live lock when %current\
  \ preempted soft\n\t\t * interrupt processing or prevents ksoftirqd from running\
  \ by\n\t\t * keeping flipping BH. If the BH work item runs on a different\n\t\t\
  \ * CPU then this has no effect other than doing the BH\n\t\t * disable/enable dance\
  \ for nothing. This is copied from\n\t\t * kernel/softirq.c::tasklet_unlock_spin_wait().\n\
  \t\t */\n\t\twhile (!try_wait_for_completion(&barr.done)) {\n\t\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT))\
  \ {\n\t\t\t\tlocal_bh_disable();\n\t\t\t\tlocal_bh_enable();\n\t\t\t} else {\n\t\
  \t\t\tcpu_relax();\n\t\t\t}\n\t\t}\n\t} else {\n\t\twait_for_completion(&barr.done);\n\
  \t}\n\n\tdestroy_work_on_stack(&barr.work);\n\treturn true;\n}\n```\n\n## Bug Fix\
  \ Patch\n\n```diff\ndiff --git a/kernel/workqueue.c b/kernel/workqueue.c\nindex\
  \ d56bd2277e58..ef174d8c1f63 100644\n--- a/kernel/workqueue.c\n+++ b/kernel/workqueue.c\n\
  @@ -4166,7 +4166,6 @@ static bool start_flush_work(struct work_struct *work, struct\
  \ wq_barrier *barr,\n static bool __flush_work(struct work_struct *work, bool from_cancel)\n\
  \ {\n \tstruct wq_barrier barr;\n-\tunsigned long data;\n \n \tif (WARN_ON(!wq_online))\n\
  \ \t\treturn false;\n@@ -4184,29 +4183,35 @@ static bool __flush_work(struct work_struct\
  \ *work, bool from_cancel)\n \t * was queued on a BH workqueue, we also know that\
  \ it was running in the\n \t * BH context and thus can be busy-waited.\n \t */\n\
  -\tdata = *work_data_bits(work);\n-\tif (from_cancel &&\n-\t    !WARN_ON_ONCE(data\
  \ & WORK_STRUCT_PWQ) && (data & WORK_OFFQ_BH)) {\n-\t\t/*\n-\t\t * On RT, prevent\
  \ a live lock when %current preempted soft\n-\t\t * interrupt processing or prevents\
  \ ksoftirqd from running by\n-\t\t * keeping flipping BH. If the BH work item runs\
  \ on a different\n-\t\t * CPU then this has no effect other than doing the BH\n\
  -\t\t * disable/enable dance for nothing. This is copied from\n-\t\t * kernel/softirq.c::tasklet_unlock_spin_wait().\n\
  -\t\t */\n-\t\twhile (!try_wait_for_completion(&barr.done)) {\n-\t\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT))\
  \ {\n-\t\t\t\tlocal_bh_disable();\n-\t\t\t\tlocal_bh_enable();\n-\t\t\t} else {\n\
  -\t\t\t\tcpu_relax();\n+\tif (from_cancel) {\n+\t\tunsigned long data = *work_data_bits(work);\n\
  +\n+\t\tif (!WARN_ON_ONCE(data & WORK_STRUCT_PWQ) &&\n+\t\t    (data & WORK_OFFQ_BH))\
  \ {\n+\t\t\t/*\n+\t\t\t * On RT, prevent a live lock when %current preempted\n+\t\
  \t\t * soft interrupt processing or prevents ksoftirqd from\n+\t\t\t * running by\
  \ keeping flipping BH. If the BH work item\n+\t\t\t * runs on a different CPU then\
  \ this has no effect other\n+\t\t\t * than doing the BH disable/enable dance for\
  \ nothing.\n+\t\t\t * This is copied from\n+\t\t\t * kernel/softirq.c::tasklet_unlock_spin_wait().\n\
  +\t\t\t */\n+\t\t\twhile (!try_wait_for_completion(&barr.done)) {\n+\t\t\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT))\
  \ {\n+\t\t\t\t\tlocal_bh_disable();\n+\t\t\t\t\tlocal_bh_enable();\n+\t\t\t\t} else\
  \ {\n+\t\t\t\t\tcpu_relax();\n+\t\t\t\t}\n \t\t\t}\n+\t\t\tgoto out_destroy;\n \t\
  \t}\n-\t} else {\n-\t\twait_for_completion(&barr.done);\n \t}\n \n+\twait_for_completion(&barr.done);\n\
  +\n+out_destroy:\n \tdestroy_work_on_stack(&barr.work);\n \treturn true;\n }\n```\n"
pattern: "## Bug Pattern\n\nSpeculative, unguarded read of a concurrently modified\
  \ field before checking the condition that makes the read safe.\n\nPattern example:\n\
  - Read shared state first: data = *shared_bits;\n- Then test the guard that guarantees\
  \ exclusive ownership: if (from_cancel) { use(data); }\n- Even if data isn\u2019\
  t used when the guard is false, the initial read can race with writers and trigger\
  \ KCSAN.\n\nCorrect pattern:\n- Check the guard (which ensures safe access) first,\
  \ and only then read the shared field: if (from_cancel) { data = *shared_bits; ...\
  \ }"
plan: "Plan\n\n1) Program state\n- REGISTER_MAP_WITH_PROGRAMSTATE(SpeculativeLoadMap,\
  \ const VarRegion *, const Stmt *)\n  - Key: the local variable that receives the\
  \ value read from shared memory (e.g., data).\n  - Value: the Stmt pointer of the\
  \ assignment/initialization that performed the read.\n- Rationale: We only need\
  \ to remember that a specific local variable was filled by a suspicious dereference\
  \ (potentially reading a concurrently modified location) right before a guard-checking\
  \ if-statement.\n\n2) Callbacks and logic\n- checkPostStmt(const DeclStmt *DS, CheckerContext\
  \ &C)\n  - Goal: Capture \u201CT x = *call(...);\u201D initializations.\n  - For\
  \ each VarDecl in DS:\n    - If it has an initializer, let Init = VD->getInit().\n\
  \    - Run analyzeAssignment(VD, Init, DS, C).\n  - If analyzeAssignment returns\
  \ true, insert into SpeculativeLoadMap: (VarRegion of VD) -> DS.\n\n- checkBind(SVal\
  \ Loc, SVal Val, const Stmt *S, CheckerContext &C)\n  - Goal: Capture \u201Cx =\
  \ *call(...);\u201D assignments.\n  - If S is a BinaryOperator and isAssignmentOp():\n\
  \    - Extract LHS and RHS Exprs.\n    - Get VD from LHS if LHS is a DeclRefExpr\
  \ to a VarDecl with local storage. Ignore non-local or non-scalar.\n    - Run analyzeAssignment(VD,\
  \ RHS, S, C).\n  - If analyzeAssignment returns true, insert into SpeculativeLoadMap:\
  \ (VarRegion of VD) -> S.\n\n- checkBranchCondition(const Stmt *Condition, CheckerContext\
  \ &C)\n  - Goal: Detect the pattern \u201Cif (Guard && ... uses X ...)\u201D where\
  \ X was read speculatively just before this if.\n  - Find the IfStmt ancestor with\
  \ findSpecificTypeInParents<IfStmt>(Condition, C). If none, return.\n  - Let IfS\
  \ = that IfStmt and CondExpr = IfS->getCond().\n  - Only handle top-level logical\
  \ AND: if CondExpr is a BinaryOperator with opcode BO_LAnd:\n    - Let LHS = CondExpr->getLHS(),\
  \ RHS = CondExpr->getRHS().\n    - For each (VarRegion* VR -> Stmt* LoadS) pair\
  \ in SpeculativeLoadMap:\n      - Obtain the VarDecl* VD for VR and its name N.\n\
  \      - Require that:\n        - ExprHasName(RHS, N, C) is true (X appears in RHS),\n\
  \        - ExprHasName(LHS, N, C) is false (X not referenced in the guard),\n  \
  \      - The IfStmt is immediately after the speculative load statement:\n     \
  \     - Use findSpecificTypeInParents<CompoundStmt>(IfS, C) to get the enclosing\
  \ block.\n          - Iterate block\u2019s children to find IfS index i and check\
  \ i > 0 and block[i-1] == LoadS.\n      - If all hold, report a bug at LoadS:\n\
  \        - Message: \u201CUnguarded read before guard; move the read under the \u2018\
  if (guard)\u2019.\u201D\n        - Build a PathSensitiveBugReport or BasicBugReport,\
  \ anchor at LoadS (the dereference) and optionally add a note at IfS.\n      - After\
  \ reporting (or when the condition is handled), erase VR from SpeculativeLoadMap\
  \ to avoid duplicates on the same path.\n\n- checkEndFunction(const ReturnStmt *RS,\
  \ CheckerContext &C)\n  - Clear SpeculativeLoadMap.\n\n3) Helper: analyzeAssignment\n\
  - Signature: bool analyzeAssignment(const VarDecl *VD, const Expr *RHS, const Stmt\
  \ *BindSite, CheckerContext &C)\n- Purpose: Decide whether RHS looks like a speculative\
  \ read of shared state that should be guarded but is not yet guarded.\n- Steps:\n\
  \  - Preconditions on destination:\n    - VD must be a local variable (automatic\
  \ storage) of integral or pointer type.\n  - Recognize a suspicious memory read\
  \ shape on RHS:\n    - Preferred canonical pattern: dereference of a function call\
  \ result:\n      - Find a UnaryOperator U with opcode UO_Deref within RHS using\
  \ findSpecificTypeInChildren<UnaryOperator>(RHS).\n      - Confirm U\u2019s subexpression\
  \ is a CallExpr CE. If not, return false.\n      - Optional macro guard: if ExprHasName(RHS,\
  \ \"READ_ONCE\", C) or ExprHasName(RHS, \"atomic\", C), return false (assumed intentional\
  \ synchronization).\n    - Additionally, filter to likely-shared source:\n     \
  \ - If CE has at least one argument A0, try to classify A0\u2019s region:\n    \
  \    - const MemRegion* R = getMemRegionFromExpr(A0, C).\n        - Accept if R\
  \ is a ParamRegion (argument of the current function) or a VarRegion whose VarDecl\
  \ has global storage (VD->hasGlobalStorage()). If unknown, be conservative and return\
  \ false to limit false positives.\n  - If all checks pass, return true to indicate\
  \ the assignment is a candidate speculative read to be paired with a subsequent\
  \ if(guard && uses(X)).\n\n4) Why this detects the target pattern\n- The checker\
  \ records when a local variable is computed from a dereference of a pointer returned\
  \ by a call tied to a parameter/global (likely shared) and the expression is not\
  \ obviously guarded (i.e., not READ_ONCE()).\n- Immediately afterward, if the next\
  \ statement is an if with top-level \u201CGuard && \u2026\u201D and the right-hand\
  \ side references that just-read local variable, it means the read happened before\
  \ the guard that makes the read safe. Even though the variable may not be used if\
  \ Guard is false, the early read can race (as in the patch).\n- Requiring adjacency\
  \ (assignment directly followed by the if) and the RHS referencing the variable\
  \ minimizes false positives and matches the kernel change.\n\n5) Reporting\n- Use\
  \ generateNonFatalErrorNode and emit via a PathSensitiveBugReport (or BasicBugReport).\n\
  - Short message: \u201CSpeculative unguarded read; move the read under the guard.\u201D\
  \n- Primary location: the dereference assignment statement. Optionally add a note\
  \ pointing to the IfStmt condition to highlight the guard.\n\n6) Notes and limitations\
  \ (intentional for simplicity and precision)\n- Only flags the canonical pattern\
  \ \u201CX = *call(...); if (Guard && uses X) \u2026\u201D with adjacency in the\
  \ same compound block.\n- Requires RHS dereference of a CallExpr and the call argument\
  \ to refer to a function parameter or a global (heuristic for shared state).\n-\
  \ Skips cases using READ_ONCE/atomic-like markers.\n- Clears state at function end;\
  \ state is path-sensitive by design."
refined_plan: null
repaired_checker_code: "#include <memory>\n#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/MemRegion.h\"\
  \n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\n#include \"clang/AST/RecursiveASTVisitor.h\"\
  \n#include \"clang/AST/StmtVisitor.h\"\n#include \"llvm/Support/raw_ostream.h\"\n\
  #include \"clang/StaticAnalyzer/Checkers/utility.h\"\n#include \"clang/AST/ASTContext.h\"\
  \n#include \"clang/AST/Decl.h\"\n#include \"clang/AST/Expr.h\"\n#include \"clang/AST/Stmt.h\"\
  \n#include \"clang/AST/StmtCXX.h\"\n#include \"clang/Basic/SourceManager.h\"\n#include\
  \ \"clang/Lex/Lexer.h\"\n\nusing namespace clang;\nusing namespace ento;\nusing\
  \ namespace taint;\n\n// Map a local VarRegion (the receiver variable) to the statement\
  \ that performed\n// the suspicious speculative load (assignment/init).\nREGISTER_MAP_WITH_PROGRAMSTATE(SpeculativeLoadMap,\
  \ const VarRegion *, const Stmt *)\n\nnamespace {\n\nclass SAGenTestChecker\n  :\
  \ public Checker<\n        check::PostStmt<DeclStmt>,\n        check::Bind,\n  \
  \      check::BranchCondition,\n        check::EndFunction\n      > {\n   mutable\
  \ std::unique_ptr<BugType> BT;\n\npublic:\n  SAGenTestChecker() : BT(new BugType(this,\
  \ \"Speculative unguarded read\", \"Concurrency\")) {}\n\n  void checkPostStmt(const\
  \ DeclStmt *DS, CheckerContext &C) const;\n  void checkBind(SVal Loc, SVal Val,\
  \ const Stmt *S, CheckerContext &C) const;\n  void checkBranchCondition(const Stmt\
  \ *Condition, CheckerContext &C) const;\n  void checkEndFunction(const ReturnStmt\
  \ *RS, CheckerContext &C) const;\n\nprivate:\n  // Returns true if RHS matches the\
  \ suspicious pattern \"*call(args...)\" and\n  // the call's first argument refers\
  \ to a shared location (param/global).\n  bool analyzeAssignment(const VarDecl *VD,\
  \ const Expr *RHS,\n                         const Stmt *BindSite, CheckerContext\
  \ &C) const;\n\n  // Utility: collect local (automatic storage) VarDecls referenced\
  \ in E.\n  void collectLocalVarDeclsInExpr(const Expr *E,\n                    \
  \              llvm::SmallVectorImpl<const VarDecl*> &Out) const;\n\n  // Utility:\
  \ verify destination variable kind is acceptable (local, scalar or pointer).\n \
  \ bool isLocalScalarOrPointerVar(const VarDecl *VD, ASTContext &ACtx) const;\n\n\
  \  // Report diagnostic at the speculative load statement.\n  void reportAtLoad(const\
  \ Stmt *LoadS, const IfStmt *IfS, CheckerContext &C) const;\n\n  // Check if IfS\
  \ is immediately following LoadS inside the same compound block.\n  bool isImmediatelyBefore(const\
  \ Stmt *Prev, const IfStmt *IfS, CheckerContext &C) const;\n};\n\nbool SAGenTestChecker::isLocalScalarOrPointerVar(const\
  \ VarDecl *VD, ASTContext &ACtx) const {\n  if (!VD)\n    return false;\n  if (!VD->hasLocalStorage())\n\
  \    return false;\n  QualType QT = VD->getType();\n  if (QT.isNull())\n    return\
  \ false;\n  return QT->isScalarType() || QT->isPointerType() || QT->isIntegerType();\n\
  }\n\nvoid SAGenTestChecker::collectLocalVarDeclsInExpr(const Expr *E,\n    llvm::SmallVectorImpl<const\
  \ VarDecl*> &Out) const {\n  if (!E) return;\n  struct Walker {\n    static void\
  \ run(const Expr *Node, llvm::SmallVectorImpl<const VarDecl*> &Out) {\n      if\
  \ (!Node) return;\n      if (const auto *DRE = dyn_cast<DeclRefExpr>(Node->IgnoreParenCasts()))\
  \ {\n        if (const auto *VD = dyn_cast<VarDecl>(DRE->getDecl())) {\n       \
  \   if (VD->hasLocalStorage())\n            Out.push_back(VD);\n        }\n    \
  \  }\n      for (const Stmt *Child : Node->children()) {\n        if (const auto\
  \ *CE = dyn_cast_or_null<Expr>(Child))\n          run(CE, Out);\n      }\n    }\n\
  \  };\n  Walker::run(E, Out);\n}\n\nbool SAGenTestChecker::analyzeAssignment(const\
  \ VarDecl *VD, const Expr *RHS,\n                                         const\
  \ Stmt *BindSite, CheckerContext &C) const {\n  if (!VD || !RHS || !BindSite)\n\
  \    return false;\n\n  if (!isLocalScalarOrPointerVar(VD, C.getASTContext()))\n\
  \    return false;\n\n  // Skip if expression explicitly uses READ_ONCE or 'atomic'\
  \ markers.\n  if (ExprHasName(RHS, \"READ_ONCE\", C) || ExprHasName(RHS, \"atomic\"\
  , C))\n    return false;\n\n  // Look for a unary '*' dereference of a call expression.\n\
  \  const UnaryOperator *UO = findSpecificTypeInChildren<UnaryOperator>(RHS);\n \
  \ if (!UO || UO->getOpcode() != UO_Deref)\n    return false;\n\n  const Expr *Sub\
  \ = UO->getSubExpr();\n  if (!Sub)\n    return false;\n  Sub = Sub->IgnoreParenCasts();\n\
  \n  const CallExpr *CE = dyn_cast<CallExpr>(Sub);\n  if (!CE)\n    return false;\n\
  \n  // Heuristic: first argument should refer to a parameter or global storage.\n\
  \  if (CE->getNumArgs() > 0) {\n    const Expr *A0 = CE->getArg(0);\n    if (!A0)\n\
  \      return false;\n\n    const MemRegion *R = getMemRegionFromExpr(A0, C);\n\
  \    if (!R)\n      return false;\n    R = R->getBaseRegion();\n    if (!R)\n  \
  \    return false;\n\n    if (const auto *VR = dyn_cast<VarRegion>(R)) {\n     \
  \ const VarDecl *SrcVD = VR->getDecl();\n      // Accept if it is a function parameter\
  \ or a global.\n      if (const auto *PVD = dyn_cast_or_null<ParmVarDecl>(SrcVD))\
  \ {\n        (void)PVD; // OK - parameter\n      } else if (SrcVD && SrcVD->hasGlobalStorage())\
  \ {\n        // OK - global\n      } else {\n        return false;\n      }\n  \
  \  } else {\n      // Unknown source - be conservative and skip.\n      return false;\n\
  \    }\n  } else {\n    // No arguments - less likely to be shared; be conservative.\n\
  \    return false;\n  }\n\n  return true;\n}\n\nbool SAGenTestChecker::isImmediatelyBefore(const\
  \ Stmt *Prev, const IfStmt *IfS, CheckerContext &C) const {\n  if (!Prev || !IfS)\n\
  \    return false;\n\n  const CompoundStmt *CS = findSpecificTypeInParents<CompoundStmt>(IfS,\
  \ C);\n  if (!CS)\n    return false;\n\n  const Stmt *Last = nullptr;\n  for (const\
  \ Stmt *Child : CS->body()) {\n    if (Child == IfS)\n      return Last == Prev;\n\
  \    Last = Child;\n  }\n  return false;\n}\n\nvoid SAGenTestChecker::reportAtLoad(const\
  \ Stmt *LoadS, const IfStmt *IfS, CheckerContext &C) const {\n  if (!LoadS)\n  \
  \  return;\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n  if (!N)\n    return;\n\
  \n  auto R = std::make_unique<PathSensitiveBugReport>(\n      *BT, \"Speculative\
  \ unguarded read; move the read under the guard\", N);\n  R->addRange(LoadS->getSourceRange());\n\
  \  C.emitReport(std::move(R));\n}\n\nvoid SAGenTestChecker::checkPostStmt(const\
  \ DeclStmt *DS, CheckerContext &C) const {\n  if (!DS)\n    return;\n\n  ProgramStateRef\
  \ State = C.getState();\n  MemRegionManager &MRMgr = C.getSValBuilder().getRegionManager();\n\
  \n  for (const Decl *D : DS->decls()) {\n    const auto *VD = dyn_cast<VarDecl>(D);\n\
  \    if (!VD)\n      continue;\n\n    if (!VD->hasInit())\n      continue;\n\n \
  \   const Expr *Init = VD->getInit();\n    if (!Init)\n      continue;\n\n    if\
  \ (!analyzeAssignment(VD, Init, DS, C))\n      continue;\n\n    const VarRegion\
  \ *VR = MRMgr.getVarRegion(VD, C.getLocationContext());\n    if (!VR)\n      continue;\n\
  \n    State = State->set<SpeculativeLoadMap>(VR, DS);\n  }\n\n  if (State != C.getState())\n\
  \    C.addTransition(State);\n}\n\nvoid SAGenTestChecker::checkBind(SVal Loc, SVal\
  \ Val, const Stmt *S, CheckerContext &C) const {\n  if (!S)\n    return;\n\n  const\
  \ auto *BO = dyn_cast<BinaryOperator>(S);\n  if (!BO || !BO->isAssignmentOp())\n\
  \    return;\n\n  const Expr *LHS = BO->getLHS();\n  const Expr *RHS = BO->getRHS();\n\
  \  if (!LHS || !RHS)\n    return;\n\n  const auto *DRE = dyn_cast<DeclRefExpr>(LHS->IgnoreParenCasts());\n\
  \  if (!DRE)\n    return;\n\n  const auto *VD = dyn_cast<VarDecl>(DRE->getDecl());\n\
  \  if (!VD)\n    return;\n\n  if (!isLocalScalarOrPointerVar(VD, C.getASTContext()))\n\
  \    return;\n\n  if (!analyzeAssignment(VD, RHS, S, C))\n    return;\n\n  ProgramStateRef\
  \ State = C.getState();\n  MemRegionManager &MRMgr = C.getSValBuilder().getRegionManager();\n\
  \  const VarRegion *VR = MRMgr.getVarRegion(VD, C.getLocationContext());\n  if (!VR)\n\
  \    return;\n\n  State = State->set<SpeculativeLoadMap>(VR, S);\n  if (State !=\
  \ C.getState())\n    C.addTransition(State);\n}\n\nvoid SAGenTestChecker::checkBranchCondition(const\
  \ Stmt *Condition, CheckerContext &C) const {\n  if (!Condition)\n    return;\n\n\
  \  const IfStmt *IfS = findSpecificTypeInParents<IfStmt>(Condition, C);\n  if (!IfS)\n\
  \    return;\n\n  const Expr *CondE = IfS->getCond();\n  if (!CondE)\n    return;\n\
  \  CondE = CondE->IgnoreParenCasts();\n\n  const auto *BO = dyn_cast<BinaryOperator>(CondE);\n\
  \  if (!BO || BO->getOpcode() != BO_LAnd)\n    return;\n\n  const Expr *LHS = BO->getLHS();\n\
  \  const Expr *RHS = BO->getRHS();\n  if (!LHS || !RHS)\n    return;\n\n  // Collect\
  \ local variables referenced on RHS.\n  llvm::SmallVector<const VarDecl*, 8> RHSVars;\n\
  \  collectLocalVarDeclsInExpr(RHS, RHSVars);\n\n  if (RHSVars.empty())\n    return;\n\
  \n  ProgramStateRef State = C.getState();\n  MemRegionManager &MRMgr = C.getSValBuilder().getRegionManager();\n\
  \n  for (const VarDecl *VD : RHSVars) {\n    if (!VD)\n      continue;\n\n    const\
  \ VarRegion *VR = MRMgr.getVarRegion(VD, C.getLocationContext());\n    if (!VR)\n\
  \      continue;\n\n    const Stmt *const *LoadSP = State->get<SpeculativeLoadMap>(VR);\n\
  \    if (!LoadSP)\n      continue;\n\n    const Stmt *LoadS = *LoadSP;\n    if (!LoadS)\n\
  \      continue;\n\n    // Ensure the variable is not referenced in the guard (LHS).\n\
  \    if (ExprHasName(LHS, VD->getName(), C))\n      continue;\n\n    // Ensure adjacency:\
  \ the 'if' immediately follows the load statement.\n    if (!isImmediatelyBefore(LoadS,\
  \ IfS, C))\n      continue;\n\n    // Report the issue at the speculative load site.\n\
  \    reportAtLoad(LoadS, IfS, C);\n\n    // Remove the entry to avoid duplicate\
  \ reports.\n    State = State->remove<SpeculativeLoadMap>(VR);\n  }\n\n  if (State\
  \ != C.getState())\n    C.addTransition(State);\n}\n\nvoid SAGenTestChecker::checkEndFunction(const\
  \ ReturnStmt *RS, CheckerContext &C) const {\n  // No explicit clearing is necessary;\
  \ function-local regions die at function exit.\n  // Kept for completeness per plan.\n\
  }\n\n} // end anonymous namespace\n\nextern \"C\" void clang_registerCheckers(CheckerRegistry\
  \ &registry) {\n  registry.addChecker<SAGenTestChecker>(\n      \"custom.SAGenTestChecker\"\
  ,\n      \"Detects speculative unguarded reads before guard checks (e.g., reading\
  \ shared state before testing a guard such as from_cancel)\",\n      \"\");\n}\n\
  \nextern \"C\" const char clang_analyzerAPIVersionString[] =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
tn_score: 1
tp_score: 0
