_base_result_dir: /scratch/chenyuan-data/knighter-dev/result-gpt-5-0814
commit_id: 78ec6f9df6642418411c534683da6133e0962ec7
commit_type: Concurrency
index: 7
initial_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/Expr.h\"\n#include \"clang/AST/Stmt.h\"\n#include \"clang/AST/ASTContext.h\"\
  \n#include \"clang/Lex/Lexer.h\"\n#include \"llvm/ADT/SmallVector.h\"\n\nusing namespace\
  \ clang;\nusing namespace ento;\nusing namespace taint;\n\nREGISTER_SET_WITH_PROGRAMSTATE(PerCpuPtrSet,\
  \ const MemRegion*) // Track per-CPU pointer regions\n\nnamespace {\nclass SAGenTestChecker\
  \ : public Checker<check::Bind, check::PostCall> {\n   // A generic BT (not used\
  \ directly) plus two specific bug types.\n   mutable std::unique_ptr<BugType> BT;\n\
  \   mutable std::unique_ptr<BugType> BT_RMW;\n   mutable std::unique_ptr<BugType>\
  \ BT_Plain;\n\n   public:\n      SAGenTestChecker()\n        : BT(new BugType(this,\
  \ \"Concurrency\", \"Per-CPU data-race (missing READ/WRITE_ONCE)\")),\n        \
  \  BT_RMW(new BugType(this, \"Per-CPU RMW without READ_ONCE/WRITE_ONCE\", \"Concurrency\"\
  )),\n          BT_Plain(new BugType(this, \"Per-CPU plain store without WRITE_ONCE\"\
  , \"Concurrency\")) {}\n\n      void checkBind(SVal Loc, SVal Val, const Stmt *S,\
  \ CheckerContext &C) const;\n      void checkPostCall(const CallEvent &Call, CheckerContext\
  \ &C) const;\n\n   private:\n      // Helpers\n      static bool isPerCpuGetterName(StringRef\
  \ N);\n      static bool sameExpr(const Expr *A, const Expr *B);\n      bool isPerCpuGetterCall(const\
  \ CallExpr *CE, CheckerContext &C) const;\n      bool baseIsPerCpuPtr(const Expr\
  \ *BaseRaw, CheckerContext &C) const;\n      bool isZero(const Expr *E, CheckerContext\
  \ &C) const;\n      bool isWriteOnceContext(const Expr *E, const Stmt *S, CheckerContext\
  \ &C) const;\n\n      void propagatePerCpuAlias(const MemRegion *LHSBaseReg, const\
  \ Expr *RHS, CheckerContext &C, ProgramStateRef &State) const;\n\n      void maybeReportRMWOnPerCpuField(const\
  \ Stmt *S, CheckerContext &C) const;\n      void maybeReportPlainZeroStoreOnPerCpuField(const\
  \ Stmt *S, CheckerContext &C) const;\n\n      void reportRMW(const MemberExpr *ME,\
  \ CheckerContext &C) const;\n      void reportPlainStore(const MemberExpr *ME, CheckerContext\
  \ &C) const;\n};\n\n// ---- Helper implementations ----\n\nbool SAGenTestChecker::isPerCpuGetterName(StringRef\
  \ N) {\n  return N == \"this_cpu_ptr\" ||\n         N == \"per_cpu_ptr\" ||\n  \
  \       N == \"raw_cpu_ptr\" ||\n         N == \"per_cpu_ptr_no_check\" ||\n   \
  \      N == \"get_cpu_ptr\";\n}\n\nbool SAGenTestChecker::sameExpr(const Expr *A,\
  \ const Expr *B) {\n  if (!A || !B) return false;\n  return A->IgnoreParenImpCasts()\
  \ == B->IgnoreParenImpCasts();\n}\n\nbool SAGenTestChecker::isPerCpuGetterCall(const\
  \ CallExpr *CE, CheckerContext &C) const {\n  if (!CE) return false;\n  // Use textual\
  \ matching for robustness with macros/wrappers.\n  return ExprHasName(CE, \"this_cpu_ptr\"\
  , C) ||\n         ExprHasName(CE, \"per_cpu_ptr\", C) ||\n         ExprHasName(CE,\
  \ \"raw_cpu_ptr\", C) ||\n         ExprHasName(CE, \"per_cpu_ptr_no_check\", C)\
  \ ||\n         ExprHasName(CE, \"get_cpu_ptr\", C);\n}\n\nbool SAGenTestChecker::baseIsPerCpuPtr(const\
  \ Expr *BaseRaw, CheckerContext &C) const {\n  if (!BaseRaw) return false;\n\n \
  \ // If the base is a per-cpu getter call, it's per-cpu for sure.\n  if (const auto\
  \ *CE = dyn_cast<CallExpr>(BaseRaw)) {\n    if (isPerCpuGetterCall(CE, C))\n   \
  \   return true;\n  }\n\n  // Otherwise, check whether the region is recorded as\
  \ per-cpu.\n  const MemRegion *MR = getMemRegionFromExpr(BaseRaw, C);\n  if (!MR)\
  \ return false;\n  MR = MR->getBaseRegion();\n  if (!MR) return false;\n\n  ProgramStateRef\
  \ State = C.getState();\n  return State->contains<PerCpuPtrSet>(MR);\n}\n\nbool\
  \ SAGenTestChecker::isZero(const Expr *E, CheckerContext &C) const {\n  if (!E)\
  \ return false;\n  llvm::APSInt Res;\n  if (EvaluateExprToInt(Res, E, C))\n    return\
  \ Res == 0;\n  return false;\n}\n\n// Determine if the write is explicitly wrapped\
  \ by WRITE_ONCE.\n// We check parent CallExpr for \"WRITE_ONCE\", and as a fallback,\
  \ we also\n// check the entire statement source text (BinaryOperator/Expr) for \"\
  WRITE_ONCE\".\nbool SAGenTestChecker::isWriteOnceContext(const Expr *E, const Stmt\
  \ *S, CheckerContext &C) const {\n  if (!E) return false;\n\n  if (const CallExpr\
  \ *ParentCall = findSpecificTypeInParents<CallExpr>(E, C)) {\n    if (ExprHasName(ParentCall,\
  \ \"WRITE_ONCE\", C))\n      return true;\n  }\n\n  if (const Expr *SE = dyn_cast_or_null<Expr>(S))\
  \ {\n    if (ExprHasName(SE, \"WRITE_ONCE\", C))\n      return true;\n  }\n  return\
  \ false;\n}\n\nvoid SAGenTestChecker::propagatePerCpuAlias(const MemRegion *LHSBaseReg,\
  \ const Expr *RHS, CheckerContext &C, ProgramStateRef &State) const {\n  if (!LHSBaseReg\
  \ || !RHS) return;\n\n  // Case 1: RHS is a direct per-cpu getter call.\n  if (const\
  \ auto *CE = dyn_cast<CallExpr>(RHS->IgnoreParenImpCasts())) {\n    if (isPerCpuGetterCall(CE,\
  \ C)) {\n      State = State->add<PerCpuPtrSet>(LHSBaseReg);\n      return;\n  \
  \  }\n  }\n\n  // Case 2: RHS is a reference to another pointer already known as\
  \ per-cpu.\n  if (const MemRegion *RHSReg = getMemRegionFromExpr(RHS, C)) {\n  \
  \  RHSReg = RHSReg->getBaseRegion();\n    if (RHSReg && State->contains<PerCpuPtrSet>(RHSReg))\
  \ {\n      State = State->add<PerCpuPtrSet>(LHSBaseReg);\n      return;\n    }\n\
  \  }\n\n  // Case 3: RHS is a member derived from a per-cpu pointer (e.g., statc->parent).\n\
  \  if (const auto *ME = dyn_cast<MemberExpr>(RHS->IgnoreParenImpCasts())) {\n  \
  \  const Expr *BaseRaw = ME->getBase(); // do not IgnoreImplicit() here for region\
  \ extraction rules\n    if (baseIsPerCpuPtr(BaseRaw, C)) {\n      // Only propagate\
  \ if RHS type is a pointer (alias propagation of pointer value).\n      if (RHS->getType()->isPointerType())\n\
  \        State = State->add<PerCpuPtrSet>(LHSBaseReg);\n      return;\n    }\n \
  \ }\n}\n\n// Inspect the statement for compound assignment or inc/dec on a per-cpu\
  \ field.\nvoid SAGenTestChecker::maybeReportRMWOnPerCpuField(const Stmt *S, CheckerContext\
  \ &C) const {\n  if (!S) return;\n\n  // Find a MemberExpr within S\n  const MemberExpr\
  \ *ME = findSpecificTypeInChildren<MemberExpr>(S);\n  if (!ME) return;\n\n  // Check\
  \ for compound assignment like (field += x) where ME is the LHS\n  if (const auto\
  \ *CAO = findSpecificTypeInParents<CompoundAssignOperator>(ME, C)) {\n    if (sameExpr(CAO->getLHS(),\
  \ ME)) {\n      const Expr *BaseRaw = ME->getBase(); // raw for region extraction\n\
  \      if (baseIsPerCpuPtr(BaseRaw, C)) {\n        reportRMW(ME, C);\n      }\n\
  \      return;\n    }\n  }\n\n  // Check for ++/-- on the field\n  if (const auto\
  \ *UO = findSpecificTypeInParents<UnaryOperator>(ME, C)) {\n    if ((UO->getOpcode()\
  \ == UO_PreInc || UO->getOpcode() == UO_PreDec ||\n         UO->getOpcode() == UO_PostInc\
  \ || UO->getOpcode() == UO_PostDec) &&\n        sameExpr(UO->getSubExpr(), ME))\
  \ {\n      const Expr *BaseRaw = ME->getBase();\n      if (baseIsPerCpuPtr(BaseRaw,\
  \ C)) {\n        reportRMW(ME, C);\n      }\n      return;\n    }\n  }\n}\n\n//\
  \ Inspect for plain assignment \"field = 0\" without WRITE_ONCE.\nvoid SAGenTestChecker::maybeReportPlainZeroStoreOnPerCpuField(const\
  \ Stmt *S, CheckerContext &C) const {\n  if (!S) return;\n  const MemberExpr *ME\
  \ = findSpecificTypeInChildren<MemberExpr>(S);\n  if (!ME) return;\n\n  if (const\
  \ auto *BO = findSpecificTypeInParents<BinaryOperator>(ME, C)) {\n    if (BO->isAssignmentOp()\
  \ && !BO->isCompoundAssignmentOp()) {\n      if (sameExpr(BO->getLHS(), ME)) {\n\
  \        const Expr *RHS = BO->getRHS();\n        if (RHS && isZero(RHS->IgnoreParenImpCasts(),\
  \ C)) {\n          // Check if it's in a WRITE_ONCE context; if yes, do not warn.\n\
  \          if (isWriteOnceContext(ME, S, C))\n            return;\n\n          const\
  \ Expr *BaseRaw = ME->getBase();\n          if (baseIsPerCpuPtr(BaseRaw, C)) {\n\
  \            reportPlainStore(ME, C);\n          }\n        }\n      }\n    }\n\
  \  }\n}\n\nvoid SAGenTestChecker::reportRMW(const MemberExpr *ME, CheckerContext\
  \ &C) const {\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n  if (!N) return;\n\
  \n  auto R = std::make_unique<PathSensitiveBugReport>(\n      *BT_RMW, \"RMW on\
  \ per-CPU field without READ_ONCE/WRITE_ONCE\", N);\n  if (ME)\n    R->addRange(ME->getSourceRange());\n\
  \  C.emitReport(std::move(R));\n}\n\nvoid SAGenTestChecker::reportPlainStore(const\
  \ MemberExpr *ME, CheckerContext &C) const {\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n\
  \  if (!N) return;\n\n  auto R = std::make_unique<PathSensitiveBugReport>(\n   \
  \   *BT_Plain, \"Plain store to per-CPU field; use WRITE_ONCE\", N);\n  if (ME)\n\
  \    R->addRange(ME->getSourceRange());\n  C.emitReport(std::move(R));\n}\n\n//\
  \ ---- Callbacks ----\n\nvoid SAGenTestChecker::checkBind(SVal Loc, SVal Val, const\
  \ Stmt *S, CheckerContext &C) const {\n  ProgramStateRef State = C.getState();\n\
  \n  // 1) Propagate per-CPU pointer aliases.\n  const MemRegion *LHSReg = Loc.getAsRegion();\n\
  \  if (LHSReg)\n    LHSReg = LHSReg->getBaseRegion();\n\n  // If RHS is already\
  \ a known per-cpu pointer region, add LHS as per-cpu.\n  if (LHSReg) {\n    if (const\
  \ MemRegion *RHSReg = Val.getAsRegion()) {\n      RHSReg = RHSReg->getBaseRegion();\n\
  \      if (RHSReg && State->contains<PerCpuPtrSet>(RHSReg)) {\n        State = State->add<PerCpuPtrSet>(LHSReg);\n\
  \      }\n    } else {\n      // Try AST-based deduction: only if S is DeclStmt\
  \ or BinaryOperator assignment.\n      const Expr *RHSExpr = nullptr;\n\n      if\
  \ (const auto *DS = dyn_cast_or_null<DeclStmt>(S)) {\n        for (const Decl *D\
  \ : DS->decls()) {\n          if (const auto *VD = dyn_cast<VarDecl>(D)) {\n   \
  \         if (const Expr *Init = VD->getInit()) {\n              RHSExpr = Init;\n\
  \              // LHSReg already computed from Loc; we also ensure pointer type\
  \ if possible.\n              // If it is a pointer, propagate based on RHS pattern.\n\
  \              if (VD->getType()->isPointerType())\n                propagatePerCpuAlias(LHSReg,\
  \ RHSExpr, C, State);\n            }\n          }\n        }\n      } else if (const\
  \ auto *BO = dyn_cast_or_null<BinaryOperator>(S)) {\n        if (BO->isAssignmentOp())\
  \ {\n          RHSExpr = BO->getRHS();\n          // LHSExpr pointer-type check\
  \ (best effort).\n          const Expr *LHSExpr = BO->getLHS();\n          if (LHSExpr\
  \ && LHSExpr->getType()->isPointerType())\n            propagatePerCpuAlias(LHSReg,\
  \ RHSExpr, C, State);\n        }\n      }\n    }\n  }\n\n  // 2) Detect suspicious\
  \ RMW on per-CPU fields.\n  maybeReportRMWOnPerCpuField(S, C);\n\n  // 3) Detect\
  \ suspicious plain reset to zero on per-CPU fields.\n  maybeReportPlainZeroStoreOnPerCpuField(S,\
  \ C);\n\n  C.addTransition(State);\n}\n\nvoid SAGenTestChecker::checkPostCall(const\
  \ CallEvent &Call, CheckerContext &C) const {\n  ProgramStateRef State = C.getState();\n\
  \  const Expr *Origin = Call.getOriginExpr();\n  if (!Origin) {\n    C.addTransition(State);\n\
  \    return;\n  }\n\n  // Opportunistically tag return value of per-cpu getters.\n\
  \  if (const auto *CE = dyn_cast<CallExpr>(Origin)) {\n    if (isPerCpuGetterCall(CE,\
  \ C)) {\n      if (const MemRegion *MR = Call.getReturnValue().getAsRegion()) {\n\
  \        MR = MR->getBaseRegion();\n        if (MR)\n          State = State->add<PerCpuPtrSet>(MR);\n\
  \      }\n    }\n  }\n\n  C.addTransition(State);\n}\n\n} // end anonymous namespace\n\
  \nextern \"C\" void clang_registerCheckers(CheckerRegistry &registry) {\n  registry.addChecker<SAGenTestChecker>(\n\
  \      \"custom.SAGenTestChecker\",\n      \"Detects plain RMW/reset on per-CPU\
  \ fields without READ_ONCE/WRITE_ONCE\",\n      \"\");\n}\n\nextern \"C\" const\
  \ char clang_analyzerAPIVersionString[] =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
patch: "## Patch Description\n\nmemcg: fix data-race KCSAN bug in rstats\n\nA data-race\
  \ issue in memcg rstat occurs when two distinct code paths\naccess the same 4-byte\
  \ region concurrently.  KCSAN detection triggers the\nfollowing BUG as a result.\n\
  \n\tBUG: KCSAN: data-race in __count_memcg_events / mem_cgroup_css_rstat_flush\n\
  \n\twrite to 0xffffe8ffff98e300 of 4 bytes by task 5274 on cpu 17:\n\tmem_cgroup_css_rstat_flush\
  \ (mm/memcontrol.c:5850)\n\tcgroup_rstat_flush_locked (kernel/cgroup/rstat.c:243\
  \ (discriminator 7))\n\tcgroup_rstat_flush (./include/linux/spinlock.h:401 kernel/cgroup/rstat.c:278)\n\
  \tmem_cgroup_flush_stats.part.0 (mm/memcontrol.c:767)\n\tmemory_numa_stat_show (mm/memcontrol.c:6911)\n\
  <snip>\n\n\tread to 0xffffe8ffff98e300 of 4 bytes by task 410848 on cpu 27:\n\t\
  __count_memcg_events (mm/memcontrol.c:725 mm/memcontrol.c:962)\n\tcount_memcg_event_mm.part.0\
  \ (./include/linux/memcontrol.h:1097 ./include/linux/memcontrol.h:1120)\n\thandle_mm_fault\
  \ (mm/memory.c:5483 mm/memory.c:5622)\n<snip>\n\n\tvalue changed: 0x00000029 ->\
  \ 0x00000000\n\nThe race occurs because two code paths access the same \"stats_updates\"\
  \nlocation.  Although \"stats_updates\" is a per-CPU variable, it is remotely\n\
  accessed by another CPU at\ncgroup_rstat_flush_locked()->mem_cgroup_css_rstat_flush(),\
  \ leading to the\ndata race mentioned.\n\nConsidering that memcg_rstat_updated()\
  \ is in the hot code path, adding a\nlock to protect it may not be desirable, especially\
  \ since this variable\npertains solely to statistics.\n\nTherefore, annotating accesses\
  \ to stats_updates with READ/WRITE_ONCE() can\nprevent KCSAN splats and potential\
  \ partial reads/writes.\n\nLink: https://lkml.kernel.org/r/20240424125940.2410718-1-leitao@debian.org\n\
  Fixes: 9cee7e8ef3e3 (\"mm: memcg: optimize parent iteration in memcg_rstat_updated()\"\
  )\nSigned-off-by: Breno Leitao <leitao@debian.org>\nSuggested-by: Shakeel Butt <shakeel.butt@linux.dev>\n\
  Acked-by: Johannes Weiner <hannes@cmpxchg.org>\nAcked-by: Shakeel Butt <shakeel.butt@linux.dev>\n\
  Reviewed-by: Yosry Ahmed <yosryahmed@google.com>\nCc: Michal Hocko <mhocko@suse.com>\n\
  Cc: Roman Gushchin <roman.gushchin@linux.dev>\nCc: Muchun Song <songmuchun@bytedance.com>\n\
  Signed-off-by: Andrew Morton <akpm@linux-foundation.org>\n\n## Buggy Code\n\n```c\n\
  // Function: memcg_rstat_updated in mm/memcontrol.c\nstatic inline void memcg_rstat_updated(struct\
  \ mem_cgroup *memcg, int val)\n{\n\tstruct memcg_vmstats_percpu *statc;\n\tint cpu\
  \ = smp_processor_id();\n\n\tif (!val)\n\t\treturn;\n\n\tcgroup_rstat_updated(memcg->css.cgroup,\
  \ cpu);\n\tstatc = this_cpu_ptr(memcg->vmstats_percpu);\n\tfor (; statc; statc =\
  \ statc->parent) {\n\t\tstatc->stats_updates += abs(val);\n\t\tif (statc->stats_updates\
  \ < MEMCG_CHARGE_BATCH)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If @memcg is already\
  \ flush-able, increasing stats_updates is\n\t\t * redundant. Avoid the overhead\
  \ of the atomic update.\n\t\t */\n\t\tif (!memcg_vmstats_needs_flush(statc->vmstats))\n\
  \t\t\tatomic64_add(statc->stats_updates,\n\t\t\t\t     &statc->vmstats->stats_updates);\n\
  \t\tstatc->stats_updates = 0;\n\t}\n}\n```\n\n```c\n// Function: mem_cgroup_css_rstat_flush\
  \ in mm/memcontrol.c\nstatic void mem_cgroup_css_rstat_flush(struct cgroup_subsys_state\
  \ *css, int cpu)\n{\n\tstruct mem_cgroup *memcg = mem_cgroup_from_css(css);\n\t\
  struct mem_cgroup *parent = parent_mem_cgroup(memcg);\n\tstruct memcg_vmstats_percpu\
  \ *statc;\n\tlong delta, delta_cpu, v;\n\tint i, nid;\n\n\tstatc = per_cpu_ptr(memcg->vmstats_percpu,\
  \ cpu);\n\n\tfor (i = 0; i < MEMCG_NR_STAT; i++) {\n\t\t/*\n\t\t * Collect the aggregated\
  \ propagation counts of groups\n\t\t * below us. We're in a per-cpu loop here and\
  \ this is\n\t\t * a global counter, so the first cycle will get them.\n\t\t */\n\
  \t\tdelta = memcg->vmstats->state_pending[i];\n\t\tif (delta)\n\t\t\tmemcg->vmstats->state_pending[i]\
  \ = 0;\n\n\t\t/* Add CPU changes on this level since the last flush */\n\t\tdelta_cpu\
  \ = 0;\n\t\tv = READ_ONCE(statc->state[i]);\n\t\tif (v != statc->state_prev[i])\
  \ {\n\t\t\tdelta_cpu = v - statc->state_prev[i];\n\t\t\tdelta += delta_cpu;\n\t\t\
  \tstatc->state_prev[i] = v;\n\t\t}\n\n\t\t/* Aggregate counts on this level and\
  \ propagate upwards */\n\t\tif (delta_cpu)\n\t\t\tmemcg->vmstats->state_local[i]\
  \ += delta_cpu;\n\n\t\tif (delta) {\n\t\t\tmemcg->vmstats->state[i] += delta;\n\t\
  \t\tif (parent)\n\t\t\t\tparent->vmstats->state_pending[i] += delta;\n\t\t}\n\t\
  }\n\n\tfor (i = 0; i < NR_MEMCG_EVENTS; i++) {\n\t\tdelta = memcg->vmstats->events_pending[i];\n\
  \t\tif (delta)\n\t\t\tmemcg->vmstats->events_pending[i] = 0;\n\n\t\tdelta_cpu =\
  \ 0;\n\t\tv = READ_ONCE(statc->events[i]);\n\t\tif (v != statc->events_prev[i])\
  \ {\n\t\t\tdelta_cpu = v - statc->events_prev[i];\n\t\t\tdelta += delta_cpu;\n\t\
  \t\tstatc->events_prev[i] = v;\n\t\t}\n\n\t\tif (delta_cpu)\n\t\t\tmemcg->vmstats->events_local[i]\
  \ += delta_cpu;\n\n\t\tif (delta) {\n\t\t\tmemcg->vmstats->events[i] += delta;\n\
  \t\t\tif (parent)\n\t\t\t\tparent->vmstats->events_pending[i] += delta;\n\t\t}\n\
  \t}\n\n\tfor_each_node_state(nid, N_MEMORY) {\n\t\tstruct mem_cgroup_per_node *pn\
  \ = memcg->nodeinfo[nid];\n\t\tstruct mem_cgroup_per_node *ppn = NULL;\n\t\tstruct\
  \ lruvec_stats_percpu *lstatc;\n\n\t\tif (parent)\n\t\t\tppn = parent->nodeinfo[nid];\n\
  \n\t\tlstatc = per_cpu_ptr(pn->lruvec_stats_percpu, cpu);\n\n\t\tfor (i = 0; i <\
  \ NR_VM_NODE_STAT_ITEMS; i++) {\n\t\t\tdelta = pn->lruvec_stats.state_pending[i];\n\
  \t\t\tif (delta)\n\t\t\t\tpn->lruvec_stats.state_pending[i] = 0;\n\n\t\t\tdelta_cpu\
  \ = 0;\n\t\t\tv = READ_ONCE(lstatc->state[i]);\n\t\t\tif (v != lstatc->state_prev[i])\
  \ {\n\t\t\t\tdelta_cpu = v - lstatc->state_prev[i];\n\t\t\t\tdelta += delta_cpu;\n\
  \t\t\t\tlstatc->state_prev[i] = v;\n\t\t\t}\n\n\t\t\tif (delta_cpu)\n\t\t\t\tpn->lruvec_stats.state_local[i]\
  \ += delta_cpu;\n\n\t\t\tif (delta) {\n\t\t\t\tpn->lruvec_stats.state[i] += delta;\n\
  \t\t\t\tif (ppn)\n\t\t\t\t\tppn->lruvec_stats.state_pending[i] += delta;\n\t\t\t\
  }\n\t\t}\n\t}\n\tstatc->stats_updates = 0;\n\t/* We are in a per-cpu loop here,\
  \ only do the atomic write once */\n\tif (atomic64_read(&memcg->vmstats->stats_updates))\n\
  \t\tatomic64_set(&memcg->vmstats->stats_updates, 0);\n}\n```\n\n## Bug Fix Patch\n\
  \n```diff\ndiff --git a/mm/memcontrol.c b/mm/memcontrol.c\nindex 9095ab05d47a..a111e0d981ba\
  \ 100644\n--- a/mm/memcontrol.c\n+++ b/mm/memcontrol.c\n@@ -715,6 +715,7 @@ static\
  \ inline void memcg_rstat_updated(struct mem_cgroup *memcg, int val)\n {\n \tstruct\
  \ memcg_vmstats_percpu *statc;\n \tint cpu = smp_processor_id();\n+\tunsigned int\
  \ stats_updates;\n \n \tif (!val)\n \t\treturn;\n@@ -722,8 +723,9 @@ static inline\
  \ void memcg_rstat_updated(struct mem_cgroup *memcg, int val)\n \tcgroup_rstat_updated(memcg->css.cgroup,\
  \ cpu);\n \tstatc = this_cpu_ptr(memcg->vmstats_percpu);\n \tfor (; statc; statc\
  \ = statc->parent) {\n-\t\tstatc->stats_updates += abs(val);\n-\t\tif (statc->stats_updates\
  \ < MEMCG_CHARGE_BATCH)\n+\t\tstats_updates = READ_ONCE(statc->stats_updates) +\
  \ abs(val);\n+\t\tWRITE_ONCE(statc->stats_updates, stats_updates);\n+\t\tif (stats_updates\
  \ < MEMCG_CHARGE_BATCH)\n \t\t\tcontinue;\n \n \t\t/*\n@@ -731,9 +733,9 @@ static\
  \ inline void memcg_rstat_updated(struct mem_cgroup *memcg, int val)\n \t\t * redundant.\
  \ Avoid the overhead of the atomic update.\n \t\t */\n \t\tif (!memcg_vmstats_needs_flush(statc->vmstats))\n\
  -\t\t\tatomic64_add(statc->stats_updates,\n+\t\t\tatomic64_add(stats_updates,\n\
  \ \t\t\t\t     &statc->vmstats->stats_updates);\n-\t\tstatc->stats_updates = 0;\n\
  +\t\tWRITE_ONCE(statc->stats_updates, 0);\n \t}\n }\n \n@@ -5887,7 +5889,7 @@ static\
  \ void mem_cgroup_css_rstat_flush(struct cgroup_subsys_state *css, int cpu)\n \t\
  \t\t}\n \t\t}\n \t}\n-\tstatc->stats_updates = 0;\n+\tWRITE_ONCE(statc->stats_updates,\
  \ 0);\n \t/* We are in a per-cpu loop here, only do the atomic write once */\n \t\
  if (atomic64_read(&memcg->vmstats->stats_updates))\n \t\tatomic64_set(&memcg->vmstats->stats_updates,\
  \ 0);\n```\n"
pattern: "## Bug Pattern\n\nUpdating and resetting a per-CPU field with plain, non-atomic\
  \ reads/writes while it is also accessed from another CPU. Concretely:\n- A per-CPU\
  \ counter (e.g., statc->stats_updates) is modified via plain read-modify-write (+=)\
  \ and reset via plain store (= 0).\n- Another CPU concurrently reads/resets the\
  \ same field during a flush path.\n- Because the per-CPU variable is remotely accessed,\
  \ using plain loads/stores causes a data race (and possible torn/lost updates).\n\
  \nPattern indicator:\n- Per-CPU variable accessed on CPU X via RMW without locks/atomics:\n\
  \  statc->stats_updates += delta;\n- Concurrent remote access on CPU Y:\n  statc->stats_updates\
  \ = 0;\n\nFix involves using READ_ONCE/WRITE_ONCE (or atomics) for all cross-CPU\
  \ accesses to the per-CPU field."
plan: "Plan\n\n1. Program state customization\n- REGISTER_SET_WITH_PROGRAMSTATE(PerCpuPtrSet,\
  \ const MemRegion*)\n  - Purpose: Track pointer-valued MemRegions that are known\
  \ per-CPU pointers (returned from this_cpu_ptr/per_cpu_ptr or derived/aliased from\
  \ them).\n\n2. Helper predicates and utilities\n- isPerCpuGetter(CallExpr/CallEvent):\n\
  \  - Return true when the callee name is one of: \"this_cpu_ptr\", \"per_cpu_ptr\"\
  , \"raw_cpu_ptr\", \"per_cpu_ptr_no_check\", \"get_cpu_ptr\".\n- isWriteOnceContext(const\
  \ Expr *E, CheckerContext &C):\n  - Find parent CallExpr via findSpecificTypeInParents<CallExpr>(E,\
  \ C).\n  - Return true if ExprHasName(ParentCallExpr, \"WRITE_ONCE\", C) is true.\n\
  - baseIsPerCpuPtr(const Expr *Base, CheckerContext &C):\n  - If Base is a CallExpr\
  \ and isPerCpuGetter(CallExpr) -> true.\n  - Else, get MemRegion of Base via getMemRegionFromExpr(Base,\
  \ C) and check if it exists in PerCpuPtrSet.\n- isZero(const Expr *E, CheckerContext\
  \ &C):\n  - Use EvaluateExprToInt to see if it evaluates to integer zero.\n\n3.\
  \ Callbacks and their logic\n\nA) checkBind(SVal Loc, SVal Val, const Stmt *S, CheckerContext\
  \ &C) const\n- Goal 1: Propagate per-CPU pointer aliases.\n  - Determine LHS region:\
  \ const MemRegion *LHSReg = Loc.getAsRegion().\n  - If LHSReg is null, return.\n\
  \  - If Val is a region SVal and ValReg \u2208 PerCpuPtrSet, then add LHSReg to\
  \ PerCpuPtrSet.\n  - Else, try to discover RHS patterns from AST:\n    - If S is\
  \ a DeclStmt with an initializer, or a BinaryOperator with isAssignmentOp, get the\
  \ RHS Expr RE.\n    - If RE contains a CallExpr CE (use findSpecificTypeInChildren<CallExpr>(S))\
  \ and isPerCpuGetter(CE):\n      - Mark LHSReg \u2208 PerCpuPtrSet (LHS type should\
  \ be a pointer).\n    - Else if RE is a DeclRefExpr or MemberExpr whose base region\
  \ (for MemberExpr: ME->getBase()) is in PerCpuPtrSet and RE\u2019s type is a pointer:\n\
  \      - Mark LHSReg \u2208 PerCpuPtrSet.\n    - This covers cases like \u201Cp\
  \ = this_cpu_ptr(...);\u201D and \u201Cstatc = statc->parent;\u201D.\n- Goal 2:\
  \ Detect suspicious RMW on per-CPU fields (+=, -=, ++, --).\n  - From S, find a\
  \ MemberExpr ME that is being written (use findSpecificTypeInChildren<MemberExpr>(S)).\n\
  \  - Validate ME is the LHS:\n    - Find ancestor CompoundAssignOperator CAO = findSpecificTypeInParents<CompoundAssignOperator>(ME,\
  \ C). If CAO and CAO->getLHS()->IgnoreParenImpCasts() == ME->IgnoreParenImpCasts():\n\
  \      - Let Base = ME->getBase()->IgnoreParenImpCasts().\n      - If baseIsPerCpuPtr(Base,\
  \ C) is true:\n        - Report bug: \"RMW on per-CPU field without READ_ONCE/WRITE_ONCE\"\
  .\n    - Else, handle increment/decrement:\n      - Find ancestor UnaryOperator\
  \ UO = findSpecificTypeInParents<UnaryOperator>(ME, C).\n      - If UO exists and\
  \ UO is one of pre/post inc/dec, and UO->getSubExpr()->IgnoreParenImpCasts() ==\
  \ ME->IgnoreParenImpCasts():\n        - If baseIsPerCpuPtr(Base, C) is true:\n \
  \         - Report bug: \"RMW on per-CPU field without READ_ONCE/WRITE_ONCE\".\n\
  - Goal 3: Detect suspicious plain reset to zero on per-CPU fields.\n  - From S,\
  \ find BinaryOperator BO = findSpecificTypeInParents<BinaryOperator>(ME, C).\n \
  \ - If BO exists, BO->isAssignmentOp() is true, and BO is not a compound assignment:\n\
  \    - If BO->getLHS()->IgnoreParenImpCasts() == ME->IgnoreParenImpCasts():\n  \
  \    - Let RHS = BO->getRHS()->IgnoreParenImpCasts().\n      - If isZero(RHS, C)\
  \ is true and isWriteOnceContext(ME, C) is false:\n        - Let Base = ME->getBase()->IgnoreParenImpCasts().\n\
  \        - If baseIsPerCpuPtr(Base, C) is true:\n          - Report bug: \"Plain\
  \ store to per-CPU field; use WRITE_ONCE\".\n\nNotes:\n- The compound assignment\
  \ path (Goal 2) intentionally flags any per-CPU field \"+=\", \"-=\", \"++\", \"\
  --\" as unsafe RMW. This matches the target pattern, where the fix is to split into\
  \ READ_ONCE + compute + WRITE_ONCE.\n- The plain reset path (Goal 3) flags \"field\
  \ = 0\" on per-CPU fields unless wrapped by WRITE_ONCE.\n- For macros READ_ONCE/WRITE_ONCE,\
  \ use ExprHasName on the parent CallExpr to suppress false positives. This is robust\
  \ enough for the Linux-style macros.\n\nB) Optional: checkPostCall(const CallEvent\
  \ &Call, CheckerContext &C) const\n- Not necessary for detection, but can be used\
  \ to opportunistically tag temporary expressions as per-CPU pointers if they are\
  \ immediately used:\n  - If Call callee name matches isPerCpuGetter and the return\
  \ value is bound to a MemRegion (rare), mark that region in PerCpuPtrSet.\n- This\
  \ is optional because checkBind already propagates from assignments and handles\
  \ bases that are calls in LHS MemberExpr.\n\n4. Bug reporting\n- Maintain two BugType\
  \ singletons:\n  - BT_RMW: \"Per-CPU RMW without READ_ONCE/WRITE_ONCE\"\n  - BT_PlainStore:\
  \ \"Per-CPU plain store without WRITE_ONCE\"\n- When a violation is found:\n  -\
  \ auto N = C.generateNonFatalErrorNode(); if (!N) return;\n  - Create PathSensitiveBugReport\
  \ with the specific BugType.\n  - Message:\n    - For RMW: \"RMW on per-CPU field\
  \ without READ_ONCE/WRITE_ONCE\"\n    - For plain zero store: \"Plain store to per-CPU\
  \ field; use WRITE_ONCE\"\n  - Highlight the MemberExpr source range.\n  - Emit\
  \ the report.\n\n5. Coverage of the target pattern in the patch\n- In memcg_rstat_updated:\n\
  \  - Detect \"statc->stats_updates += abs(val)\" as RMW on per-CPU field \u2192\
  \ report.\n  - Detect \"statc->stats_updates = 0\" as plain store \u2192 report\
  \ unless wrapped in WRITE_ONCE.\n- In mem_cgroup_css_rstat_flush:\n  - Detect \"\
  statc->stats_updates = 0\" as plain store \u2192 report unless wrapped in WRITE_ONCE.\n\
  - The checker recognizes 'statc' as per-CPU pointer via:\n  - \"statc = this_cpu_ptr(...)\"\
  \ assignment in memcg_rstat_updated.\n  - \"statc = per_cpu_ptr(..., cpu)\" assignment\
  \ in mem_cgroup_css_rstat_flush.\n  - Propagates per-CPU property across \"statc\
  \ = statc->parent\".\n\n6. Simplifications and robustness choices\n- We do not attempt\
  \ to prove cross-CPU remote access; we conservatively consider any per-CPU pointer\
  \ field update as potentially racy if it uses plain RMW/reset.\n- We rely on ExprHasName\
  \ to detect READ_ONCE/WRITE_ONCE wrappers via parent CallExpr textual name matches.\n\
  - We use EvaluateExprToInt to robustly recognize RHS literal zero in resets.\n-\
  \ We use findSpecificTypeInParents/Children to tie the MemberExpr to the correct\
  \ operator node for accurate classification."
refined_plan: null
repaired_checker_code: "#include \"clang/StaticAnalyzer/Core/BugReporter/BugReporter.h\"\
  \n#include \"clang/StaticAnalyzer/Core/BugReporter/BugType.h\"\n#include \"clang/StaticAnalyzer/Checkers/Taint.h\"\
  \n#include \"clang/StaticAnalyzer/Core/Checker.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/CallEvent.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/CheckerContext.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/Environment.h\"\n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramState.h\"\
  \n#include \"clang/StaticAnalyzer/Core/PathSensitive/ProgramStateTrait.h\"\n#include\
  \ \"clang/StaticAnalyzer/Core/PathSensitive/SymExpr.h\"\n#include \"clang/StaticAnalyzer/Frontend/CheckerRegistry.h\"\
  \n#include \"clang/AST/RecursiveASTVisitor.h\"\n#include \"clang/AST/StmtVisitor.h\"\
  \n#include \"llvm/Support/raw_ostream.h\"\n#include \"clang/StaticAnalyzer/Checkers/utility.h\"\
  \n#include \"clang/AST/Expr.h\"\n#include \"clang/AST/Stmt.h\"\n#include \"clang/AST/ASTContext.h\"\
  \n#include \"clang/Lex/Lexer.h\"\n#include \"llvm/ADT/SmallVector.h\"\n\nusing namespace\
  \ clang;\nusing namespace ento;\nusing namespace taint;\n\nREGISTER_SET_WITH_PROGRAMSTATE(PerCpuPtrSet,\
  \ const MemRegion*) // Track per-CPU pointer regions\n\nnamespace {\nclass SAGenTestChecker\
  \ : public Checker<check::Bind, check::PostCall> {\n   // A generic BT (not used\
  \ directly) plus two specific bug types.\n   mutable std::unique_ptr<BugType> BT;\n\
  \   mutable std::unique_ptr<BugType> BT_RMW;\n   mutable std::unique_ptr<BugType>\
  \ BT_Plain;\n\n   public:\n      SAGenTestChecker()\n        : BT(new BugType(this,\
  \ \"Concurrency\", \"Per-CPU data-race (missing READ/WRITE_ONCE)\")),\n        \
  \  BT_RMW(new BugType(this, \"Per-CPU RMW without READ_ONCE/WRITE_ONCE\", \"Concurrency\"\
  )),\n          BT_Plain(new BugType(this, \"Per-CPU plain store without WRITE_ONCE\"\
  , \"Concurrency\")) {}\n\n      void checkBind(SVal Loc, SVal Val, const Stmt *S,\
  \ CheckerContext &C) const;\n      void checkPostCall(const CallEvent &Call, CheckerContext\
  \ &C) const;\n\n   private:\n      // Helpers\n      static bool isPerCpuGetterName(StringRef\
  \ N);\n      static bool sameExpr(const Expr *A, const Expr *B);\n      bool isPerCpuGetterCall(const\
  \ CallExpr *CE, CheckerContext &C) const;\n      bool baseIsPerCpuPtr(const Expr\
  \ *BaseRaw, CheckerContext &C) const;\n      bool isZero(const Expr *E, CheckerContext\
  \ &C) const;\n      bool isWriteOnceContext(const Expr *E, const Stmt *S, CheckerContext\
  \ &C) const;\n\n      void propagatePerCpuAlias(const MemRegion *LHSBaseReg, const\
  \ Expr *RHS, CheckerContext &C, ProgramStateRef &State) const;\n\n      void maybeReportRMWOnPerCpuField(const\
  \ Stmt *S, CheckerContext &C) const;\n      void maybeReportPlainZeroStoreOnPerCpuField(const\
  \ Stmt *S, CheckerContext &C) const;\n\n      void reportRMW(const MemberExpr *ME,\
  \ CheckerContext &C) const;\n      void reportPlainStore(const MemberExpr *ME, CheckerContext\
  \ &C) const;\n};\n\n// ---- Helper implementations ----\n\nbool SAGenTestChecker::isPerCpuGetterName(StringRef\
  \ N) {\n  return N == \"this_cpu_ptr\" ||\n         N == \"per_cpu_ptr\" ||\n  \
  \       N == \"raw_cpu_ptr\" ||\n         N == \"per_cpu_ptr_no_check\" ||\n   \
  \      N == \"get_cpu_ptr\";\n}\n\nbool SAGenTestChecker::sameExpr(const Expr *A,\
  \ const Expr *B) {\n  if (!A || !B) return false;\n  return A->IgnoreParenImpCasts()\
  \ == B->IgnoreParenImpCasts();\n}\n\nbool SAGenTestChecker::isPerCpuGetterCall(const\
  \ CallExpr *CE, CheckerContext &C) const {\n  if (!CE) return false;\n  // Use textual\
  \ matching for robustness with macros/wrappers.\n  return ExprHasName(CE, \"this_cpu_ptr\"\
  , C) ||\n         ExprHasName(CE, \"per_cpu_ptr\", C) ||\n         ExprHasName(CE,\
  \ \"raw_cpu_ptr\", C) ||\n         ExprHasName(CE, \"per_cpu_ptr_no_check\", C)\
  \ ||\n         ExprHasName(CE, \"get_cpu_ptr\", C);\n}\n\nbool SAGenTestChecker::baseIsPerCpuPtr(const\
  \ Expr *BaseRaw, CheckerContext &C) const {\n  if (!BaseRaw) return false;\n\n \
  \ // If the base is a per-cpu getter call, it's per-cpu for sure.\n  if (const auto\
  \ *CE = dyn_cast<CallExpr>(BaseRaw)) {\n    if (isPerCpuGetterCall(CE, C))\n   \
  \   return true;\n  }\n\n  // Otherwise, check whether the region is recorded as\
  \ per-cpu.\n  const MemRegion *MR = getMemRegionFromExpr(BaseRaw, C);\n  if (!MR)\
  \ return false;\n  MR = MR->getBaseRegion();\n  if (!MR) return false;\n\n  ProgramStateRef\
  \ State = C.getState();\n  return State->contains<PerCpuPtrSet>(MR);\n}\n\nbool\
  \ SAGenTestChecker::isZero(const Expr *E, CheckerContext &C) const {\n  if (!E)\
  \ return false;\n  llvm::APSInt Res;\n  if (EvaluateExprToInt(Res, E, C))\n    return\
  \ Res == 0;\n  return false;\n}\n\n// Determine if the write is explicitly wrapped\
  \ by WRITE_ONCE.\n// We check parent CallExpr for \"WRITE_ONCE\", and as a fallback,\
  \ we also\n// check the entire statement source text (BinaryOperator/Expr) for \"\
  WRITE_ONCE\".\nbool SAGenTestChecker::isWriteOnceContext(const Expr *E, const Stmt\
  \ *S, CheckerContext &C) const {\n  if (!E) return false;\n\n  if (const CallExpr\
  \ *ParentCall = findSpecificTypeInParents<CallExpr>(E, C)) {\n    if (ExprHasName(ParentCall,\
  \ \"WRITE_ONCE\", C))\n      return true;\n  }\n\n  if (const Expr *SE = dyn_cast_or_null<Expr>(S))\
  \ {\n    if (ExprHasName(SE, \"WRITE_ONCE\", C))\n      return true;\n  }\n  return\
  \ false;\n}\n\nvoid SAGenTestChecker::propagatePerCpuAlias(const MemRegion *LHSBaseReg,\
  \ const Expr *RHS, CheckerContext &C, ProgramStateRef &State) const {\n  if (!LHSBaseReg\
  \ || !RHS) return;\n\n  // Case 1: RHS is a direct per-cpu getter call.\n  if (const\
  \ auto *CE = dyn_cast<CallExpr>(RHS->IgnoreParenImpCasts())) {\n    if (isPerCpuGetterCall(CE,\
  \ C)) {\n      State = State->add<PerCpuPtrSet>(LHSBaseReg);\n      return;\n  \
  \  }\n  }\n\n  // Case 2: RHS is a reference to another pointer already known as\
  \ per-cpu.\n  if (const MemRegion *RHSReg = getMemRegionFromExpr(RHS, C)) {\n  \
  \  RHSReg = RHSReg->getBaseRegion();\n    if (RHSReg && State->contains<PerCpuPtrSet>(RHSReg))\
  \ {\n      State = State->add<PerCpuPtrSet>(LHSBaseReg);\n      return;\n    }\n\
  \  }\n\n  // Case 3: RHS is a member derived from a per-cpu pointer (e.g., statc->parent).\n\
  \  if (const auto *ME = dyn_cast<MemberExpr>(RHS->IgnoreParenImpCasts())) {\n  \
  \  const Expr *BaseRaw = ME->getBase(); // do not IgnoreImplicit() here for region\
  \ extraction rules\n    if (baseIsPerCpuPtr(BaseRaw, C)) {\n      // Only propagate\
  \ if RHS type is a pointer (alias propagation of pointer value).\n      if (RHS->getType()->isPointerType())\n\
  \        State = State->add<PerCpuPtrSet>(LHSBaseReg);\n      return;\n    }\n \
  \ }\n}\n\n// Inspect the statement for compound assignment or inc/dec on a per-cpu\
  \ field.\nvoid SAGenTestChecker::maybeReportRMWOnPerCpuField(const Stmt *S, CheckerContext\
  \ &C) const {\n  if (!S) return;\n\n  // Find a MemberExpr within S\n  const MemberExpr\
  \ *ME = findSpecificTypeInChildren<MemberExpr>(S);\n  if (!ME) return;\n\n  // Check\
  \ for compound assignment like (field += x) where ME is the LHS\n  if (const auto\
  \ *CAO = findSpecificTypeInParents<CompoundAssignOperator>(ME, C)) {\n    if (sameExpr(CAO->getLHS(),\
  \ ME)) {\n      const Expr *BaseRaw = ME->getBase(); // raw for region extraction\n\
  \      if (baseIsPerCpuPtr(BaseRaw, C)) {\n        reportRMW(ME, C);\n      }\n\
  \      return;\n    }\n  }\n\n  // Check for ++/-- on the field\n  if (const auto\
  \ *UO = findSpecificTypeInParents<UnaryOperator>(ME, C)) {\n    if ((UO->getOpcode()\
  \ == UO_PreInc || UO->getOpcode() == UO_PreDec ||\n         UO->getOpcode() == UO_PostInc\
  \ || UO->getOpcode() == UO_PostDec) &&\n        sameExpr(UO->getSubExpr(), ME))\
  \ {\n      const Expr *BaseRaw = ME->getBase();\n      if (baseIsPerCpuPtr(BaseRaw,\
  \ C)) {\n        reportRMW(ME, C);\n      }\n      return;\n    }\n  }\n}\n\n//\
  \ Inspect for plain assignment \"field = 0\" without WRITE_ONCE.\nvoid SAGenTestChecker::maybeReportPlainZeroStoreOnPerCpuField(const\
  \ Stmt *S, CheckerContext &C) const {\n  if (!S) return;\n  const MemberExpr *ME\
  \ = findSpecificTypeInChildren<MemberExpr>(S);\n  if (!ME) return;\n\n  if (const\
  \ auto *BO = findSpecificTypeInParents<BinaryOperator>(ME, C)) {\n    if (BO->isAssignmentOp()\
  \ && !BO->isCompoundAssignmentOp()) {\n      if (sameExpr(BO->getLHS(), ME)) {\n\
  \        const Expr *RHS = BO->getRHS();\n        if (RHS && isZero(RHS->IgnoreParenImpCasts(),\
  \ C)) {\n          // Check if it's in a WRITE_ONCE context; if yes, do not warn.\n\
  \          if (isWriteOnceContext(ME, S, C))\n            return;\n\n          const\
  \ Expr *BaseRaw = ME->getBase();\n          if (baseIsPerCpuPtr(BaseRaw, C)) {\n\
  \            reportPlainStore(ME, C);\n          }\n        }\n      }\n    }\n\
  \  }\n}\n\nvoid SAGenTestChecker::reportRMW(const MemberExpr *ME, CheckerContext\
  \ &C) const {\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n  if (!N) return;\n\
  \n  auto R = std::make_unique<PathSensitiveBugReport>(\n      *BT_RMW, \"RMW on\
  \ per-CPU field without READ_ONCE/WRITE_ONCE\", N);\n  if (ME)\n    R->addRange(ME->getSourceRange());\n\
  \  C.emitReport(std::move(R));\n}\n\nvoid SAGenTestChecker::reportPlainStore(const\
  \ MemberExpr *ME, CheckerContext &C) const {\n  ExplodedNode *N = C.generateNonFatalErrorNode();\n\
  \  if (!N) return;\n\n  auto R = std::make_unique<PathSensitiveBugReport>(\n   \
  \   *BT_Plain, \"Plain store to per-CPU field; use WRITE_ONCE\", N);\n  if (ME)\n\
  \    R->addRange(ME->getSourceRange());\n  C.emitReport(std::move(R));\n}\n\n//\
  \ ---- Callbacks ----\n\nvoid SAGenTestChecker::checkBind(SVal Loc, SVal Val, const\
  \ Stmt *S, CheckerContext &C) const {\n  ProgramStateRef State = C.getState();\n\
  \n  // 1) Propagate per-CPU pointer aliases.\n  const MemRegion *LHSReg = Loc.getAsRegion();\n\
  \  if (LHSReg)\n    LHSReg = LHSReg->getBaseRegion();\n\n  // If RHS is already\
  \ a known per-cpu pointer region, add LHS as per-cpu.\n  if (LHSReg) {\n    if (const\
  \ MemRegion *RHSReg = Val.getAsRegion()) {\n      RHSReg = RHSReg->getBaseRegion();\n\
  \      if (RHSReg && State->contains<PerCpuPtrSet>(RHSReg)) {\n        State = State->add<PerCpuPtrSet>(LHSReg);\n\
  \      }\n    } else {\n      // Try AST-based deduction: only if S is DeclStmt\
  \ or BinaryOperator assignment.\n      const Expr *RHSExpr = nullptr;\n\n      if\
  \ (const auto *DS = dyn_cast_or_null<DeclStmt>(S)) {\n        for (const Decl *D\
  \ : DS->decls()) {\n          if (const auto *VD = dyn_cast<VarDecl>(D)) {\n   \
  \         if (const Expr *Init = VD->getInit()) {\n              RHSExpr = Init;\n\
  \              // LHSReg already computed from Loc; we also ensure pointer type\
  \ if possible.\n              // If it is a pointer, propagate based on RHS pattern.\n\
  \              if (VD->getType()->isPointerType())\n                propagatePerCpuAlias(LHSReg,\
  \ RHSExpr, C, State);\n            }\n          }\n        }\n      } else if (const\
  \ auto *BO = dyn_cast_or_null<BinaryOperator>(S)) {\n        if (BO->isAssignmentOp())\
  \ {\n          RHSExpr = BO->getRHS();\n          // LHSExpr pointer-type check\
  \ (best effort).\n          const Expr *LHSExpr = BO->getLHS();\n          if (LHSExpr\
  \ && LHSExpr->getType()->isPointerType())\n            propagatePerCpuAlias(LHSReg,\
  \ RHSExpr, C, State);\n        }\n      }\n    }\n  }\n\n  // 2) Detect suspicious\
  \ RMW on per-CPU fields.\n  maybeReportRMWOnPerCpuField(S, C);\n\n  // 3) Detect\
  \ suspicious plain reset to zero on per-CPU fields.\n  maybeReportPlainZeroStoreOnPerCpuField(S,\
  \ C);\n\n  C.addTransition(State);\n}\n\nvoid SAGenTestChecker::checkPostCall(const\
  \ CallEvent &Call, CheckerContext &C) const {\n  ProgramStateRef State = C.getState();\n\
  \  const Expr *Origin = Call.getOriginExpr();\n  if (!Origin) {\n    C.addTransition(State);\n\
  \    return;\n  }\n\n  // Opportunistically tag return value of per-cpu getters.\n\
  \  if (const auto *CE = dyn_cast<CallExpr>(Origin)) {\n    if (isPerCpuGetterCall(CE,\
  \ C)) {\n      if (const MemRegion *MR = Call.getReturnValue().getAsRegion()) {\n\
  \        MR = MR->getBaseRegion();\n        if (MR)\n          State = State->add<PerCpuPtrSet>(MR);\n\
  \      }\n    }\n  }\n\n  C.addTransition(State);\n}\n\n} // end anonymous namespace\n\
  \nextern \"C\" void clang_registerCheckers(CheckerRegistry &registry) {\n  registry.addChecker<SAGenTestChecker>(\n\
  \      \"custom.SAGenTestChecker\",\n      \"Detects plain RMW/reset on per-CPU\
  \ fields without READ_ONCE/WRITE_ONCE\",\n      \"\");\n}\n\nextern \"C\" const\
  \ char clang_analyzerAPIVersionString[] =\n    CLANG_ANALYZER_API_VERSION_STRING;\n"
tn_score: 1
tp_score: 0
