### Report Summary

File:| /scratch/chenyuan-data/linux-debug/arch/x86/events/amd/ibs.c
---|---
Warning:| line 350, column 2
Shift done in 32-bit, widened after; cast left operand to 64-bit before <<

### Annotated Source Code


296   |
297   |  if (hwc->sample_period) {
298   |  if (config & perf_ibs->cnt_mask)
299   |  /* raw max_cnt may not be set */
300   |  return -EINVAL;
301   |  if (!event->attr.sample_freq && hwc->sample_period & 0x0f)
302   |  /*
303   |  * lower 4 bits can not be set in ibs max cnt,
304   |  * but allowing it in case we adjust the
305   |  * sample period to set a frequency.
306   |  */
307   |  return -EINVAL;
308   | 		hwc->sample_period &= ~0x0FULL;
309   |  if (!hwc->sample_period)
310   | 			hwc->sample_period = 0x10;
311   | 	} else {
312   | 		max_cnt = config & perf_ibs->cnt_mask;
313   | 		config &= ~perf_ibs->cnt_mask;
314   | 		event->attr.sample_period = max_cnt << 4;
315   | 		hwc->sample_period = event->attr.sample_period;
316   | 	}
317   |
318   |  if (!hwc->sample_period)
319   |  return -EINVAL;
320   |
321   |  /*
322   |  * If we modify hwc->sample_period, we also need to update
323   |  * hwc->last_period and hwc->period_left.
324   |  */
325   | 	hwc->last_period = hwc->sample_period;
326   |  local64_set(&hwc->period_left, hwc->sample_period);
327   |
328   | 	hwc->config_base = perf_ibs->msr;
329   | 	hwc->config = config;
330   |
331   |  return 0;
332   | }
333   |
334   | static int perf_ibs_set_period(struct perf_ibs *perf_ibs,
335   |  struct hw_perf_event *hwc, u64 *period)
336   | {
337   |  int overflow;
338   |
339   |  /* ignore lower 4 bits in min count: */
340   | 	overflow = perf_event_set_period(hwc, 1<<4, perf_ibs->max_period, period);
341   |  local64_set(&hwc->prev_count, 0);
342   |
343   |  return overflow;
344   | }
345   |
346   | static u64 get_ibs_fetch_count(u64 config)
347   | {
348   |  union ibs_fetch_ctl fetch_ctl = (union ibs_fetch_ctl)config;
349   |
350   |  return fetch_ctl.fetch_cnt << 4;
    Shift done in 32-bit, widened after; cast left operand to 64-bit before <<
351   | }
352   |
353   | static u64 get_ibs_op_count(u64 config)
354   | {
355   |  union ibs_op_ctl op_ctl = (union ibs_op_ctl)config;
356   | 	u64 count = 0;
357   |
358   |  /*
359   |  * If the internal 27-bit counter rolled over, the count is MaxCnt
360   |  * and the lower 7 bits of CurCnt are randomized.
361   |  * Otherwise CurCnt has the full 27-bit current counter value.
362   |  */
363   |  if (op_ctl.op_val) {
364   | 		count = op_ctl.opmaxcnt << 4;
365   |  if (ibs_caps & IBS_CAPS_OPCNTEXT)
366   | 			count += op_ctl.opmaxcnt_ext << 20;
367   | 	} else if (ibs_caps & IBS_CAPS_RDWROPCNT) {
368   | 		count = op_ctl.opcurcnt;
369   | 	}
370   |
371   |  return count;
372   | }
373   |
374   | static void
375   | perf_ibs_event_update(struct perf_ibs *perf_ibs, struct perf_event *event,
376   | 		      u64 *config)
377   | {
378   | 	u64 count = perf_ibs->get_count(*config);
379   |
380   |  /*
