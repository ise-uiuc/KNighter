--- original_code.cpp+++ syntax_correct_refine_code.cpp@@ -21,8 +21,27 @@ using namespace ento;
 using namespace taint;

-// No custom program states needed
-// REGISTER_MAP_WITH_PROGRAMSTATE(...) not required
+// Utility functions provided by the prompt.
+template <typename T>
+const T* findSpecificTypeInParents(const Stmt *S, CheckerContext &C);
+
+template <typename T>
+const T* findSpecificTypeInChildren(const Stmt *S);
+
+bool EvaluateExprToInt(llvm::APSInt &EvalRes, const Expr *expr, CheckerContext &C);
+const llvm::APSInt *inferSymbolMaxVal(SymbolRef Sym, CheckerContext &C);
+bool getArraySizeFromExpr(llvm::APInt &ArraySize, const Expr *E);
+bool getStringSize(llvm::APInt &StringSize, const Expr *E);
+const MemRegion* getMemRegionFromExpr(const Expr* E, CheckerContext &C);
+
+struct KnownDerefFunction {
+  const char *Name;
+  llvm::SmallVector<unsigned, 4> Params;
+};
+
+bool functionKnownToDeref(const CallEvent &Call,
+                                 llvm::SmallVectorImpl<unsigned> &DerefParams);
+bool ExprHasName(const Expr *E, StringRef Name, CheckerContext &C);

 namespace {

@@ -34,20 +53,150 @@         check::PreCall> {
    mutable std::unique_ptr<BugType> BT;

-   public:
-      SAGenTestChecker() : BT(new BugType(this, "Narrow shift widened to 64-bit", "Integer")) {}
-
-      void checkPostStmt(const DeclStmt *DS, CheckerContext &C) const;
-      void checkBind(SVal Loc, SVal Val, const Stmt *S, CheckerContext &C) const;
-      void checkPreStmt(const ReturnStmt *RS, CheckerContext &C) const;
-      void checkPreCall(const CallEvent &Call, CheckerContext &C) const;
-
-   private:
-      void analyzeAndReportShiftToWide(const Expr *E, QualType DestTy,
-                                       CheckerContext &C, StringRef Ctx) const;
-
-      static const BinaryOperator *findShiftInTree(const Stmt *S);
-      static bool hasExplicitCastToWide64(const Expr *E, ASTContext &ACtx);
+public:
+  SAGenTestChecker() : BT(new BugType(this, "Narrow shift widened to 64-bit", "Integer")) {}
+
+  void checkPostStmt(const DeclStmt *DS, CheckerContext &C) const;
+  void checkBind(SVal Loc, SVal Val, const Stmt *S, CheckerContext &C) const;
+  void checkPreStmt(const ReturnStmt *RS, CheckerContext &C) const;
+  void checkPreCall(const CallEvent &Call, CheckerContext &C) const;
+
+private:
+  void analyzeAndReportShiftToWide(const Expr *E, QualType DestTy,
+                                   CheckerContext &C, StringRef Ctx) const;
+
+  static const BinaryOperator *findShiftInTree(const Stmt *S);
+  static bool hasExplicitCastToWide64(const Expr *E, ASTContext &ACtx);
+
+  // New helpers to reduce false positives while preserving true positives.
+
+  // Returns true if E is syntactically the integer literal 1 (with any suffix),
+  // ignoring parentheses and implicit casts.
+  static bool isLiteralOne(const Expr *E) {
+    if (!E)
+      return false;
+    E = E->IgnoreParenImpCasts();
+    if (const auto *IL = dyn_cast<IntegerLiteral>(E)) {
+      // Treat 1 of any width/signedness as "literal one"
+      return IL->getValue() == 1;
+    }
+    return false;
+  }
+
+  // Try to compute an unsigned upper bound for the value of E:
+  //  - Prefer compile-time evaluation (EvaluateExprToInt).
+  //  - Otherwise use path-sensitive constraint manager (inferSymbolMaxVal).
+  // Returns true and sets Out if successful and value is non-negative.
+  static bool getUnsignedUpperBound(const Expr *E, CheckerContext &C, uint64_t &Out) {
+    if (!E)
+      return false;
+
+    llvm::APSInt EvalRes;
+    if (EvaluateExprToInt(EvalRes, E, C)) {
+      if (EvalRes.isSigned() && EvalRes.isNegative())
+        return false;
+      Out = EvalRes.getZExtValue();
+      return true;
+    }
+
+    ProgramStateRef State = C.getState();
+    SVal V = State->getSVal(E, C.getLocationContext());
+    if (SymbolRef Sym = V.getAsSymbol()) {
+      if (const llvm::APSInt *Max = inferSymbolMaxVal(Sym, C)) {
+        if (Max->isSigned() && Max->isNegative())
+          return false;
+        Out = Max->getZExtValue();
+        return true;
+      }
+    }
+    return false;
+  }
+
+  // Try to compute an upper bound on the highest possible set bit index of E.
+  // For example, if max(E) <= 7 (0b111), returns 2.
+  // Only considers non-negative values. Returns true if successful.
+  static bool getMaxBitIndexUpperBound(const Expr *E, CheckerContext &C, unsigned &Idx) {
+    if (!E)
+      return false;
+
+    llvm::APSInt EvalRes;
+    if (EvaluateExprToInt(EvalRes, E, C)) {
+      if (EvalRes.isSigned() && EvalRes.isNegative())
+        return false;
+      const llvm::APInt &V = EvalRes;
+      if (V.isZero()) {
+        Idx = 0;
+        return true;
+      }
+      unsigned BitWidth = V.getBitWidth();
+      unsigned LZ = V.countLeadingZeros();
+      if (LZ >= BitWidth) {
+        Idx = 0;
+      } else {
+        Idx = BitWidth - 1 - LZ;
+      }
+      return true;
+    }
+
+    ProgramStateRef State = C.getState();
+    SVal V = State->getSVal(E, C.getLocationContext());
+    if (SymbolRef Sym = V.getAsSymbol()) {
+      if (const llvm::APSInt *Max = inferSymbolMaxVal(Sym, C)) {
+        if (Max->isSigned() && Max->isNegative())
+          return false;
+        const llvm::APInt &A = *Max;
+        if (A.isZero()) {
+          Idx = 0;
+          return true;
+        }
+        unsigned BitWidth = A.getBitWidth();
+        unsigned LZ = A.countLeadingZeros();
+        if (LZ >= BitWidth) {
+          Idx = 0;
+        } else {
+          Idx = BitWidth - 1 - LZ;
+        }
+        return true;
+      }
+    }
+    return false;
+  }
+
+  // Decide if the found shift is a false positive given the current path state.
+  // Suppress when:
+  //  - Shift amount is proven to be < promoted LHS width AND
+  //    a) LHS is literal one (bitmask construction), OR
+  //    b) we can prove (max_bit_index(LHS) + max_shift) < promoted LHS width.
+  static bool isFalsePositive(const BinaryOperator *Shl, unsigned PromotedLHSWidth,
+                              CheckerContext &C) {
+    if (!Shl)
+      return false;
+    const Expr *L = Shl->getLHS();
+    const Expr *R = Shl->getRHS();
+    if (!L || !R)
+      return false;
+
+    uint64_t ShiftUB = 0;
+    if (!getUnsignedUpperBound(R, C, ShiftUB))
+      return false; // Can't prove anything, don't suppress.
+
+    if (ShiftUB >= PromotedLHSWidth)
+      return false; // May exceed width, keep the warning.
+
+    // Bitmask-of-one: safe if shift < width.
+    if (isLiteralOne(L))
+      return true;
+
+    // More general: if we can bound the maximum bit index of LHS and
+    // the sum stays within promoted width, it's safe.
+    unsigned LMaxIdx = 0;
+    if (getMaxBitIndexUpperBound(L, C, LMaxIdx)) {
+      if ((uint64_t)LMaxIdx + ShiftUB < PromotedLHSWidth)
+        return true;
+    }
+
+    return false;
+  }
 };

 static const BinaryOperator *asShift(const Stmt *S) {
@@ -76,7 +225,6 @@   if (!E)
     return false;

-  // Look for any explicit cast to integer type with width >= 64 within E's subtree.
   if (const auto *ECE = dyn_cast<ExplicitCastExpr>(E->IgnoreParens())) {
     QualType ToTy = ECE->getType();
     if (ToTy->isIntegerType() && ACtx.getIntWidth(ToTy) >= 64)
@@ -89,14 +237,6 @@     if (const auto *CE = dyn_cast<Expr>(Child)) {
       if (hasExplicitCastToWide64(CE, ACtx))
         return true;
-    } else {
-      if (const BinaryOperator *B = asShift(Child)) {
-        (void)B; // not needed here
-      }
-      // Continue traversal for safety
-      if (const BinaryOperator *B2 = findShiftInTree(Child)) {
-        (void)B2;
-      }
     }
   }
   return false;
@@ -130,37 +270,20 @@   if (!ShlTy->isIntegerType())
     return;

-  unsigned ShlW = ACtx.getIntWidth(ShlTy);
-  if (ShlW >= 64)
-    return; // Shift already performed in 64-bit, OK.
-
-  // If LHS type is already 64-bit (or wider), no issue.
-  if (L->getType()->isIntegerType()) {
-    unsigned LHSW = ACtx.getIntWidth(L->getType());
-    if (LHSW >= 64)
-      return;
-
-    // If there is an explicit cast to >=64-bit within the LHS subtree, suppress.
-    if (hasExplicitCastToWide64(L, ACtx))
-      return;
-
-    // Try to evaluate RHS; if it's a constant less than LHS width, suppress to reduce FPs.
-    llvm::APSInt RHSEval;
-    if (EvaluateExprToInt(RHSEval, R, C)) {
-      // Treat negative or very large values conservatively.
-      if (!RHSEval.isSigned() || !RHSEval.isNegative()) {
-        uint64_t ShiftAmt = RHSEval.getZExtValue();
-        if (ShiftAmt < LHSW) {
-          // Heuristic suppression per plan.
-          return;
-        }
-      }
-    }
-  } else {
-    // Non-integer LHS shouldn't happen for <<, but be safe.
-    return;
-  }
-
+  // The type of the shift expression is the type of the promoted left operand.
+  unsigned PromotedLHSWidth = ACtx.getIntWidth(ShlTy);
+  if (PromotedLHSWidth >= 64)
+    return; // Shift already performed in >=64-bit, OK.
+
+  // If there is an explicit cast to >=64-bit within the LHS subtree, suppress.
+  if (hasExplicitCastToWide64(L, ACtx))
+    return;
+
+  // If path constraints prove this shift is safe (see isFalsePositive), suppress.
+  if (isFalsePositive(Shl, PromotedLHSWidth, C))
+    return;
+
+  // Otherwise, report.
   ExplodedNode *N = C.generateNonFatalErrorNode();
   if (!N)
     return;
@@ -189,7 +312,7 @@ }

 void SAGenTestChecker::checkBind(SVal, SVal, const Stmt *S, CheckerContext &C) const {
-  // Only handle assignments: LHS = RHS;
+  // Only handle assignments: LHS = RHS or compound assignments (e.g., |=).
   const auto *BO = dyn_cast_or_null<BinaryOperator>(S);
   if (!BO || !BO->isAssignmentOp())
     return;
