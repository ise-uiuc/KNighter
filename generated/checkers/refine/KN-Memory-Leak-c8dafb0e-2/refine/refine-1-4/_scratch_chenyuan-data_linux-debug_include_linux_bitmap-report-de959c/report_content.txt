### Report Summary

File:| /scratch/chenyuan-data/linux-debug/./include/linux/bitmap.h
---|---
Warning:| line 334, column 2
Missing hwrm_req_drop() after successful hwrm_req_init()

### Annotated Source Code


2344  | 			link_info->req_signal_mode = BNXT_SIG_MODE_PAM4;
2345  |  break;
2346  |  case BNXT_LINK_SPEED_100GB_PAM4_112:
2347  |  case BNXT_LINK_SPEED_200GB_PAM4_112:
2348  |  case BNXT_LINK_SPEED_400GB_PAM4_112:
2349  | 			link_info->req_signal_mode = BNXT_SIG_MODE_PAM4_112;
2350  |  break;
2351  |  default:
2352  | 			link_info->req_signal_mode = BNXT_SIG_MODE_NRZ;
2353  | 		}
2354  |  return;
2355  | 	}
2356  | 	link_info->req_link_speed = link_info->force_link_speed;
2357  | 	link_info->req_signal_mode = BNXT_SIG_MODE_NRZ;
2358  |  if (link_info->force_pam4_link_speed) {
2359  | 		link_info->req_link_speed = link_info->force_pam4_link_speed;
2360  | 		link_info->req_signal_mode = BNXT_SIG_MODE_PAM4;
2361  | 	}
2362  | }
2363  |
2364  | static void bnxt_set_auto_speed(struct bnxt_link_info *link_info)
2365  | {
2366  |  struct bnxt *bp = container_of(link_info, struct bnxt, link_info);
2367  |
2368  |  if (bp->phy_flags & BNXT_PHY_FL_SPEEDS2) {
2369  | 		link_info->advertising = link_info->auto_link_speeds2;
2370  |  return;
2371  | 	}
2372  | 	link_info->advertising = link_info->auto_link_speeds;
2373  | 	link_info->advertising_pam4 = link_info->auto_pam4_link_speeds;
2374  | }
2375  |
2376  | static bool bnxt_force_speed_updated(struct bnxt_link_info *link_info)
2377  | {
2378  |  struct bnxt *bp = container_of(link_info, struct bnxt, link_info);
2379  |
2380  |  if (bp->phy_flags & BNXT_PHY_FL_SPEEDS2) {
2381  |  if (link_info->req_link_speed != link_info->force_link_speed2)
2382  |  return true;
2383  |  return false;
2384  | 	}
2385  |  if (link_info->req_signal_mode == BNXT_SIG_MODE_NRZ &&
2386  | 	    link_info->req_link_speed != link_info->force_link_speed)
2387  |  return true;
2388  |  if (link_info->req_signal_mode == BNXT_SIG_MODE_PAM4 &&
2389  | 	    link_info->req_link_speed != link_info->force_pam4_link_speed)
2390  |  return true;
2391  |  return false;
2392  | }
2393  |
2394  | static bool bnxt_auto_speed_updated(struct bnxt_link_info *link_info)
2395  | {
2396  |  struct bnxt *bp = container_of(link_info, struct bnxt, link_info);
2397  |
2398  |  if (bp->phy_flags & BNXT_PHY_FL_SPEEDS2) {
2399  |  if (link_info->advertising != link_info->auto_link_speeds2)
2400  |  return true;
2401  |  return false;
2402  | 	}
2403  |  if (link_info->advertising != link_info->auto_link_speeds ||
2404  | 	    link_info->advertising_pam4 != link_info->auto_pam4_link_speeds)
2405  |  return true;
2406  |  return false;
2407  | }
2408  |
2409  | #define BNXT_EVENT_THERMAL_CURRENT_TEMP(data2)				\
2410  |  ((data2) &							\
2411  |  ASYNC_EVENT_CMPL_ERROR_REPORT_THERMAL_EVENT_DATA2_CURRENT_TEMP_MASK)
2412  |
2413  | #define BNXT_EVENT_THERMAL_THRESHOLD_TEMP(data2)			\
2414  |  (((data2) &							\
2415  |  ASYNC_EVENT_CMPL_ERROR_REPORT_THERMAL_EVENT_DATA2_THRESHOLD_TEMP_MASK) >>\
2416  |  ASYNC_EVENT_CMPL_ERROR_REPORT_THERMAL_EVENT_DATA2_THRESHOLD_TEMP_SFT)
2417  |
2418  | #define EVENT_DATA1_THERMAL_THRESHOLD_TYPE(data1)			\
2419  |  ((data1) &							\
2420  |  ASYNC_EVENT_CMPL_ERROR_REPORT_THERMAL_EVENT_DATA1_THRESHOLD_TYPE_MASK)
2421  |
2422  | #define EVENT_DATA1_THERMAL_THRESHOLD_DIR_INCREASING(data1)		\
2423  |  (((data1) &							\
2424  |  ASYNC_EVENT_CMPL_ERROR_REPORT_THERMAL_EVENT_DATA1_TRANSITION_DIR) ==\
2425  |  ASYNC_EVENT_CMPL_ERROR_REPORT_THERMAL_EVENT_DATA1_TRANSITION_DIR_INCREASING)
2426  |
2427  | /* Return true if the workqueue has to be scheduled */
2428  | static bool bnxt_event_error_report(struct bnxt *bp, u32 data1, u32 data2)
2429  | {
2430  | 	u32 err_type = BNXT_EVENT_ERROR_REPORT_TYPE(data1);
2431  |
10835 |  le16_to_cpu(resp->supported_speeds_auto_mode);
10836 |  if (resp->supported_pam4_speeds_auto_mode)
10837 | 		link_info->support_pam4_auto_speeds =
10838 |  le16_to_cpu(resp->supported_pam4_speeds_auto_mode);
10839 |  if (resp->supported_speeds2_auto_mode)
10840 | 		link_info->support_auto_speeds2 =
10841 |  le16_to_cpu(resp->supported_speeds2_auto_mode);
10842 |
10843 | 	bp->port_count = resp->port_cnt;
10844 |
10845 | hwrm_phy_qcaps_exit:
10846 | 	hwrm_req_drop(bp, req);
10847 |  return rc;
10848 | }
10849 |
10850 | static bool bnxt_support_dropped(u16 advertising, u16 supported)
10851 | {
10852 | 	u16 diff = advertising ^ supported;
10853 |
10854 |  return ((supported | diff) != supported);
10855 | }
10856 |
10857 | static bool bnxt_support_speed_dropped(struct bnxt_link_info *link_info)
10858 | {
10859 |  struct bnxt *bp = container_of(link_info, struct bnxt, link_info);
10860 |
10861 |  /* Check if any advertised speeds are no longer supported. The caller
10862 |  * holds the link_lock mutex, so we can modify link_info settings.
10863 |  */
10864 |  if (bp->phy_flags & BNXT_PHY_FL_SPEEDS2) {
10865 |  if (bnxt_support_dropped(link_info->advertising,
10866 | 					 link_info->support_auto_speeds2)) {
10867 | 			link_info->advertising = link_info->support_auto_speeds2;
10868 |  return true;
10869 | 		}
10870 |  return false;
10871 | 	}
10872 |  if (bnxt_support_dropped(link_info->advertising,
10873 | 				 link_info->support_auto_speeds)) {
10874 | 		link_info->advertising = link_info->support_auto_speeds;
10875 |  return true;
10876 | 	}
10877 |  if (bnxt_support_dropped(link_info->advertising_pam4,
10878 | 				 link_info->support_pam4_auto_speeds)) {
10879 | 		link_info->advertising_pam4 = link_info->support_pam4_auto_speeds;
10880 |  return true;
10881 | 	}
10882 |  return false;
10883 | }
10884 |
10885 | int bnxt_update_link(struct bnxt *bp, bool chng_link_state)
10886 | {
10887 |  struct bnxt_link_info *link_info = &bp->link_info;
10888 |  struct hwrm_port_phy_qcfg_output *resp;
10889 |  struct hwrm_port_phy_qcfg_input *req;
10890 | 	u8 link_state = link_info->link_state;
10891 | 	bool support_changed;
10892 |  int rc;
10893 |
10894 | 	rc = hwrm_req_init(bp, req, HWRM_PORT_PHY_QCFG);
10895 |  if (rc)
10896 |  return rc;
10897 |
10898 | 	resp = hwrm_req_hold(bp, req);
10899 | 	rc = hwrm_req_send(bp, req);
10900 |  if (rc) {
10901 | 		hwrm_req_drop(bp, req);
10902 |  if (BNXT_VF(bp) && rc == -ENODEV) {
10903 | 			netdev_warn(bp->dev, "Cannot obtain link state while PF unavailable.\n");
10904 | 			rc = 0;
10905 | 		}
10906 |  return rc;
10907 | 	}
10908 |
10909 |  memcpy(&link_info->phy_qcfg_resp, resp, sizeof(*resp));
10910 | 	link_info->phy_link_status = resp->link;
10911 | 	link_info->duplex = resp->duplex_cfg;
10912 |  if (bp->hwrm_spec_code >= 0x10800)
10913 | 		link_info->duplex = resp->duplex_state;
10914 | 	link_info->pause = resp->pause;
10915 | 	link_info->auto_mode = resp->auto_mode;
10916 | 	link_info->auto_pause_setting = resp->auto_pause;
10917 | 	link_info->lp_pause = resp->link_partner_adv_pause;
10918 | 	link_info->force_pause_setting = resp->force_pause;
10919 | 	link_info->duplex_setting = resp->duplex_cfg;
10920 |  if (link_info->phy_link_status == BNXT_LINK_LINK) {
10921 | 		link_info->link_speed = le16_to_cpu(resp->link_speed);
10922 |  if (bp->phy_flags & BNXT_PHY_FL_SPEEDS2)
10923 | 			link_info->active_lanes = resp->active_lanes;
10924 | 	} else {
10925 | 		link_info->link_speed = 0;
10926 | 		link_info->active_lanes = 0;
10927 | 	}
10928 | 	link_info->force_link_speed = le16_to_cpu(resp->force_link_speed);
10929 | 	link_info->force_pam4_link_speed =
10930 |  le16_to_cpu(resp->force_pam4_link_speed);
10931 | 	link_info->force_link_speed2 = le16_to_cpu(resp->force_link_speeds2);
10932 | 	link_info->support_speeds = le16_to_cpu(resp->support_speeds);
10933 | 	link_info->support_pam4_speeds = le16_to_cpu(resp->support_pam4_speeds);
10934 | 	link_info->support_speeds2 = le16_to_cpu(resp->support_speeds2);
10935 | 	link_info->auto_link_speeds = le16_to_cpu(resp->auto_link_speed_mask);
10936 | 	link_info->auto_pam4_link_speeds =
10937 |  le16_to_cpu(resp->auto_pam4_link_speed_mask);
10938 | 	link_info->auto_link_speeds2 = le16_to_cpu(resp->auto_link_speeds2);
10939 | 	link_info->lp_auto_link_speeds =
10940 |  le16_to_cpu(resp->link_partner_adv_speeds);
10941 | 	link_info->lp_auto_pam4_link_speeds =
10942 | 		resp->link_partner_pam4_adv_speeds;
10943 | 	link_info->preemphasis = le32_to_cpu(resp->preemphasis);
10944 | 	link_info->phy_ver[0] = resp->phy_maj;
10945 | 	link_info->phy_ver[1] = resp->phy_min;
10946 | 	link_info->phy_ver[2] = resp->phy_bld;
10947 | 	link_info->media_type = resp->media_type;
10948 | 	link_info->phy_type = resp->phy_type;
10949 | 	link_info->transceiver = resp->xcvr_pkg_type;
10950 | 	link_info->phy_addr = resp->eee_config_phy_addr &
10951 |  PORT_PHY_QCFG_RESP_PHY_ADDR_MASK;
10952 | 	link_info->module_status = resp->module_status;
10953 |
10954 |  if (bp->phy_flags & BNXT_PHY_FL_EEE_CAP) {
10955 |  struct ethtool_keee *eee = &bp->eee;
10956 | 		u16 fw_speeds;
10957 |
10958 | 		eee->eee_active = 0;
10959 |  if (resp->eee_config_phy_addr &
10960 |  PORT_PHY_QCFG_RESP_EEE_CONFIG_EEE_ACTIVE) {
10961 | 			eee->eee_active = 1;
10962 | 			fw_speeds = le16_to_cpu(
10963 |  resp->link_partner_adv_eee_link_speed_mask);
10964 | 			_bnxt_fw_to_linkmode(eee->lp_advertised, fw_speeds);
10965 | 		}
10966 |
10967 |  /* Pull initial EEE config */
10968 |  if (!chng_link_state) {
10969 |  if (resp->eee_config_phy_addr &
10970 |  PORT_PHY_QCFG_RESP_EEE_CONFIG_EEE_ENABLED)
10971 | 				eee->eee_enabled = 1;
10972 |
10973 | 			fw_speeds = le16_to_cpu(resp->adv_eee_link_speed_mask);
10974 | 			_bnxt_fw_to_linkmode(eee->advertised, fw_speeds);
10975 |
10976 |  if (resp->eee_config_phy_addr &
10977 |  PORT_PHY_QCFG_RESP_EEE_CONFIG_EEE_TX_LPI) {
10978 | 				__le32 tmr;
10979 |
10980 | 				eee->tx_lpi_enabled = 1;
10981 | 				tmr = resp->xcvr_identifier_type_tx_lpi_timer;
10982 | 				eee->tx_lpi_timer = le32_to_cpu(tmr) &
10983 |  PORT_PHY_QCFG_RESP_TX_LPI_TIMER_MASK;
10984 | 			}
10985 | 		}
10986 | 	}
10987 |
10988 | 	link_info->fec_cfg = PORT_PHY_QCFG_RESP_FEC_CFG_FEC_NONE_SUPPORTED;
10989 |  if (bp->hwrm_spec_code >= 0x10504) {
10990 | 		link_info->fec_cfg = le16_to_cpu(resp->fec_cfg);
10991 | 		link_info->active_fec_sig_mode = resp->active_fec_signal_mode;
10992 | 	}
10993 |  /* TODO: need to add more logic to report VF link */
10994 |  if (chng_link_state) {
10995 |  if (link_info->phy_link_status == BNXT_LINK_LINK)
10996 | 			link_info->link_state = BNXT_LINK_STATE_UP;
10997 |  else
10998 | 			link_info->link_state = BNXT_LINK_STATE_DOWN;
10999 |  if (link_state != link_info->link_state)
11000 | 			bnxt_report_link(bp);
11001 | 	} else {
11002 |  /* always link down if not require to update link state */
11003 | 		link_info->link_state = BNXT_LINK_STATE_DOWN;
11004 | 	}
11005 | 	hwrm_req_drop(bp, req);
11006 |
11007 |  if (!BNXT_PHY_CFG_ABLE(bp))
11008 |  return 0;
11009 |
11010 | 	support_changed = bnxt_support_speed_dropped(link_info);
11011 |  if (support_changed && (link_info->autoneg & BNXT_AUTONEG_SPEED))
11012 | 		bnxt_hwrm_set_link_setting(bp, true, false);
11013 |  return 0;
11014 | }
11015 |
11016 | static void bnxt_get_port_module_status(struct bnxt *bp)
11017 | {
11018 |  struct bnxt_link_info *link_info = &bp->link_info;
11019 |  struct hwrm_port_phy_qcfg_output *resp = &link_info->phy_qcfg_resp;
11020 | 	u8 module_status;
11021 |
11022 |  if (bnxt_update_link(bp, true))
11023 |  return;
11024 |
11025 | 	module_status = link_info->module_status;
11026 |  switch (module_status) {
11027 |  case PORT_PHY_QCFG_RESP_MODULE_STATUS_DISABLETX:
11028 |  case PORT_PHY_QCFG_RESP_MODULE_STATUS_PWRDOWN:
11029 |  case PORT_PHY_QCFG_RESP_MODULE_STATUS_WARNINGMSG:
11030 | 		netdev_warn(bp->dev, "Unqualified SFP+ module detected on port %d\n",
11031 | 			    bp->pf.port_id);
11032 |  if (bp->hwrm_spec_code >= 0x10201) {
11033 | 			netdev_warn(bp->dev, "Module part number %s\n",
11034 | 				    resp->phy_vendor_partnumber);
11035 | 		}
11036 |  if (module_status == PORT_PHY_QCFG_RESP_MODULE_STATUS_DISABLETX)
11037 | 			netdev_warn(bp->dev, "TX is disabled\n");
11038 |  if (module_status == PORT_PHY_QCFG_RESP_MODULE_STATUS_PWRDOWN)
11458 |
11459 | 	req->port_id = cpu_to_le16(bp->pf.port_id);
11460 | 	req->enables = cpu_to_le32(WOL_FILTER_FREE_REQ_ENABLES_WOL_FILTER_ID);
11461 | 	req->wol_filter_id = bp->wol_filter_id;
11462 |
11463 |  return hwrm_req_send(bp, req);
11464 | }
11465 |
11466 | static u16 bnxt_hwrm_get_wol_fltrs(struct bnxt *bp, u16 handle)
11467 | {
11468 |  struct hwrm_wol_filter_qcfg_output *resp;
11469 |  struct hwrm_wol_filter_qcfg_input *req;
11470 | 	u16 next_handle = 0;
11471 |  int rc;
11472 |
11473 | 	rc = hwrm_req_init(bp, req, HWRM_WOL_FILTER_QCFG);
11474 |  if (rc)
11475 |  return rc;
11476 |
11477 | 	req->port_id = cpu_to_le16(bp->pf.port_id);
11478 | 	req->handle = cpu_to_le16(handle);
11479 | 	resp = hwrm_req_hold(bp, req);
11480 | 	rc = hwrm_req_send(bp, req);
11481 |  if (!rc) {
11482 | 		next_handle = le16_to_cpu(resp->next_handle);
11483 |  if (next_handle != 0) {
11484 |  if (resp->wol_type ==
11485 |  WOL_FILTER_ALLOC_REQ_WOL_TYPE_MAGICPKT) {
11486 | 				bp->wol = 1;
11487 | 				bp->wol_filter_id = resp->wol_filter_id;
11488 | 			}
11489 | 		}
11490 | 	}
11491 | 	hwrm_req_drop(bp, req);
11492 |  return next_handle;
11493 | }
11494 |
11495 | static void bnxt_get_wol_settings(struct bnxt *bp)
11496 | {
11497 | 	u16 handle = 0;
11498 |
11499 | 	bp->wol = 0;
11500 |  if (!BNXT_PF(bp) || !(bp->flags & BNXT_FLAG_WOL_CAP))
11501 |  return;
11502 |
11503 |  do {
11504 | 		handle = bnxt_hwrm_get_wol_fltrs(bp, handle);
11505 | 	} while (handle && handle != 0xffff);
11506 | }
11507 |
11508 | static bool bnxt_eee_config_ok(struct bnxt *bp)
11509 | {
11510 |  struct ethtool_keee *eee = &bp->eee;
11511 |  struct bnxt_link_info *link_info = &bp->link_info;
11512 |
11513 |  if (!(bp->phy_flags & BNXT_PHY_FL_EEE_CAP))
    34←Assuming the condition is false→
    35←Taking false branch→
11514 |  return true;
11515 |
11516 |  if (eee->eee_enabled) {
    36←Assuming field 'eee_enabled' is true→
    37←Taking true branch→
11517 |  __ETHTOOL_DECLARE_LINK_MODE_MASK(advertising);
11518 |  __ETHTOOL_DECLARE_LINK_MODE_MASK(tmp);
11519 |
11520 | 		_bnxt_fw_to_linkmode(advertising, link_info->advertising);
11521 |
11522 |  if (!(link_info->autoneg & BNXT_AUTONEG_SPEED)) {
    38←Taking false branch→
11523 | 			eee->eee_enabled = 0;
11524 |  return false;
11525 | 		}
11526 |  if (linkmode_andnot(tmp, eee->advertised, advertising)) {
    39←Calling 'linkmode_andnot'→
11527 | 			linkmode_and(eee->advertised, advertising,
11528 | 				     eee->supported);
11529 |  return false;
11530 | 		}
11531 | 	}
11532 |  return true;
11533 | }
11534 |
11535 | static int bnxt_update_phy_setting(struct bnxt *bp)
11536 | {
11537 |  int rc;
11538 | 	bool update_link = false;
11539 | 	bool update_pause = false;
11540 | 	bool update_eee = false;
11541 |  struct bnxt_link_info *link_info = &bp->link_info;
11542 |
11543 | 	rc = bnxt_update_link(bp, true);
11544 |  if (rc21.1'rc' is 021.1'rc' is 021.1'rc' is 0) {
11545 | 		netdev_err(bp->dev, "failed to update link (rc: %x)\n",
11546 | 			   rc);
11547 |  return rc;
11548 | 	}
11549 |  if (!BNXT_SINGLE_PF(bp))
    22←Taking false branch→
11550 |  return 0;
11551 |
11552 |  if ((link_info->autoneg & BNXT_AUTONEG_FLOW_CTRL) &&
    23←Assuming the condition is false→
11553 | 	    (link_info->auto_pause_setting & BNXT_LINK_PAUSE_BOTH) !=
11554 | 	    link_info->req_flow_ctrl)
11555 | 		update_pause = true;
11556 |  if (!(link_info->autoneg & BNXT_AUTONEG_FLOW_CTRL) &&
    25←Taking false branch→
11557 |  link_info->force_pause_setting != link_info->req_flow_ctrl)
    24←Assuming field 'force_pause_setting' is equal to field 'req_flow_ctrl'→
11558 | 		update_pause = true;
11559 |  if (!(link_info->autoneg & BNXT_AUTONEG_SPEED)) {
    26←Assuming the condition is false→
    27←Taking false branch→
11560 |  if (BNXT_AUTO_MODE(link_info->auto_mode))
11561 | 			update_link = true;
11562 |  if (bnxt_force_speed_updated(link_info))
11563 | 			update_link = true;
11564 |  if (link_info->req_duplex != link_info->duplex_setting)
11565 | 			update_link = true;
11566 | 	} else {
11567 |  if (link_info->auto_mode == BNXT_LINK_AUTO_NONE)
    28←Assuming field 'auto_mode' is not equal to BNXT_LINK_AUTO_NONE→
    29←Taking false branch→
11568 | 			update_link = true;
11569 |  if (bnxt_auto_speed_updated(link_info))
    30←Taking false branch→
11570 | 			update_link = true;
11571 | 	}
11572 |
11573 |  /* The last close may have shutdown the link, so need to call
11574 |  * PHY_CFG to bring it back up.
11575 |  */
11576 |  if (!BNXT_LINK_IS_UP(bp))
    31←Assuming field 'link_state' is equal to 2→
    32←Taking false branch→
11577 | 		update_link = true;
11578 |
11579 |  if (!bnxt_eee_config_ok(bp))
    33←Calling 'bnxt_eee_config_ok'→
11580 | 		update_eee = true;
11581 |
11582 |  if (update_link)
11583 | 		rc = bnxt_hwrm_set_link_setting(bp, update_pause, update_eee);
11584 |  else if (update_pause)
11585 | 		rc = bnxt_hwrm_set_pause(bp);
11586 |  if (rc) {
11587 | 		netdev_err(bp->dev, "failed to update phy setting (rc: %x)\n",
11588 | 			   rc);
11589 |  return rc;
11590 | 	}
11591 |
11592 |  return rc;
11593 | }
11594 |
11595 | /* Common routine to pre-map certain register block to different GRC window.
11596 |  * A PF has 16 4K windows and a VF has 4 4K windows. However, only 15 windows
11597 |  * in PF and 3 windows in VF that can be customized to map in different
11598 |  * register blocks.
11599 |  */
11600 | static void bnxt_preset_reg_win(struct bnxt *bp)
11601 | {
11602 |  if (BNXT_PF(bp)) {
11603 |  /* CAG registers map to GRC window #4 */
11604 |  writel(BNXT_CAG_REG_BASE,
11605 | 		       bp->bar0 + BNXT_GRCPF_REG_WINDOW_BASE_OUT + 12);
11606 | 	}
11607 | }
11608 |
11609 | static int bnxt_init_dflt_ring_mode(struct bnxt *bp);
13230 | 			fw_ring_id = cpr2->cp_ring_struct.fw_ring_id;
13231 | 			bnxt_dbg_hwrm_ring_info_get(bp,
13232 |  DBG_RING_INFO_GET_REQ_RING_TYPE_L2_CMPL,
13233 | 				fw_ring_id, &val[0], &val[1]);
13234 | 			cpr->sw_stats.cmn.missed_irqs++;
13235 | 		}
13236 | 	}
13237 | }
13238 |
13239 | static void bnxt_cfg_ntp_filters(struct bnxt *);
13240 |
13241 | static void bnxt_init_ethtool_link_settings(struct bnxt *bp)
13242 | {
13243 |  struct bnxt_link_info *link_info = &bp->link_info;
13244 |
13245 |  if (BNXT_AUTO_MODE(link_info->auto_mode)) {
13246 | 		link_info->autoneg = BNXT_AUTONEG_SPEED;
13247 |  if (bp->hwrm_spec_code >= 0x10201) {
13248 |  if (link_info->auto_pause_setting &
13249 |  PORT_PHY_CFG_REQ_AUTO_PAUSE_AUTONEG_PAUSE)
13250 | 				link_info->autoneg |= BNXT_AUTONEG_FLOW_CTRL;
13251 | 		} else {
13252 | 			link_info->autoneg |= BNXT_AUTONEG_FLOW_CTRL;
13253 | 		}
13254 | 		bnxt_set_auto_speed(link_info);
13255 | 	} else {
13256 | 		bnxt_set_force_speed(link_info);
13257 | 		link_info->req_duplex = link_info->duplex_setting;
13258 | 	}
13259 |  if (link_info->autoneg & BNXT_AUTONEG_FLOW_CTRL)
13260 | 		link_info->req_flow_ctrl =
13261 | 			link_info->auto_pause_setting & BNXT_LINK_PAUSE_BOTH;
13262 |  else
13263 | 		link_info->req_flow_ctrl = link_info->force_pause_setting;
13264 | }
13265 |
13266 | static void bnxt_fw_echo_reply(struct bnxt *bp)
13267 | {
13268 |  struct bnxt_fw_health *fw_health = bp->fw_health;
13269 |  struct hwrm_func_echo_response_input *req;
13270 |  int rc;
13271 |
13272 | 	rc = hwrm_req_init(bp, req, HWRM_FUNC_ECHO_RESPONSE);
13273 |  if (rc)
13274 |  return;
13275 | 	req->event_data1 = cpu_to_le32(fw_health->echo_req_data1);
13276 | 	req->event_data2 = cpu_to_le32(fw_health->echo_req_data2);
13277 | 	hwrm_req_send(bp, req);
13278 | }
13279 |
13280 | static void bnxt_sp_task(struct work_struct *work)
13281 | {
13282 |  struct bnxt *bp = container_of(work, struct bnxt, sp_task);
13283 |
13284 | 	set_bit(BNXT_STATE_IN_SP_TASK, &bp->state);
13285 |  smp_mb__after_atomic();
    1Loop condition is false.  Exiting loop→
    2←Loop condition is false.  Exiting loop→
13286 |  if (!test_bit(BNXT_STATE_OPEN, &bp->state)) {
    3←Loop condition is false.  Exiting loop→
    4←Assuming the condition is true→
    5←Assuming the condition is false→
    6←Taking false branch→
13287 | 		clear_bit(BNXT_STATE_IN_SP_TASK, &bp->state);
13288 |  return;
13289 | 	}
13290 |
13291 |  if (test_and_clear_bit(BNXT_RX_MASK_SP_EVENT, &bp->sp_event))
    7←Assuming the condition is false→
    8←Taking false branch→
13292 | 		bnxt_cfg_rx_mode(bp);
13293 |
13294 |  if (test_and_clear_bit(BNXT_RX_NTP_FLTR_SP_EVENT, &bp->sp_event))
    9←Assuming the condition is false→
    10←Taking false branch→
13295 | 		bnxt_cfg_ntp_filters(bp);
13296 |  if (test_and_clear_bit(BNXT_HWRM_EXEC_FWD_REQ_SP_EVENT, &bp->sp_event))
    11←Assuming the condition is false→
    12←Taking false branch→
13297 | 		bnxt_hwrm_exec_fwd_req(bp);
13298 |  if (test_and_clear_bit(BNXT_HWRM_PF_UNLOAD_SP_EVENT, &bp->sp_event))
    13←Assuming the condition is false→
    14←Taking false branch→
13299 | 		netdev_info(bp->dev, "Receive PF driver unload event!\n");
13300 |  if (test_and_clear_bit(BNXT_PERIODIC_STATS_SP_EVENT, &bp->sp_event)) {
    15←Assuming the condition is false→
    16←Taking false branch→
13301 | 		bnxt_hwrm_port_qstats(bp, 0);
13302 | 		bnxt_hwrm_port_qstats_ext(bp, 0);
13303 | 		bnxt_accumulate_all_stats(bp);
13304 | 	}
13305 |
13306 |  if (test_and_clear_bit(BNXT_LINK_CHNG_SP_EVENT, &bp->sp_event)) {
    17←Assuming the condition is false→
    18←Taking false branch→
13307 |  int rc;
13308 |
13309 |  mutex_lock(&bp->link_lock);
13310 |  if (test_and_clear_bit(BNXT_LINK_SPEED_CHNG_SP_EVENT,
13311 | 				       &bp->sp_event))
13312 | 			bnxt_hwrm_phy_qcaps(bp);
13313 |
13314 | 		rc = bnxt_update_link(bp, true);
13315 |  if (rc)
13316 | 			netdev_err(bp->dev, "SP task can't update link (rc: %x)\n",
13317 | 				   rc);
13318 |
13319 |  if (test_and_clear_bit(BNXT_LINK_CFG_CHANGE_SP_EVENT,
13320 | 				       &bp->sp_event))
13321 | 			bnxt_init_ethtool_link_settings(bp);
13322 | 		mutex_unlock(&bp->link_lock);
13323 | 	}
13324 |  if (test_and_clear_bit(BNXT_UPDATE_PHY_SP_EVENT, &bp->sp_event)) {
    19←Assuming the condition is true→
    20←Taking true branch→
13325 |  int rc;
13326 |
13327 |  mutex_lock(&bp->link_lock);
13328 |  rc = bnxt_update_phy_setting(bp);
    21←Calling 'bnxt_update_phy_setting'→
13329 | 		mutex_unlock(&bp->link_lock);
13330 |  if (rc) {
13331 | 			netdev_warn(bp->dev, "update phy settings retry failed\n");
13332 | 		} else {
13333 | 			bp->link_info.phy_retry = false;
13334 | 			netdev_info(bp->dev, "update phy settings retry succeeded\n");
13335 | 		}
13336 | 	}
13337 |  if (test_and_clear_bit(BNXT_HWRM_PORT_MODULE_SP_EVENT, &bp->sp_event)) {
13338 |  mutex_lock(&bp->link_lock);
13339 | 		bnxt_get_port_module_status(bp);
13340 | 		mutex_unlock(&bp->link_lock);
13341 | 	}
13342 |
13343 |  if (test_and_clear_bit(BNXT_FLOW_STATS_SP_EVENT, &bp->sp_event))
13344 | 		bnxt_tc_flow_stats_work(bp);
13345 |
13346 |  if (test_and_clear_bit(BNXT_RING_COAL_NOW_SP_EVENT, &bp->sp_event))
13347 | 		bnxt_chk_missed_irq(bp);
13348 |
13349 |  if (test_and_clear_bit(BNXT_FW_ECHO_REQUEST_SP_EVENT, &bp->sp_event))
13350 | 		bnxt_fw_echo_reply(bp);
13351 |
13352 |  if (test_and_clear_bit(BNXT_THERMAL_THRESHOLD_SP_EVENT, &bp->sp_event))
13353 | 		bnxt_hwmon_notify_event(bp);
13354 |
13355 |  /* These functions below will clear BNXT_STATE_IN_SP_TASK.  They
13356 |  * must be the last functions to be called before exiting.
13357 |  */
13358 |  if (test_and_clear_bit(BNXT_RESET_TASK_SP_EVENT, &bp->sp_event))
1     | #ifndef __LINKMODE_H
2     | #define __LINKMODE_H
3     |
4     | #include <linux/bitmap.h>
5     | #include <linux/ethtool.h>
6     | #include <uapi/linux/ethtool.h>
7     |
8     | static inline void linkmode_zero(unsigned long *dst)
9     | {
10    | 	bitmap_zero(dst, __ETHTOOL_LINK_MODE_MASK_NBITS);
11    | }
12    |
13    | static inline void linkmode_fill(unsigned long *dst)
14    | {
15    | 	bitmap_fill(dst, __ETHTOOL_LINK_MODE_MASK_NBITS);
16    | }
17    |
18    | static inline void linkmode_copy(unsigned long *dst, const unsigned long *src)
19    | {
20    | 	bitmap_copy(dst, src, __ETHTOOL_LINK_MODE_MASK_NBITS);
21    | }
22    |
23    | static inline void linkmode_and(unsigned long *dst, const unsigned long *a,
24    |  const unsigned long *b)
25    | {
26    | 	bitmap_and(dst, a, b, __ETHTOOL_LINK_MODE_MASK_NBITS);
27    | }
28    |
29    | static inline void linkmode_or(unsigned long *dst, const unsigned long *a,
30    |  const unsigned long *b)
31    | {
32    | 	bitmap_or(dst, a, b, __ETHTOOL_LINK_MODE_MASK_NBITS);
33    | }
34    |
35    | static inline bool linkmode_empty(const unsigned long *src)
36    | {
37    |  return bitmap_empty(src, __ETHTOOL_LINK_MODE_MASK_NBITS);
38    | }
39    |
40    | static inline int linkmode_andnot(unsigned long *dst, const unsigned long *src1,
41    |  const unsigned long *src2)
42    | {
43    |  return bitmap_andnot(dst, src1, src2,  __ETHTOOL_LINK_MODE_MASK_NBITS);
    40←Calling 'bitmap_andnot'→
44    | }
45    |
46    | static inline void linkmode_set_bit(int nr, volatile unsigned long *addr)
47    | {
48    |  __set_bit(nr, addr);
49    | }
50    |
51    | static inline void linkmode_clear_bit(int nr, volatile unsigned long *addr)
52    | {
53    |  __clear_bit(nr, addr);
54    | }
55    |
56    | static inline void linkmode_mod_bit(int nr, volatile unsigned long *addr,
57    |  int set)
58    | {
59    |  if (set)
60    | 		linkmode_set_bit(nr, addr);
61    |  else
62    | 		linkmode_clear_bit(nr, addr);
63    | }
64    |
65    | static inline int linkmode_test_bit(int nr, const volatile unsigned long *addr)
66    | {
67    |  return test_bit(nr, addr);
68    | }
69    |
70    | static inline void linkmode_set_bit_array(const int *array, int array_size,
71    |  unsigned long *addr)
72    | {
73    |  int i;
279   |  unsigned int nbits);
280   | #else
281   | #define bitmap_from_arr32(bitmap, buf, nbits)			\
282   |  bitmap_copy_clear_tail((unsigned long *) (bitmap),	\
283   |  (const unsigned long *) (buf), (nbits))
284   | #define bitmap_to_arr32(buf, bitmap, nbits)			\
285   |  bitmap_copy_clear_tail((unsigned long *) (buf),		\
286   |  (const unsigned long *) (bitmap), (nbits))
287   | #endif
288   |
289   | /*
290   |  * On 64-bit systems bitmaps are represented as u64 arrays internally. So,
291   |  * the conversion is not needed when copying data from/to arrays of u64.
292   |  */
293   | #if BITS_PER_LONG == 32
294   | void bitmap_from_arr64(unsigned long *bitmap, const u64 *buf, unsigned int nbits);
295   | void bitmap_to_arr64(u64 *buf, const unsigned long *bitmap, unsigned int nbits);
296   | #else
297   | #define bitmap_from_arr64(bitmap, buf, nbits)			\
298   |  bitmap_copy_clear_tail((unsigned long *)(bitmap), (const unsigned long *)(buf), (nbits))
299   | #define bitmap_to_arr64(buf, bitmap, nbits)			\
300   |  bitmap_copy_clear_tail((unsigned long *)(buf), (const unsigned long *)(bitmap), (nbits))
301   | #endif
302   |
303   | static inline bool bitmap_and(unsigned long *dst, const unsigned long *src1,
304   |  const unsigned long *src2, unsigned int nbits)
305   | {
306   |  if (small_const_nbits(nbits))
307   |  return (*dst = *src1 & *src2 & BITMAP_LAST_WORD_MASK(nbits)) != 0;
308   |  return __bitmap_and(dst, src1, src2, nbits);
309   | }
310   |
311   | static inline void bitmap_or(unsigned long *dst, const unsigned long *src1,
312   |  const unsigned long *src2, unsigned int nbits)
313   | {
314   |  if (small_const_nbits(nbits))
315   | 		*dst = *src1 | *src2;
316   |  else
317   | 		__bitmap_or(dst, src1, src2, nbits);
318   | }
319   |
320   | static inline void bitmap_xor(unsigned long *dst, const unsigned long *src1,
321   |  const unsigned long *src2, unsigned int nbits)
322   | {
323   |  if (small_const_nbits(nbits))
324   | 		*dst = *src1 ^ *src2;
325   |  else
326   | 		__bitmap_xor(dst, src1, src2, nbits);
327   | }
328   |
329   | static inline bool bitmap_andnot(unsigned long *dst, const unsigned long *src1,
330   |  const unsigned long *src2, unsigned int nbits)
331   | {
332   |  if (small_const_nbits(nbits))
333   |  return (*dst = *src1 & ~(*src2) & BITMAP_LAST_WORD_MASK(nbits)) != 0;
334   |  return __bitmap_andnot(dst, src1, src2, nbits);
    41←Missing hwrm_req_drop() after successful hwrm_req_init()
335   | }
336   |
337   | static inline void bitmap_complement(unsigned long *dst, const unsigned long *src,
338   |  unsigned int nbits)
339   | {
340   |  if (small_const_nbits(nbits))
341   | 		*dst = ~(*src);
342   |  else
343   | 		__bitmap_complement(dst, src, nbits);
344   | }
345   |
346   | #ifdef __LITTLE_ENDIAN
347   | #define BITMAP_MEM_ALIGNMENT 8
348   | #else
349   | #define BITMAP_MEM_ALIGNMENT (8 * sizeof(unsigned long))
350   | #endif
351   | #define BITMAP_MEM_MASK (BITMAP_MEM_ALIGNMENT - 1)
352   |
353   | static inline bool bitmap_equal(const unsigned long *src1,
354   |  const unsigned long *src2, unsigned int nbits)
355   | {
356   |  if (small_const_nbits(nbits))
357   |  return !((*src1 ^ *src2) & BITMAP_LAST_WORD_MASK(nbits));
358   |  if (__builtin_constant_p(nbits & BITMAP_MEM_MASK) &&
359   |  IS_ALIGNED(nbits, BITMAP_MEM_ALIGNMENT))
360   |  return !memcmp(src1, src2, nbits / 8);
361   |  return __bitmap_equal(src1, src2, nbits);
362   | }
363   |
364   | /**
