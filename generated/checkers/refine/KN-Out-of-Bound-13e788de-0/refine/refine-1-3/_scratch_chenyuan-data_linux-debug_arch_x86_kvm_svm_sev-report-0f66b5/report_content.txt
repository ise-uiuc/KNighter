### Report Summary

File:| /scratch/chenyuan-data/linux-debug/arch/x86/kvm/svm/sev.c
---|---
Warning:| line 159, column 15
Off-by-one bound check: use '>= MAX' instead of '> MAX' for index validation

### Annotated Source Code


64    | #define sev_es_enabled false
65    | #define sev_es_debug_swap_enabled false
66    | #endif /* CONFIG_KVM_AMD_SEV */
67    |
68    | static u8 sev_enc_bit;
69    | static DECLARE_RWSEM(sev_deactivate_lock);
70    | static DEFINE_MUTEX(sev_bitmap_lock);
71    | unsigned int max_sev_asid;
72    | static unsigned int min_sev_asid;
73    | static unsigned long sev_me_mask;
74    | static unsigned int nr_asids;
75    | static unsigned long *sev_asid_bitmap;
76    | static unsigned long *sev_reclaim_asid_bitmap;
77    |
78    | struct enc_region {
79    |  struct list_head list;
80    |  unsigned long npages;
81    |  struct page **pages;
82    |  unsigned long uaddr;
83    |  unsigned long size;
84    | };
85    |
86    | /* Called with the sev_bitmap_lock held, or on shutdown  */
87    | static int sev_flush_asids(unsigned int min_asid, unsigned int max_asid)
88    | {
89    |  int ret, error = 0;
90    |  unsigned int asid;
91    |
92    |  /* Check if there are any ASIDs to reclaim before performing a flush */
93    | 	asid = find_next_bit(sev_reclaim_asid_bitmap, nr_asids, min_asid);
94    |  if (asid > max_asid)
95    |  return -EBUSY;
96    |
97    |  /*
98    |  * DEACTIVATE will clear the WBINVD indicator causing DF_FLUSH to fail,
99    |  * so it must be guarded.
100   |  */
101   | 	down_write(&sev_deactivate_lock);
102   |
103   | 	wbinvd_on_all_cpus();
104   | 	ret = sev_guest_df_flush(&error);
105   |
106   | 	up_write(&sev_deactivate_lock);
107   |
108   |  if (ret)
109   |  pr_err("SEV: DF_FLUSH failed, ret=%d, error=%#x\n", ret, error);
110   |
111   |  return ret;
112   | }
113   |
114   | static inline bool is_mirroring_enc_context(struct kvm *kvm)
115   | {
116   |  return !!to_kvm_svm(kvm)->sev_info.enc_context_owner;
117   | }
118   |
119   | /* Must be called with the sev_bitmap_lock held */
120   | static bool __sev_recycle_asids(unsigned int min_asid, unsigned int max_asid)
121   | {
122   |  if (sev_flush_asids(min_asid, max_asid))
123   |  return false;
124   |
125   |  /* The flush process will flush all reclaimable SEV and SEV-ES ASIDs */
126   | 	bitmap_xor(sev_asid_bitmap, sev_asid_bitmap, sev_reclaim_asid_bitmap,
127   | 		   nr_asids);
128   | 	bitmap_zero(sev_reclaim_asid_bitmap, nr_asids);
129   |
130   |  return true;
131   | }
132   |
133   | static int sev_misc_cg_try_charge(struct kvm_sev_info *sev)
134   | {
135   |  enum misc_res_type type = sev->es_active ? MISC_CG_RES_SEV_ES : MISC_CG_RES_SEV;
136   |  return misc_cg_try_charge(type, sev->misc_cg, 1);
137   | }
138   |
139   | static void sev_misc_cg_uncharge(struct kvm_sev_info *sev)
140   | {
141   |  enum misc_res_type type = sev->es_active ? MISC_CG_RES_SEV_ES : MISC_CG_RES_SEV;
142   | 	misc_cg_uncharge(type, sev->misc_cg, 1);
143   | }
144   |
145   | static int sev_asid_new(struct kvm_sev_info *sev)
146   | {
147   |  /*
148   |  * SEV-enabled guests must use asid from min_sev_asid to max_sev_asid.
149   |  * SEV-ES-enabled guest can use from 1 to min_sev_asid - 1.
150   |  * Note: min ASID can end up larger than the max if basic SEV support is
151   |  * effectively disabled by disallowing use of ASIDs for SEV guests.
152   |  */
153   |  unsigned int min_asid = sev->es_active13.1Field 'es_active' is false ? 1 : min_sev_asid;
    14←'?' condition is false→
154   |  unsigned int max_asid = sev->es_active14.1Field 'es_active' is false ? min_sev_asid - 1 : max_sev_asid;
    15←'?' condition is false→
155   |  unsigned int asid;
156   | 	bool retry = true;
157   |  int ret;
158   |
159   |  if (min_asid > max_asid)
    16←Assuming 'min_asid' is <= 'max_asid'→
    17←Off-by-one bound check: use '>= MAX' instead of '> MAX' for index validation
160   |  return -ENOTTY;
161   |
162   |  WARN_ON(sev->misc_cg);
163   | 	sev->misc_cg = get_current_misc_cg();
164   | 	ret = sev_misc_cg_try_charge(sev);
165   |  if (ret) {
166   | 		put_misc_cg(sev->misc_cg);
167   | 		sev->misc_cg = NULL;
168   |  return ret;
169   | 	}
170   |
171   |  mutex_lock(&sev_bitmap_lock);
172   |
173   | again:
174   | 	asid = find_next_zero_bit(sev_asid_bitmap, max_asid + 1, min_asid);
175   |  if (asid > max_asid) {
176   |  if (retry && __sev_recycle_asids(min_asid, max_asid)) {
177   | 			retry = false;
178   |  goto again;
179   | 		}
180   | 		mutex_unlock(&sev_bitmap_lock);
181   | 		ret = -EBUSY;
182   |  goto e_uncharge;
183   | 	}
184   |
185   |  __set_bit(asid, sev_asid_bitmap);
186   |
187   | 	mutex_unlock(&sev_bitmap_lock);
188   |
189   | 	sev->asid = asid;
204   |
205   | static void sev_asid_free(struct kvm_sev_info *sev)
206   | {
207   |  struct svm_cpu_data *sd;
208   |  int cpu;
209   |
210   |  mutex_lock(&sev_bitmap_lock);
211   |
212   |  __set_bit(sev->asid, sev_reclaim_asid_bitmap);
213   |
214   |  for_each_possible_cpu(cpu) {
215   | 		sd = per_cpu_ptr(&svm_data, cpu);
216   | 		sd->sev_vmcbs[sev->asid] = NULL;
217   | 	}
218   |
219   | 	mutex_unlock(&sev_bitmap_lock);
220   |
221   | 	sev_misc_cg_uncharge(sev);
222   | 	put_misc_cg(sev->misc_cg);
223   | 	sev->misc_cg = NULL;
224   | }
225   |
226   | static void sev_decommission(unsigned int handle)
227   | {
228   |  struct sev_data_decommission decommission;
229   |
230   |  if (!handle)
231   |  return;
232   |
233   | 	decommission.handle = handle;
234   | 	sev_guest_decommission(&decommission, NULL);
235   | }
236   |
237   | static void sev_unbind_asid(struct kvm *kvm, unsigned int handle)
238   | {
239   |  struct sev_data_deactivate deactivate;
240   |
241   |  if (!handle)
242   |  return;
243   |
244   | 	deactivate.handle = handle;
245   |
246   |  /* Guard DEACTIVATE against WBINVD/DF_FLUSH used in ASID recycling */
247   | 	down_read(&sev_deactivate_lock);
248   | 	sev_guest_deactivate(&deactivate, NULL);
249   | 	up_read(&sev_deactivate_lock);
250   |
251   | 	sev_decommission(handle);
252   | }
253   |
254   | static int sev_guest_init(struct kvm *kvm, struct kvm_sev_cmd *argp)
255   | {
256   |  struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
257   |  struct sev_platform_init_args init_args = {0};
258   |  int ret;
259   |
260   |  if (kvm->created_vcpus)
    9←Assuming field 'created_vcpus' is 0→
    10←Taking false branch→
261   |  return -EINVAL;
262   |
263   |  if (unlikely(sev->active))
    11←Assuming field 'active' is false→
    12←Taking false branch→
264   |  return -EINVAL;
265   |
266   |  sev->active = true;
267   | 	sev->es_active = argp->id == KVM_SEV_ES_INIT;
268   |  ret = sev_asid_new(sev);
    13←Calling 'sev_asid_new'→
269   |  if (ret)
270   |  goto e_no_asid;
271   |
272   | 	init_args.probe = false;
273   | 	ret = sev_platform_init(&init_args);
274   |  if (ret)
275   |  goto e_free;
276   |
277   | 	INIT_LIST_HEAD(&sev->regions_list);
278   | 	INIT_LIST_HEAD(&sev->mirror_vms);
279   |
280   | 	kvm_set_apicv_inhibit(kvm, APICV_INHIBIT_REASON_SEV);
281   |
282   |  return 0;
283   |
284   | e_free:
285   | 	argp->error = init_args.error;
286   | 	sev_asid_free(sev);
287   | 	sev->asid = 0;
288   | e_no_asid:
289   | 	sev->es_active = false;
290   | 	sev->active = false;
291   |  return ret;
292   | }
293   |
294   | static int sev_bind_asid(struct kvm *kvm, unsigned int handle, int *error)
295   | {
296   |  unsigned int asid = sev_get_asid(kvm);
297   |  struct sev_data_activate activate;
298   |  int ret;
1814  |
1815  |  if (sev_guest(kvm) || !sev_guest(source_kvm)) {
1816  | 		ret = -EINVAL;
1817  |  goto out_unlock;
1818  | 	}
1819  |
1820  | 	src_sev = &to_kvm_svm(source_kvm)->sev_info;
1821  |
1822  | 	dst_sev->misc_cg = get_current_misc_cg();
1823  | 	cg_cleanup_sev = dst_sev;
1824  |  if (dst_sev->misc_cg != src_sev->misc_cg) {
1825  | 		ret = sev_misc_cg_try_charge(dst_sev);
1826  |  if (ret)
1827  |  goto out_dst_cgroup;
1828  | 		charged = true;
1829  | 	}
1830  |
1831  | 	ret = sev_lock_vcpus_for_migration(kvm, SEV_MIGRATION_SOURCE);
1832  |  if (ret)
1833  |  goto out_dst_cgroup;
1834  | 	ret = sev_lock_vcpus_for_migration(source_kvm, SEV_MIGRATION_TARGET);
1835  |  if (ret)
1836  |  goto out_dst_vcpu;
1837  |
1838  | 	ret = sev_check_source_vcpus(kvm, source_kvm);
1839  |  if (ret)
1840  |  goto out_source_vcpu;
1841  |
1842  | 	sev_migrate_from(kvm, source_kvm);
1843  | 	kvm_vm_dead(source_kvm);
1844  | 	cg_cleanup_sev = src_sev;
1845  | 	ret = 0;
1846  |
1847  | out_source_vcpu:
1848  | 	sev_unlock_vcpus_for_migration(source_kvm);
1849  | out_dst_vcpu:
1850  | 	sev_unlock_vcpus_for_migration(kvm);
1851  | out_dst_cgroup:
1852  |  /* Operates on the source on success, on the destination on failure.  */
1853  |  if (charged)
1854  | 		sev_misc_cg_uncharge(cg_cleanup_sev);
1855  | 	put_misc_cg(cg_cleanup_sev->misc_cg);
1856  | 	cg_cleanup_sev->misc_cg = NULL;
1857  | out_unlock:
1858  | 	sev_unlock_two_vms(kvm, source_kvm);
1859  | out_fput:
1860  | 	fdput(f);
1861  |  return ret;
1862  | }
1863  |
1864  | int sev_mem_enc_ioctl(struct kvm *kvm, void __user *argp)
1865  | {
1866  |  struct kvm_sev_cmd sev_cmd;
1867  |  int r;
1868  |
1869  |  if (!sev_enabled)
    1Assuming 'sev_enabled' is true→
    2←Taking false branch→
1870  |  return -ENOTTY;
1871  |
1872  |  if (!argp)
    3←Assuming 'argp' is non-null→
    4←Taking false branch→
1873  |  return 0;
1874  |
1875  |  if (copy_from_user(&sev_cmd, argp, sizeof(struct kvm_sev_cmd)))
    5←Assuming the condition is false→
    6←Taking false branch→
1876  |  return -EFAULT;
1877  |
1878  |  mutex_lock(&kvm->lock);
1879  |
1880  |  /* Only the enc_context_owner handles some memory enc operations. */
1881  |  if (is_mirroring_enc_context(kvm) &&
1882  | 	    !is_cmd_allowed_from_mirror(sev_cmd.id)) {
1883  | 		r = -EINVAL;
1884  |  goto out;
1885  | 	}
1886  |
1887  |  switch (sev_cmd.id) {
    7←Control jumps to 'case KVM_SEV_INIT:'  at line 1894→
1888  |  case KVM_SEV_ES_INIT:
1889  |  if (!sev_es_enabled) {
1890  | 			r = -ENOTTY;
1891  |  goto out;
1892  | 		}
1893  |  fallthrough;
1894  |  case KVM_SEV_INIT:
1895  |  r = sev_guest_init(kvm, &sev_cmd);
    8←Calling 'sev_guest_init'→
1896  |  break;
1897  |  case KVM_SEV_LAUNCH_START:
1898  | 		r = sev_launch_start(kvm, &sev_cmd);
1899  |  break;
1900  |  case KVM_SEV_LAUNCH_UPDATE_DATA:
1901  | 		r = sev_launch_update_data(kvm, &sev_cmd);
1902  |  break;
1903  |  case KVM_SEV_LAUNCH_UPDATE_VMSA:
1904  | 		r = sev_launch_update_vmsa(kvm, &sev_cmd);
1905  |  break;
1906  |  case KVM_SEV_LAUNCH_MEASURE:
1907  | 		r = sev_launch_measure(kvm, &sev_cmd);
1908  |  break;
1909  |  case KVM_SEV_LAUNCH_FINISH:
1910  | 		r = sev_launch_finish(kvm, &sev_cmd);
1911  |  break;
1912  |  case KVM_SEV_GUEST_STATUS:
1913  | 		r = sev_guest_status(kvm, &sev_cmd);
1914  |  break;
1915  |  case KVM_SEV_DBG_DECRYPT:
1916  | 		r = sev_dbg_crypt(kvm, &sev_cmd, true);
1917  |  break;
1918  |  case KVM_SEV_DBG_ENCRYPT:
1919  | 		r = sev_dbg_crypt(kvm, &sev_cmd, false);
1920  |  break;
1921  |  case KVM_SEV_LAUNCH_SECRET:
1922  | 		r = sev_launch_secret(kvm, &sev_cmd);
1923  |  break;
1924  |  case KVM_SEV_GET_ATTESTATION_REPORT:
1925  | 		r = sev_get_attestation_report(kvm, &sev_cmd);
